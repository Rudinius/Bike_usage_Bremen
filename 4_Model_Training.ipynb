{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "y9LfcFe3a_nP",
        "outputId": "c8b769aa-863d-4f8f-c103-312664bf1e20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y9LfcFe3a_nP",
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CBLnLwZIZpWJ",
      "metadata": {
        "id": "CBLnLwZIZpWJ"
      },
      "source": [
        "# Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lZXvJFJqZuRE",
      "metadata": {
        "id": "lZXvJFJqZuRE"
      },
      "source": [
        "In the Model learning step, the prepared dataset from [3_Imputing](https://raw.githubusercontent.com/Rudinius/Bike_usage_Bremen/main/3_Imputing.ipynb) is loaded. Then different machine learning algorithms are trained and compared to each other.\n",
        "\n",
        "We will test\n",
        "* XGBoost\n",
        "* Multilayer perceptron (MLP)\n",
        "* Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c910711",
      "metadata": {
        "id": "0c910711"
      },
      "source": [
        "<a name=\"content\"></a>\n",
        "# Content\n",
        "\n",
        "* [1. Import libraries and mount drive](#1.)\n",
        "* [2. Import datasets](#2.)\n",
        "* [3. Select a target station](#3.)\n",
        "* [4. Establish baseline benchmark](#4.)\n",
        "* [5. Training machine learning algorithms](#5)\n",
        "    * [5.2. XGBoost](#5.2.)\n",
        "    * [5.3. Multilayer perceptron](#5.3.)\n",
        "    * [5.4. Recurrent Neural Network](#5.4.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f76996",
      "metadata": {
        "id": "85f76996"
      },
      "source": [
        "<a name=\"1.\"></a>\n",
        "# 1.&nbsp;Import libraries\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "id": "3731ea33",
      "metadata": {
        "id": "3731ea33"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "#from plotly.subplots import make_subplots\n",
        "#import random\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, TimeSeriesSplit\n",
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization, LSTM, Bidirectional, Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import RootMeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "LcKvjPd27cDu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcKvjPd27cDu",
        "outputId": "977e4def-9ce9-4944-e3f8-e8a40c1c03db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyjanitor in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from pyjanitor) (8.4.0)\n",
            "Requirement already satisfied: pandas-flavor in /usr/local/lib/python3.10/dist-packages (from pyjanitor) (0.6.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from pyjanitor) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyjanitor) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.10/dist-packages (from pandas-flavor->pyjanitor) (1.5.3)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from pandas-flavor->pyjanitor) (2023.7.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->pyjanitor) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-flavor->pyjanitor) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-flavor->pyjanitor) (2023.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from xarray->pandas-flavor->pyjanitor) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas-flavor->pyjanitor) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install package pyjanitor since it is not part of the standard packages\n",
        "# of Google Colab\n",
        "\n",
        "import importlib\n",
        "\n",
        "# Check if package is installed\n",
        "package_name = \"pyjanitor\"\n",
        "spec = importlib.util.find_spec(package_name)\n",
        "if spec is None:\n",
        "    # Package is not installed, install it via pip\n",
        "    !pip install pyjanitor\n",
        "else:\n",
        "    print(f\"{package_name} is already installed\")\n",
        "\n",
        "import janitor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.set_random_seed(1)"
      ],
      "metadata": {
        "id": "FBMlPVNJzgfz",
        "outputId": "16d18a78-2926-4004-c4c3-af3d4cf3f68c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FBMlPVNJzgfz",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2516jhMiVxrJ",
      "metadata": {
        "id": "2516jhMiVxrJ"
      },
      "source": [
        "<a name=\"2.\"></a>\n",
        "#2.&nbsp;Import dataset\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IF9lS_3ok1tO",
      "metadata": {
        "id": "IF9lS_3ok1tO"
      },
      "source": [
        "Import the processed dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "Xu3OXfHqVxfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu3OXfHqVxfa",
        "outputId": "ecb64f1b-569a-450d-c27e-99f5d11aa031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Set base url\n",
        "url = \"https://raw.githubusercontent.com/Rudinius/Bike_usage_Bremen/main/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "2etHV6ODVsUV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "2etHV6ODVsUV",
        "outputId": "346dd999-d17d-4a3e-aa32-887f15304186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            graf_moltke_straße_ostseite  graf_moltke_straße_westseite  \\\n",
              "date                                                                    \n",
              "2013-01-01                        261.0                         290.0   \n",
              "2013-01-02                        750.0                         876.0   \n",
              "2013-01-03                        931.0                        1015.0   \n",
              "2013-01-04                        500.0                         587.0   \n",
              "2013-01-05                       1013.0                        1011.0   \n",
              "\n",
              "            hastedter_bruckenstraße  langemarckstraße_ostseite  \\\n",
              "date                                                             \n",
              "2013-01-01                    381.0                      312.0   \n",
              "2013-01-02                   1109.0                     1258.0   \n",
              "2013-01-03                   1603.0                     1556.0   \n",
              "2013-01-04                   1284.0                      703.0   \n",
              "2013-01-05                      0.0                     1856.0   \n",
              "\n",
              "            langemarckstraße_westseite  osterdeich  radweg_kleine_weser  \\\n",
              "date                                                                      \n",
              "2013-01-01                       308.0       870.0                410.0   \n",
              "2013-01-02                      1120.0      2169.0               1762.0   \n",
              "2013-01-03                      1480.0      2295.0               2287.0   \n",
              "2013-01-04                       626.0      1640.0               1548.0   \n",
              "2013-01-05                      1621.0      4128.0               4256.0   \n",
              "\n",
              "            schwachhauser_ring  wachmannstraße_auswarts_sud  \\\n",
              "date                                                          \n",
              "2013-01-01                 391                        514.0   \n",
              "2013-01-02                 829                       1786.0   \n",
              "2013-01-03                1196                       2412.0   \n",
              "2013-01-04                1418                        964.0   \n",
              "2013-01-05                3075                       2065.0   \n",
              "\n",
              "            wachmannstraße_einwarts_nord  ...  holiday_2_weihnachtsfeiertag  \\\n",
              "date                                      ...                                 \n",
              "2013-01-01                         267.0  ...                           0.0   \n",
              "2013-01-02                        1456.0  ...                           0.0   \n",
              "2013-01-03                        2035.0  ...                           0.0   \n",
              "2013-01-04                         702.0  ...                           0.0   \n",
              "2013-01-05                        1377.0  ...                           0.0   \n",
              "\n",
              "            holiday_christi_himmelfahrt  holiday_karfreitag  holiday_neujahr  \\\n",
              "date                                                                           \n",
              "2013-01-01                          0.0                 0.0              1.0   \n",
              "2013-01-02                          0.0                 0.0              0.0   \n",
              "2013-01-03                          0.0                 0.0              0.0   \n",
              "2013-01-04                          0.0                 0.0              0.0   \n",
              "2013-01-05                          0.0                 0.0              0.0   \n",
              "\n",
              "            holiday_ostermontag  holiday_pfingstmontag  \\\n",
              "date                                                     \n",
              "2013-01-01                  0.0                    0.0   \n",
              "2013-01-02                  0.0                    0.0   \n",
              "2013-01-03                  0.0                    0.0   \n",
              "2013-01-04                  0.0                    0.0   \n",
              "2013-01-05                  0.0                    0.0   \n",
              "\n",
              "            holiday_reformationstag  holiday_tag_der_arbeit  \\\n",
              "date                                                          \n",
              "2013-01-01                      0.0                     0.0   \n",
              "2013-01-02                      0.0                     0.0   \n",
              "2013-01-03                      0.0                     0.0   \n",
              "2013-01-04                      0.0                     0.0   \n",
              "2013-01-05                      0.0                     0.0   \n",
              "\n",
              "            holiday_tag_der_deutschen_einheit  transformed_vacation  \n",
              "date                                                                 \n",
              "2013-01-01                                0.0                     1  \n",
              "2013-01-02                                0.0                     1  \n",
              "2013-01-03                                0.0                     1  \n",
              "2013-01-04                                0.0                     1  \n",
              "2013-01-05                                0.0                     1  \n",
              "\n",
              "[5 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d56d613a-eedc-47d6-b090-bd310e7d4fb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>graf_moltke_straße_ostseite</th>\n",
              "      <th>graf_moltke_straße_westseite</th>\n",
              "      <th>hastedter_bruckenstraße</th>\n",
              "      <th>langemarckstraße_ostseite</th>\n",
              "      <th>langemarckstraße_westseite</th>\n",
              "      <th>osterdeich</th>\n",
              "      <th>radweg_kleine_weser</th>\n",
              "      <th>schwachhauser_ring</th>\n",
              "      <th>wachmannstraße_auswarts_sud</th>\n",
              "      <th>wachmannstraße_einwarts_nord</th>\n",
              "      <th>...</th>\n",
              "      <th>holiday_2_weihnachtsfeiertag</th>\n",
              "      <th>holiday_christi_himmelfahrt</th>\n",
              "      <th>holiday_karfreitag</th>\n",
              "      <th>holiday_neujahr</th>\n",
              "      <th>holiday_ostermontag</th>\n",
              "      <th>holiday_pfingstmontag</th>\n",
              "      <th>holiday_reformationstag</th>\n",
              "      <th>holiday_tag_der_arbeit</th>\n",
              "      <th>holiday_tag_der_deutschen_einheit</th>\n",
              "      <th>transformed_vacation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>261.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>870.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>391</td>\n",
              "      <td>514.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>750.0</td>\n",
              "      <td>876.0</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>2169.0</td>\n",
              "      <td>1762.0</td>\n",
              "      <td>829</td>\n",
              "      <td>1786.0</td>\n",
              "      <td>1456.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>931.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>1603.0</td>\n",
              "      <td>1556.0</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>2287.0</td>\n",
              "      <td>1196</td>\n",
              "      <td>2412.0</td>\n",
              "      <td>2035.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>500.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>703.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>1640.0</td>\n",
              "      <td>1548.0</td>\n",
              "      <td>1418</td>\n",
              "      <td>964.0</td>\n",
              "      <td>702.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>1013.0</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1856.0</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>4128.0</td>\n",
              "      <td>4256.0</td>\n",
              "      <td>3075</td>\n",
              "      <td>2065.0</td>\n",
              "      <td>1377.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d56d613a-eedc-47d6-b090-bd310e7d4fb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d56d613a-eedc-47d6-b090-bd310e7d4fb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d56d613a-eedc-47d6-b090-bd310e7d4fb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6afde60-9cc0-47ff-8acb-9feb4dfef1e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6afde60-9cc0-47ff-8acb-9feb4dfef1e2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6afde60-9cc0-47ff-8acb-9feb4dfef1e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# Import dataset\n",
        "\n",
        "# We will also parse the date column as datetime64 and set it to the index column\n",
        "df = pd.read_csv(url + \"03_training_data/\" + \"2023-08-24_processed_df.csv\",\n",
        "                         parse_dates=[0], index_col=[0])\n",
        "\n",
        "# Check the correct loading of dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv96sN3croOJ"
      },
      "source": [
        "<a name=\"3.\"></a>\n",
        "# 3.&nbsp;Select a target station\n",
        "[Content](#content)\n"
      ],
      "id": "jv96sN3croOJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many stations that we could train our model on. Also we could add up all stations to a column `total` and try to predict the overall number in the city per day. However this approach would average many values which would lead on side to less noisy data as single outliers would be less impactful. On the other side it would also average over indivdual patterns.\n",
        "\n",
        "For this reason, we choose a single station to train our model on. For real-life purposes better results could be expected with one model per station.\n",
        "\n",
        "For the further process, we will work with the station: `wilhelm_kaisen_brucke_ost`\n"
      ],
      "metadata": {
        "id": "OG06qWVLrl_R"
      },
      "id": "OG06qWVLrl_R"
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"imputed_wilhelm_kaisen_brucke_ost\""
      ],
      "metadata": {
        "id": "cdukN1mWtqr5",
        "outputId": "71fe4837-1d84-477a-ae0c-e5b20d5a5fe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cdukN1mWtqr5",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gBM3I6LFOHL9",
      "metadata": {
        "id": "gBM3I6LFOHL9"
      },
      "source": [
        "<a name=\"4.\"></a>\n",
        "# 4.&nbsp;Establish baseline benchmark\n",
        "[Content](#content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VgkVXhdAx6zB",
      "metadata": {
        "id": "VgkVXhdAx6zB"
      },
      "source": [
        "For our current task of creating model a to predict the amount of cyclers for a given day, we do not have any baseline metric score to measure our model against.\n",
        "For this reason, we will create a naive baseline model. For this, we will simply predict the amount of a day based on the value of previous day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "6mu5aaMpO42j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mu5aaMpO42j",
        "outputId": "53cf3b1a-f5da-40a5-bf31-34c6776f95b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1791.993974\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model's performance using RMSE\n",
        "\n",
        "# Select the `wilhelm_kaisen_brucke_ost` column as our target and preds arrays\n",
        "y = y_hat = df.loc[:,target]\n",
        "\n",
        "rmse = 0\n",
        "length = y.shape[0]\n",
        "\n",
        "# Loop from 0 to second last entry, as we can only use seconds last entry to\n",
        "# predict the last entry of series\n",
        "for i in range(length-1):\n",
        "    # The mean_sqared_error function expects an array as input, therfore we\n",
        "    # concatenate the range from current value to current value + 1 (excluding)\n",
        "    rmse += np.sqrt(mean_squared_error(y[i+1:i+2], y_hat[i:i+1]))\n",
        "\n",
        "# Divide rmse value by number of pairs\n",
        "rmse = rmse / (length-1)\n",
        "print(\"RMSE: %f\" % (rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6O5OFAwW9Pm",
      "metadata": {
        "id": "f6O5OFAwW9Pm"
      },
      "source": [
        "If we were naivly predicting the current value with the last value, we get an error over the entire dataset of approximately $1,792$.\n",
        "\n",
        "This is our naive benchmark to compare our model against."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YHm0GDHUmczY",
      "metadata": {
        "id": "YHm0GDHUmczY"
      },
      "source": [
        "Another method would be to predict the value of a given day by the average of all the other equal days in the dataset (e.g., to predict 18.08.2017, we take the average of all other 18.08. days in the dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "kOSNaRxAdoCA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOSNaRxAdoCA",
        "outputId": "46441cec-b3ee-48f1-b74f-4a2ea1b357fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2033.3351259991568\n"
          ]
        }
      ],
      "source": [
        "# Initialize squared error\n",
        "se = 0\n",
        "\n",
        "# Get the total number of examples\n",
        "m = df.shape[0]\n",
        "\n",
        "for i in df.index:\n",
        "    day = i.day\n",
        "    month = i.month\n",
        "    year = i.year\n",
        "\n",
        "    # create a mask for given day but exclude the day we want to predict\n",
        "    mask = (df.index.day == day) & (df.index.month == month) & (df.index.year != year)\n",
        "\n",
        "    # Get value for current day and mean values of all the other same days in the dataset\n",
        "    y = df.loc[i, target]\n",
        "    y_hat = df.loc[mask, target].mean()\n",
        "\n",
        "    # Calculate the squared error\n",
        "    se += (y - y_hat)**2\n",
        "\n",
        "# Calculate mean squared error\n",
        "mse = se / m\n",
        "\n",
        "# Calcualte root mean squared error\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SQ-iEzyHoc8M",
      "metadata": {
        "id": "SQ-iEzyHoc8M"
      },
      "source": [
        "With this second approach, of average all our previous values for the given day and using this as our forecast, we get an error over the entire dataset of approximately $2,033$.\n",
        "\n",
        "The error of this second naive approach is close to the first approach.\n",
        "Both approaches could be seen as human-level as this would be a typical approach of a human, to predict the value of any given day. A domain expert, who also looks at more data and e.g., compares also the temperatures, could come up with better estimates. However humans are typically not very good in accurately predicting complex time-series data. The expected Bayes error (least possible error) should therefore be much lower."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5HqwjOgkxauH",
      "metadata": {
        "id": "5HqwjOgkxauH"
      },
      "source": [
        "<a name=\"5\"></a>\n",
        "# 5.&nbsp;Training machine learning algorithms\n",
        "[Content](#content)\n",
        "\n",
        "We are going to train 1 shallow machine learning algorithm and 2 deep machine learning algorithms to be able to compare performances. Those are:\n",
        "\n",
        "* XGBoost\n",
        "* Multilayer Perceptron (MLP -- standard NN)\n",
        "* Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b154c25",
      "metadata": {
        "id": "9b154c25"
      },
      "source": [
        "<a name=\"5.1.\"></a>\n",
        "## 5.1. Adding sequential data to our model\n",
        "\n",
        "[Content](#content)\n",
        "\n",
        "In contrast to RNNs where the algorithm takes automically the datapoints of previous timesteps into account, XGBoost and MLPs do not have direct access to the sequential data of previous time steps.\n",
        "Those algorithms have only indirect knowledge via the learned model parameters. RNNs however directly include the previous timestep for learning the parameters of the current timestep.\n",
        "\n",
        "We will add the data points of the previous time steps as features to the feature vector.\n",
        "\n",
        "In this case, we will only add the last 3 values, as the observed improvement of accuracy (RMSE score) is drastically decressing with each further time step added after 3 steps.\n",
        "\n",
        "Improvements:\n",
        "* 1 day 6291 2,8%\n",
        "* 2 day 6157 2,1%\n",
        "* 3 day 6120 0,6%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842f23eb",
      "metadata": {
        "id": "842f23eb"
      },
      "source": [
        "The following code creates a dataframe with a variable amount of time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "a03f3499",
      "metadata": {
        "id": "a03f3499",
        "outputId": "1cde463d-7877-4cf5-e768-d11ca29fd6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Create empty new dataframe\\ndf_lagged_days = pd.DataFrame({})\\n\\n# Select the number of lagged days\\ngo_back_x_days = 3\\n\\nfor i in range(go_back_x_days):\\n    # Shift the values in \"Total\" by i and assign to new column prev_Total_i+1\\n    df_lagged_days[f\\'prev_total_{i+1}\\'] = df_transformed_date[\\'total\\'].shift(i+1)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Create empty new dataframe\n",
        "df_lagged_days = pd.DataFrame({})\n",
        "\n",
        "# Select the number of lagged days\n",
        "go_back_x_days = 3\n",
        "\n",
        "for i in range(go_back_x_days):\n",
        "    # Shift the values in \"Total\" by i and assign to new column prev_Total_i+1\n",
        "    df_lagged_days[f'prev_total_{i+1}'] = df_transformed_date['total'].shift(i+1)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mO2Xt87cykEf",
      "metadata": {
        "id": "mO2Xt87cykEf"
      },
      "source": [
        "<a name=\"5.2.\"></a>\n",
        "## 5.2. XGBoost\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZgSdeq3fOxaQ",
      "metadata": {
        "id": "ZgSdeq3fOxaQ"
      },
      "source": [
        "For XGBoost, we will add the dataframe `df_lagged_days` to our dataset. Because we do not have all the information about the previous days for the first `go_back_x_days`, we drop the rows with `na` values. The parameter on how far to go back in time, has therefore an impact on the length of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "outputId": "9f8fcd18-ea96-4919-849a-e8f0008bf6bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "p8e0WfWKj6Gn"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Concat new dataframe with old dataframe\\n# Using bfill strategy on dataset since the first few days will have NaN values\\n# Using pyjanitor to clean up names\\ndf_transformed_date_lagged = (pd.concat([df_transformed_date, df_lagged_days], axis=1)\\n                              .dropna(axis=0)\\n                              .clean_names(strip_underscores=\"both\"))\\n\\n# Check output\\ndf_transformed_date_lagged\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Concat new dataframe with old dataframe\n",
        "# Using bfill strategy on dataset since the first few days will have NaN values\n",
        "# Using pyjanitor to clean up names\n",
        "df_transformed_date_lagged = (pd.concat([df_transformed_date, df_lagged_days], axis=1)\n",
        "                              .dropna(axis=0)\n",
        "                              .clean_names(strip_underscores=\"both\"))\n",
        "\n",
        "# Check output\n",
        "df_transformed_date_lagged\n",
        "\"\"\""
      ],
      "id": "p8e0WfWKj6Gn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5.2.1\"></a>\n",
        "### 5.2.1 Split data into train and dev set and standardize training data\n",
        "[Content](#content)\n",
        "\n",
        "Now, we will split the data into a training set and into a dev set. Also here we select the final futures, which we want to use to train our model.\n",
        "\n",
        "Highly correlated features `tavg`, `tmin`, `wpgt` will be removed and features with no correlation to our target value will be also removed (`wdir`).\n",
        "\n",
        "When splitting into train and dev set, we will not shuffle the data. This ensures that the validation results are more realistic since they are being evaluated on the data collected after the model was trained. Otherwise we would introduce a \"leakage error\" into our data."
      ],
      "metadata": {
        "id": "XH_6MbWERL_5"
      },
      "id": "XH_6MbWERL_5"
    },
    {
      "cell_type": "code",
      "source": [
        "features_date = [\n",
        "    'year',\n",
        "    'month',\n",
        "    'day',\n",
        "    'weekday',\n",
        "]\n",
        "\n",
        "features_sin_cos_transformation = [\n",
        "    'week_sin', 'week_cos',\n",
        "    'month_sin', 'month_cos',\n",
        "    'year_sin', 'year_cos',\n",
        "]\n",
        "\n",
        "features_weather = [\n",
        "    'tmax',\n",
        "    'prcp',\n",
        "    'imputed_snow',\n",
        "    'wspd',\n",
        "    'pres',\n",
        "    'tsun',\n",
        "    ]\n",
        "\n",
        "features_holidays_vacation = [\n",
        "    'holiday_1_weihnachtsfeiertag', 'holiday_2_weihnachtsfeiertag',\n",
        "    'holiday_christi_himmelfahrt', 'holiday_karfreitag', 'holiday_neujahr',\n",
        "    'holiday_ostermontag', 'holiday_pfingstmontag',\n",
        "    'holiday_reformationstag', 'holiday_tag_der_arbeit',\n",
        "    'holiday_tag_der_deutschen_einheit', 'transformed_vacation'\n",
        "    ]\n",
        "\n",
        "# Target is 'imputed_wilhelm_kaisen_brucke_ost'\n",
        "target = target\n",
        "\n",
        "# Higly correlated features have been removed (tavg, tmin, imputed_wpgt)\n",
        "# Features with no correlation have been removed (imputed_wdir, wdir_sin, wdir_cos)\n",
        "# Only all single couting stations are being removed"
      ],
      "metadata": {
        "id": "vZyJeABHuthG",
        "outputId": "3441b58a-ff07-43a5-b004-a3130262f86e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vZyJeABHuthG",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = features_sin_cos_transformation + features_weather + features_holidays_vacation\n",
        "features"
      ],
      "metadata": {
        "id": "BiakefxsxJ7e",
        "outputId": "1ec9d951-4636-4152-f60a-2e597a963778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BiakefxsxJ7e",
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['week_sin',\n",
              " 'week_cos',\n",
              " 'month_sin',\n",
              " 'month_cos',\n",
              " 'year_sin',\n",
              " 'year_cos',\n",
              " 'tmax',\n",
              " 'prcp',\n",
              " 'imputed_snow',\n",
              " 'wspd',\n",
              " 'pres',\n",
              " 'tsun',\n",
              " 'holiday_1_weihnachtsfeiertag',\n",
              " 'holiday_2_weihnachtsfeiertag',\n",
              " 'holiday_christi_himmelfahrt',\n",
              " 'holiday_karfreitag',\n",
              " 'holiday_neujahr',\n",
              " 'holiday_ostermontag',\n",
              " 'holiday_pfingstmontag',\n",
              " 'holiday_reformationstag',\n",
              " 'holiday_tag_der_arbeit',\n",
              " 'holiday_tag_der_deutschen_einheit',\n",
              " 'transformed_vacation']"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "nxeQ39ojh2Y-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxeQ39ojh2Y-",
        "outputId": "083d4ddd-3930-4949-8188-a6b781ce00ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (2921, 23) y_train:  (2921,)\n",
            "X_dev:  (731, 23) y_dev:  (731,)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and dev sets\n",
        "# We set shuffle to False\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(df[features], df[target],\n",
        "                                                    test_size=0.2, shuffle=False, random_state=0)\n",
        "\n",
        "print(\"X_train: \", X_train[features].shape, \"y_train: \", y_train.shape)\n",
        "print(\"X_dev: \", X_dev[features].shape, \"y_dev: \", y_dev.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1GVZoPCdit-",
      "metadata": {
        "id": "a1GVZoPCdit-"
      },
      "source": [
        "Finally, we will standardize our dataset. Standarization will generally improve learning speed of the models and can help to improve the accuarcy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "ZwsuKeAWsUr8"
      },
      "outputs": [],
      "source": [
        "# Standardize and fit to the training set only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the same standardization to the dev set\n",
        "X_dev_scaled = scaler.transform(X_dev)\n",
        "\n",
        "#X_train_scaled = X_train\n",
        "#X_dev_scaled = X_dev"
      ],
      "id": "ZwsuKeAWsUr8"
    },
    {
      "cell_type": "markdown",
      "id": "amR72D-bg9Ea",
      "metadata": {
        "id": "amR72D-bg9Ea"
      },
      "source": [
        "<a name=\"5.2.2\"></a>\n",
        "### 5.2.2 Using GridSeachCV to select the optimal parameters\n",
        "[Content](#content)\n",
        "\n",
        "We will use `GridSearchCV` to select optimal parameters among the preselected ranges for the training data. Furthermore we will create our own scoring metric, to evaluate the performance of the parameters found with `GridSearchCV`.\n",
        "\n",
        "`GridSearchCV` is using `KFold` for regression problems as default. However `KFold` would split the training data in such a way, that later data will be evaluated against earlier data, introducing `leackage error`.\n",
        "Therefore we do not use the default, but create splits with `TimeSeriesSplit` and pass this to `GridSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom function for evaluating GridSearchCV\n",
        "def custom_rmse(y, y_hat):\n",
        "    return np.sqrt(mean_squared_error(y, y_hat))\n",
        "\n",
        "# Create the scoring object using the custom scoring function\n",
        "custom_scorer_rmse = make_scorer(custom_rmse)"
      ],
      "metadata": {
        "id": "TB-c62B8Je2b"
      },
      "id": "TB-c62B8Je2b",
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "248a44d8-1fc5-4bf2-d5f2-428c3e60df94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU0g5nDdCaX4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 162 candidates, totalling 648 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 12, 'n_estimators': 1000, 'reg_alpha': 8.0, 'reg_lambda': 8.0}\n",
            "7136.89129076001\n",
            "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
            "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
            "             min_child_weight=12, missing=nan, monotone_constraints=None,\n",
            "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
            "             predictor=None, random_state=0, ...)\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    'n_estimators': [1000],\n",
        "    'learning_rate': [0.05],\n",
        "    'max_depth': [5, 10, 20],           # max. depth of tree\n",
        "    'min_child_weight': [3, 6, 12],     # min. weight for splitting into new node\n",
        "    'colsample_bytree': [0.7, 0.8],     # subsample ratio of columns\n",
        "    'reg_alpha': [2.0, 4.0, 8.0],       # L1 regularization\n",
        "    'reg_lambda': [4.0, 8.0, 16.0],    # L2 regularization\n",
        "}\n",
        "\n",
        "# Getting time series splits using TimeSeriesSplit\n",
        "n = 4\n",
        "tscv = TimeSeriesSplit(n_splits=n)\n",
        "splits = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(tscv.split(X_train)):\n",
        "    splits.append((train_index, test_index))\n",
        "\n",
        "# Define the estimator\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)\n",
        "\n",
        "# Define GridSearch and fit GridSearch on the training data with the custom scorer and custom splits\n",
        "grid_search = GridSearchCV(xg_reg, param_grid=params, cv=splits, scoring=custom_scorer_rmse, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and score as well as the best model to that score\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)"
      ],
      "id": "dU0g5nDdCaX4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 7, 'n_estimators': 1000, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 1.0}\n"
      ],
      "metadata": {
        "id": "b8nRHJ0YVnGd"
      },
      "id": "b8nRHJ0YVnGd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 13, 'min_child_weight': 5, 'n_estimators': 1000, 'reg_alpha': 7.0, 'reg_lambda': 4.0, 'subsample': 1.0}\n"
      ],
      "metadata": {
        "id": "XLWBhuPRf01z"
      },
      "id": "XLWBhuPRf01z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 12, 'n_estimators': 1000, 'reg_alpha': 8.0, 'reg_lambda': 8.0}\n"
      ],
      "metadata": {
        "id": "PTRgEhqMF0p9"
      },
      "id": "PTRgEhqMF0p9"
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "id": "u9DKLFqkmIRm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9DKLFqkmIRm",
        "outputId": "1f275bda-edb3-406f-a095-e96bf934deb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 820.721704\n",
            "Dev RMSE: 1473.750005\n"
          ]
        }
      ],
      "source": [
        "# Build the XGBoost regressor model with selected hyper parameters\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror',  reg_alpha = 10.0, reg_lambda = 1.0, learning_rate = 0.1)\n",
        "\n",
        "\"\"\", colsample_bytree = 0.5, learning_rate = 0.05,\n",
        "                          max_depth = 8, n_estimators = 1000, reg_alpha = 10.0, reg_lambda = 40.0,\n",
        "                          subsample = 0.8, min_child_weight=5\"\"\"\n",
        "\n",
        "xg_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the train set\n",
        "y_train_hat = xg_reg.predict(X_train_scaled)\n",
        "\n",
        "# Predict on the dev set\n",
        "y_dev_hat = xg_reg.predict(X_dev_scaled)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "# Training set\n",
        "rmse_train = custom_rmse(y_train, y_train_hat)\n",
        "print(\"Train RMSE: %f\" % (rmse_train))\n",
        "\n",
        "# Dev set\n",
        "rmse_dev = custom_rmse(y_dev, y_dev_hat)\n",
        "print(\"Dev RMSE: %f\" % (rmse_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sin and cos\n",
        "Train RMSE: 1019.252085\n",
        "Dev RMSE: 1709.549721\n",
        "\n",
        "date\n",
        "Train RMSE: 1184.215359\n",
        "Dev RMSE: 1761.530727"
      ],
      "metadata": {
        "id": "RH9n4j1XTNFh"
      },
      "id": "RH9n4j1XTNFh"
    },
    {
      "cell_type": "markdown",
      "id": "fOFZ5oXgTT7V",
      "metadata": {
        "id": "fOFZ5oXgTT7V"
      },
      "source": [
        "<a name=\"5.3.\"></a>\n",
        "## 5.3. Multilayer Perceptron\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "CFbCaX6sKhZF",
      "metadata": {
        "id": "CFbCaX6sKhZF",
        "outputId": "0a23f8af-7dd7-4350-df4c-7918e341f27e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_79 (Dense)            (None, 128)               3584      \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,905\n",
            "Trainable params: 11,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 2s 9ms/step - loss: 23088532.0000 - root_mean_squared_error: 4805.0527 - val_loss: 3531288.7500 - val_root_mean_squared_error: 1879.1724\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 2906176.2500 - root_mean_squared_error: 1704.7511 - val_loss: 2996437.0000 - val_root_mean_squared_error: 1731.0220\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 2581666.2500 - root_mean_squared_error: 1606.7565 - val_loss: 2665774.0000 - val_root_mean_squared_error: 1632.7198\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2459620.7500 - root_mean_squared_error: 1568.3177 - val_loss: 2568147.5000 - val_root_mean_squared_error: 1602.5441\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2449901.7500 - root_mean_squared_error: 1565.2162 - val_loss: 2780460.7500 - val_root_mean_squared_error: 1667.4713\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2327202.5000 - root_mean_squared_error: 1525.5171 - val_loss: 2545995.5000 - val_root_mean_squared_error: 1595.6176\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2353126.2500 - root_mean_squared_error: 1533.9904 - val_loss: 2574265.0000 - val_root_mean_squared_error: 1604.4517\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2353417.5000 - root_mean_squared_error: 1534.0852 - val_loss: 2394474.0000 - val_root_mean_squared_error: 1547.4088\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2306785.5000 - root_mean_squared_error: 1518.8105 - val_loss: 2373360.5000 - val_root_mean_squared_error: 1540.5715\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2371109.2500 - root_mean_squared_error: 1539.8407 - val_loss: 2710040.0000 - val_root_mean_squared_error: 1646.2200\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2266220.2500 - root_mean_squared_error: 1505.3971 - val_loss: 2353601.2500 - val_root_mean_squared_error: 1534.1451\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2208305.0000 - root_mean_squared_error: 1486.0366 - val_loss: 2535772.7500 - val_root_mean_squared_error: 1592.4110\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2279066.7500 - root_mean_squared_error: 1509.6578 - val_loss: 2343665.2500 - val_root_mean_squared_error: 1530.9034\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2269879.2500 - root_mean_squared_error: 1506.6118 - val_loss: 2520421.7500 - val_root_mean_squared_error: 1587.5836\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2241388.2500 - root_mean_squared_error: 1497.1267 - val_loss: 2402285.0000 - val_root_mean_squared_error: 1549.9307\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2240866.5000 - root_mean_squared_error: 1496.9524 - val_loss: 2869523.7500 - val_root_mean_squared_error: 1693.9669\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2259248.7500 - root_mean_squared_error: 1503.0797 - val_loss: 2269472.5000 - val_root_mean_squared_error: 1506.4768\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2211455.7500 - root_mean_squared_error: 1487.0964 - val_loss: 2686592.5000 - val_root_mean_squared_error: 1639.0828\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2203818.5000 - root_mean_squared_error: 1484.5264 - val_loss: 2301059.7500 - val_root_mean_squared_error: 1516.9244\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2245369.5000 - root_mean_squared_error: 1498.4557 - val_loss: 2711750.5000 - val_root_mean_squared_error: 1646.7394\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2158246.2500 - root_mean_squared_error: 1469.0970 - val_loss: 2336937.7500 - val_root_mean_squared_error: 1528.7046\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2175456.5000 - root_mean_squared_error: 1474.9429 - val_loss: 2284673.0000 - val_root_mean_squared_error: 1511.5134\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2231379.5000 - root_mean_squared_error: 1493.7803 - val_loss: 2811225.7500 - val_root_mean_squared_error: 1676.6710\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2206711.5000 - root_mean_squared_error: 1485.5004 - val_loss: 2290656.2500 - val_root_mean_squared_error: 1513.4915\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2180228.2500 - root_mean_squared_error: 1476.5596 - val_loss: 2790681.5000 - val_root_mean_squared_error: 1670.5333\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2248444.0000 - root_mean_squared_error: 1499.4812 - val_loss: 2899308.5000 - val_root_mean_squared_error: 1702.7356\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2175893.2500 - root_mean_squared_error: 1475.0909 - val_loss: 2497798.0000 - val_root_mean_squared_error: 1580.4424\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2192366.5000 - root_mean_squared_error: 1480.6642 - val_loss: 2426009.0000 - val_root_mean_squared_error: 1557.5651\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2133201.7500 - root_mean_squared_error: 1460.5485 - val_loss: 2414349.5000 - val_root_mean_squared_error: 1553.8177\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2157871.7500 - root_mean_squared_error: 1468.9696 - val_loss: 2464305.2500 - val_root_mean_squared_error: 1569.8105\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2127491.0000 - root_mean_squared_error: 1458.5922 - val_loss: 2621218.2500 - val_root_mean_squared_error: 1619.0177\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2136516.7500 - root_mean_squared_error: 1461.6829 - val_loss: 2255731.5000 - val_root_mean_squared_error: 1501.9093\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2083923.6250 - root_mean_squared_error: 1443.5802 - val_loss: 2368769.5000 - val_root_mean_squared_error: 1539.0807\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2131572.0000 - root_mean_squared_error: 1459.9904 - val_loss: 2283454.7500 - val_root_mean_squared_error: 1511.1105\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2107196.5000 - root_mean_squared_error: 1451.6185 - val_loss: 2306615.2500 - val_root_mean_squared_error: 1518.7545\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2152197.7500 - root_mean_squared_error: 1467.0371 - val_loss: 2469699.5000 - val_root_mean_squared_error: 1571.5277\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2128172.7500 - root_mean_squared_error: 1458.8258 - val_loss: 2707755.2500 - val_root_mean_squared_error: 1645.5259\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2175921.0000 - root_mean_squared_error: 1475.1003 - val_loss: 2369799.5000 - val_root_mean_squared_error: 1539.4153\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2106107.2500 - root_mean_squared_error: 1451.2433 - val_loss: 2543543.2500 - val_root_mean_squared_error: 1594.8490\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2163980.0000 - root_mean_squared_error: 1471.0472 - val_loss: 3087407.0000 - val_root_mean_squared_error: 1757.1019\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2135477.5000 - root_mean_squared_error: 1461.3273 - val_loss: 2661014.0000 - val_root_mean_squared_error: 1631.2615\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 2113523.2500 - root_mean_squared_error: 1453.7961 - val_loss: 2667324.2500 - val_root_mean_squared_error: 1633.1945\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2153936.7500 - root_mean_squared_error: 1467.6296 - val_loss: 2739861.0000 - val_root_mean_squared_error: 1655.2526\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2119626.0000 - root_mean_squared_error: 1455.8936 - val_loss: 2450072.7500 - val_root_mean_squared_error: 1565.2709\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2192296.2500 - root_mean_squared_error: 1480.6405 - val_loss: 2349139.2500 - val_root_mean_squared_error: 1532.6902\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2112223.5000 - root_mean_squared_error: 1453.3491 - val_loss: 2340343.0000 - val_root_mean_squared_error: 1529.8180\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2152626.2500 - root_mean_squared_error: 1467.1831 - val_loss: 2738406.5000 - val_root_mean_squared_error: 1654.8131\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2070306.2500 - root_mean_squared_error: 1438.8558 - val_loss: 2333272.0000 - val_root_mean_squared_error: 1527.5051\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2139173.7500 - root_mean_squared_error: 1462.5914 - val_loss: 2290264.5000 - val_root_mean_squared_error: 1513.3619\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2068566.1250 - root_mean_squared_error: 1438.2511 - val_loss: 2544891.0000 - val_root_mean_squared_error: 1595.2715\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2119705.5000 - root_mean_squared_error: 1455.9209 - val_loss: 2471678.2500 - val_root_mean_squared_error: 1572.1572\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2040743.8750 - root_mean_squared_error: 1428.5460 - val_loss: 2504271.0000 - val_root_mean_squared_error: 1582.4889\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2093546.1250 - root_mean_squared_error: 1446.9092 - val_loss: 2624571.5000 - val_root_mean_squared_error: 1620.0530\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2080779.6250 - root_mean_squared_error: 1442.4907 - val_loss: 2455628.7500 - val_root_mean_squared_error: 1567.0446\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2043873.8750 - root_mean_squared_error: 1429.6411 - val_loss: 2525268.0000 - val_root_mean_squared_error: 1589.1091\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2105453.0000 - root_mean_squared_error: 1451.0179 - val_loss: 2363617.0000 - val_root_mean_squared_error: 1537.4059\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2122548.2500 - root_mean_squared_error: 1456.8967 - val_loss: 2643137.7500 - val_root_mean_squared_error: 1625.7729\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2030837.7500 - root_mean_squared_error: 1425.0747 - val_loss: 2322713.0000 - val_root_mean_squared_error: 1524.0449\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2087793.6250 - root_mean_squared_error: 1444.9199 - val_loss: 2907601.5000 - val_root_mean_squared_error: 1705.1691\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2109712.5000 - root_mean_squared_error: 1452.4850 - val_loss: 2622957.2500 - val_root_mean_squared_error: 1619.5547\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2054379.0000 - root_mean_squared_error: 1433.3105 - val_loss: 2466956.7500 - val_root_mean_squared_error: 1570.6549\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2136398.7500 - root_mean_squared_error: 1461.6425 - val_loss: 2270862.2500 - val_root_mean_squared_error: 1506.9380\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2007024.7500 - root_mean_squared_error: 1416.6951 - val_loss: 2583502.0000 - val_root_mean_squared_error: 1607.3276\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2119740.0000 - root_mean_squared_error: 1455.9327 - val_loss: 2415130.2500 - val_root_mean_squared_error: 1554.0690\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2147045.2500 - root_mean_squared_error: 1465.2799 - val_loss: 2770751.2500 - val_root_mean_squared_error: 1664.5574\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2076591.0000 - root_mean_squared_error: 1441.0382 - val_loss: 2412633.5000 - val_root_mean_squared_error: 1553.2654\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2080550.0000 - root_mean_squared_error: 1442.4111 - val_loss: 2601831.2500 - val_root_mean_squared_error: 1613.0193\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2040874.2500 - root_mean_squared_error: 1428.5917 - val_loss: 2674445.0000 - val_root_mean_squared_error: 1635.3730\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2098502.7500 - root_mean_squared_error: 1448.6210 - val_loss: 2638690.0000 - val_root_mean_squared_error: 1624.4045\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2075853.2500 - root_mean_squared_error: 1440.7822 - val_loss: 2473564.2500 - val_root_mean_squared_error: 1572.7568\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2069033.3750 - root_mean_squared_error: 1438.4135 - val_loss: 2523396.7500 - val_root_mean_squared_error: 1588.5203\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2096882.6250 - root_mean_squared_error: 1448.0616 - val_loss: 2700362.7500 - val_root_mean_squared_error: 1643.2781\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2063991.8750 - root_mean_squared_error: 1436.6599 - val_loss: 2303582.5000 - val_root_mean_squared_error: 1517.7557\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2039833.3750 - root_mean_squared_error: 1428.2273 - val_loss: 2899103.7500 - val_root_mean_squared_error: 1702.6754\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2045655.7500 - root_mean_squared_error: 1430.2643 - val_loss: 2476892.7500 - val_root_mean_squared_error: 1573.8147\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2026176.7500 - root_mean_squared_error: 1423.4384 - val_loss: 2822454.0000 - val_root_mean_squared_error: 1680.0161\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2039512.6250 - root_mean_squared_error: 1428.1151 - val_loss: 2440272.7500 - val_root_mean_squared_error: 1562.1372\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2097068.3750 - root_mean_squared_error: 1448.1259 - val_loss: 2915946.2500 - val_root_mean_squared_error: 1707.6143\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2064011.5000 - root_mean_squared_error: 1436.6667 - val_loss: 2379640.0000 - val_root_mean_squared_error: 1542.6082\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2002023.2500 - root_mean_squared_error: 1414.9287 - val_loss: 2520303.2500 - val_root_mean_squared_error: 1587.5463\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2043772.2500 - root_mean_squared_error: 1429.6056 - val_loss: 2602505.0000 - val_root_mean_squared_error: 1613.2281\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 2021706.2500 - root_mean_squared_error: 1421.8672 - val_loss: 2536077.2500 - val_root_mean_squared_error: 1592.5066\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2055457.0000 - root_mean_squared_error: 1433.6865 - val_loss: 2297193.5000 - val_root_mean_squared_error: 1515.6495\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2150200.2500 - root_mean_squared_error: 1466.3561 - val_loss: 2541761.5000 - val_root_mean_squared_error: 1594.2903\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2065046.3750 - root_mean_squared_error: 1437.0270 - val_loss: 2467777.7500 - val_root_mean_squared_error: 1570.9163\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2060956.1250 - root_mean_squared_error: 1435.6030 - val_loss: 2342206.7500 - val_root_mean_squared_error: 1530.4270\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1959883.1250 - root_mean_squared_error: 1399.9583 - val_loss: 2564088.7500 - val_root_mean_squared_error: 1601.2772\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2040390.5000 - root_mean_squared_error: 1428.4224 - val_loss: 2655866.7500 - val_root_mean_squared_error: 1629.6830\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2009986.0000 - root_mean_squared_error: 1417.7397 - val_loss: 2269413.5000 - val_root_mean_squared_error: 1506.4573\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2036528.8750 - root_mean_squared_error: 1427.0701 - val_loss: 2796501.0000 - val_root_mean_squared_error: 1672.2742\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2061290.6250 - root_mean_squared_error: 1435.7196 - val_loss: 2596204.7500 - val_root_mean_squared_error: 1611.2743\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2060158.6250 - root_mean_squared_error: 1435.3253 - val_loss: 2426312.2500 - val_root_mean_squared_error: 1557.6625\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1980086.8750 - root_mean_squared_error: 1407.1556 - val_loss: 2652789.5000 - val_root_mean_squared_error: 1628.7386\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2074345.0000 - root_mean_squared_error: 1440.2587 - val_loss: 2497965.0000 - val_root_mean_squared_error: 1580.4951\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2052575.8750 - root_mean_squared_error: 1432.6814 - val_loss: 2583572.0000 - val_root_mean_squared_error: 1607.3494\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 1999380.3750 - root_mean_squared_error: 1413.9945 - val_loss: 3172764.5000 - val_root_mean_squared_error: 1781.2256\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2028000.7500 - root_mean_squared_error: 1424.0789 - val_loss: 2683477.7500 - val_root_mean_squared_error: 1638.1324\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2052598.7500 - root_mean_squared_error: 1432.6893 - val_loss: 2784665.0000 - val_root_mean_squared_error: 1668.7316\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 2074003.5000 - root_mean_squared_error: 1440.1401 - val_loss: 2555180.7500 - val_root_mean_squared_error: 1598.4933\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 2045305.7500 - root_mean_squared_error: 1430.1418 - val_loss: 2629459.5000 - val_root_mean_squared_error: 1621.5608\n"
          ]
        }
      ],
      "source": [
        "dropout = 0.2 # 0.2 best\n",
        "\n",
        "# Define the architecture of the MLP with L2 regularization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(len(features),)))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(units=1, activation='linear'))  # Output layer with 1 neuron for regression\n",
        "\n",
        "# Compile the model with mean squared error (MSE) loss, and root mean square error (RMSE) as metric\n",
        "# Use Adam optimizer with learning rate\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model and save the learning history, use x_dev and y_dev for validation\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_dev_scaled, y_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "all features with cos and sin\n",
        "Epoch 100/100\n",
        "92/92 [==============================] - 0s 3ms/step - loss: 2264314.0000 - root_mean_squared_error: 1504.7638 - val_loss: 2452808.2500 - val_root_mean_squared_error: 1566.1444"
      ],
      "metadata": {
        "id": "60pDB98PVm1I"
      },
      "id": "60pDB98PVm1I"
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "RhbEPgSPsXCy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "RhbEPgSPsXCy",
        "outputId": "2d5b5e24-d4b9-4f39-8bd2-df736e76ee2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9163feae-ad0c-4f54-822c-3024d5880570\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9163feae-ad0c-4f54-822c-3024d5880570\")) {                    Plotly.newPlot(                        \"9163feae-ad0c-4f54-822c-3024d5880570\",                        [{\"hovertemplate\":\"\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"mode\":\"lines+markers\",\"name\":\"Train RMSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[4805.052734375,1704.7510986328125,1606.7564697265625,1568.3177490234375,1565.2161865234375,1525.51708984375,1533.9903564453125,1534.085205078125,1518.810546875,1539.8406982421875,1505.3970947265625,1486.03662109375,1509.6578369140625,1506.61181640625,1497.126708984375,1496.952392578125,1503.0797119140625,1487.096435546875,1484.5263671875,1498.4556884765625,1469.0970458984375,1474.94287109375,1493.7802734375,1485.5003662109375,1476.5595703125,1499.481201171875,1475.0909423828125,1480.6641845703125,1460.5484619140625,1468.9696044921875,1458.5921630859375,1461.682861328125,1443.5802001953125,1459.9903564453125,1451.6185302734375,1467.037109375,1458.8258056640625,1475.100341796875,1451.2432861328125,1471.0472412109375,1461.3272705078125,1453.796142578125,1467.629638671875,1455.8935546875,1480.6405029296875,1453.34912109375,1467.18310546875,1438.8558349609375,1462.5914306640625,1438.2510986328125,1455.9208984375,1428.5460205078125,1446.9091796875,1442.49072265625,1429.64111328125,1451.0179443359375,1456.896728515625,1425.07470703125,1444.919921875,1452.4849853515625,1433.310546875,1461.6424560546875,1416.695068359375,1455.9327392578125,1465.2799072265625,1441.0382080078125,1442.4111328125,1428.5916748046875,1448.6209716796875,1440.7822265625,1438.4134521484375,1448.0616455078125,1436.659912109375,1428.227294921875,1430.2642822265625,1423.4383544921875,1428.1151123046875,1448.1258544921875,1436.666748046875,1414.9287109375,1429.6055908203125,1421.8671875,1433.6865234375,1466.3560791015625,1437.0269775390625,1435.60302734375,1399.958251953125,1428.42236328125,1417.73974609375,1427.070068359375,1435.7196044921875,1435.3253173828125,1407.1556396484375,1440.2586669921875,1432.681396484375,1413.9945068359375,1424.078857421875,1432.6893310546875,1440.14013671875,1430.141845703125],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Dev RMSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[1879.17236328125,1731.02197265625,1632.7198486328125,1602.5440673828125,1667.4713134765625,1595.6175537109375,1604.45166015625,1547.4088134765625,1540.571533203125,1646.219970703125,1534.1451416015625,1592.4110107421875,1530.9034423828125,1587.5836181640625,1549.9306640625,1693.9669189453125,1506.476806640625,1639.082763671875,1516.9244384765625,1646.7393798828125,1528.70458984375,1511.513427734375,1676.6710205078125,1513.491455078125,1670.5333251953125,1702.735595703125,1580.4423828125,1557.5650634765625,1553.8177490234375,1569.810546875,1619.0177001953125,1501.9093017578125,1539.0806884765625,1511.1104736328125,1518.7545166015625,1571.5277099609375,1645.52587890625,1539.415283203125,1594.8489990234375,1757.1019287109375,1631.261474609375,1633.1944580078125,1655.2525634765625,1565.2708740234375,1532.690185546875,1529.8179931640625,1654.8131103515625,1527.505126953125,1513.3619384765625,1595.271484375,1572.1572265625,1582.4888916015625,1620.052978515625,1567.0445556640625,1589.109130859375,1537.4058837890625,1625.77294921875,1524.044921875,1705.1690673828125,1619.5546875,1570.6549072265625,1506.93798828125,1607.32763671875,1554.0689697265625,1664.557373046875,1553.265380859375,1613.019287109375,1635.373046875,1624.404541015625,1572.7568359375,1588.520263671875,1643.278076171875,1517.7557373046875,1702.6754150390625,1573.814697265625,1680.01611328125,1562.13720703125,1707.6142578125,1542.608154296875,1587.5462646484375,1613.2281494140625,1592.506591796875,1515.6495361328125,1594.290283203125,1570.916259765625,1530.427001953125,1601.2772216796875,1629.6829833984375,1506.457275390625,1672.274169921875,1611.2742919921875,1557.6624755859375,1628.7386474609375,1580.4951171875,1607.349365234375,1781.2255859375,1638.1324462890625,1668.7315673828125,1598.4932861328125,1621.560791015625],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"RMSE\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"train RMSE vs. dev RMSE\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9163feae-ad0c-4f54-822c-3024d5880570');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create the array for the x axis, starting from 1\n",
        "epochs = np.arange(1, len(history.history[\"root_mean_squared_error\"])+1)\n",
        "train_rmse = history.history[\"root_mean_squared_error\"]\n",
        "dev_rmse = history.history[\"val_root_mean_squared_error\"]\n",
        "\n",
        "# Create a line chart with two lines using Plotly Express\n",
        "fig = px.line(title='train RMSE vs. dev RMSE')\n",
        "fig.add_scatter(x=epochs, y=train_rmse, mode='lines+markers', name='Train RMSE', line=dict(color='red'))\n",
        "fig.add_scatter(x=epochs, y=dev_rmse, mode='lines+markers', name='Dev RMSE', line=dict(color='blue'))\n",
        "\n",
        "\n",
        "# Set chart title and axis labels\n",
        "fig.update_layout(\n",
        "    xaxis_title='Epochs',\n",
        "    yaxis_title='RMSE'\n",
        ")\n",
        "\n",
        "# Show the chart\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qg2TMtxJUzVm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg2TMtxJUzVm",
        "outputId": "27112e65-201e-42f1-927e-bf8c20614373"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "92/92 [==============================] - 1s 10ms/step\n",
            "Trai RMSE: 2623.097985\n",
            "23/23 [==============================] - 0s 8ms/step\n",
            "Test RMSE: 8387.871121\n"
          ]
        }
      ],
      "source": [
        "preds_train = model.predict(X_train_scaled)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, preds_train))\n",
        "print(\"Trai RMSE: %f\" % (rmse_train))\n",
        "\n",
        "preds_dev = model.predict(x_dev_scaled)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "rmse_dev = np.sqrt(mean_squared_error(y_dev, preds_dev))\n",
        "print(\"Dev RMSE: %f\" % (rmse_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35YvxR1B1tcY",
      "metadata": {
        "id": "35YvxR1B1tcY"
      },
      "source": [
        "<a name=\"5.4.\"></a>\n",
        "## 5.4. Recurrent Neural Network\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we train an RNN to compare to the previous two models. A RNN can take in multiple timesteps, to make a prediction (Many-to-One). Specifically, we will feed in 4 timesteps at a time (current day and the 3 previous days) and output the prediction of the current day.\n",
        "\n",
        "Out input shape is therefore (none, 4, 21), where none represents a variable amount of training days (in our case the length of X_train)."
      ],
      "metadata": {
        "id": "sfs0s3ZGC9Wp"
      },
      "id": "sfs0s3ZGC9Wp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J7cPlQdTzEmQ",
      "metadata": {
        "id": "J7cPlQdTzEmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70daad21-ab50-4170-b52d-3b264b8d7c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['year', 'month', 'day', 'weekday', 'tmax', 'prcp', 'snow', 'wspd', 'pres', 'tsun', 'vacation', 'holiday_1_weihnachtsfeiertag', 'holiday_2_weihnachtsfeiertag', 'holiday_christi_himmelfahrt', 'holiday_karfreitag', 'holiday_neujahr', 'holiday_ostermontag', 'holiday_pfingstmontag', 'holiday_reformationstag', 'holiday_tag_der_arbeit', 'holiday_tag_der_deutschen_einheit']\n",
            "(2921, 21)\n",
            "(2921, 1)\n",
            "(731, 21)\n",
            "(731, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Load the data into a pandas dataframe\n",
        "data = df_transformed_date\n",
        "\n",
        "# Define the features and target\n",
        "# Higly correlated features have been removed (tavg, tmin, wpgt)\n",
        "# Features with no correlation have been removed (wdir)\n",
        "# Only all single couting stations are being removed\n",
        "features = [feature for feature in data.columns if feature not in [\"tavg\", \"tmin\", \"wpgt\", \"wdir\",\n",
        "                                                                    'graf_moltke_straße_ostseite', 'graf_moltke_straße_westseite',\n",
        "                                                                    'hastedter_bruckenstraße', 'langemarckstraße_ostseite',\n",
        "                                                                    'langemarckstraße_westseite', 'osterdeich', 'radweg_kleine_weser',\n",
        "                                                                    'schwachhauser_ring', 'wachmannstraße_auswarts_sud',\n",
        "                                                                    'wachmannstraße_einwarts_nord', 'wilhelm_kaisen_brucke_ost',\n",
        "                                                                    'wilhelm_kaisen_brucke_west', 'total']]\n",
        "target = ['total']\n",
        "\n",
        "print(features)\n",
        "\n",
        "# Split the data into training and dev sets\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(data[features], data[target],\n",
        "                                                    test_size=0.2, shuffle=False, random_state=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_dev.shape)\n",
        "print(y_dev.shape)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import timeseries_dataset_from_array\n",
        "\n",
        "input_data = X_train\n",
        "#targets = y_train[3:]\n",
        "targets = y_train\n",
        "dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data=input_data, targets=targets, sequence_length=4, batch_size=None, shuffle=False)\n",
        "\n",
        "\n",
        "#print(dataset.take(10))\n",
        "\n",
        "for x,y in dataset.take(1):\n",
        "    print(x, y)\n",
        "\"\"\"\n",
        "\n",
        "#for x, y in dataset.take(10):\n",
        "#    print(x, y)\n",
        "\n",
        "y_trainnnn = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data=targets, targets=None, sequence_length=4, batch_size=None, shuffle=False)\n",
        "\n",
        "\n",
        "for y in y_trainnnn.take(10):\n",
        "    print(y)\n",
        "\n",
        "x_trainnnn.to_numpy()\"\"\"\n"
      ],
      "metadata": {
        "id": "vzzhZEanaiIt",
        "outputId": "5dd6d8dd-fbb9-483c-f3ce-0a620de43517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "id": "vzzhZEanaiIt",
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 7.81831482e-01  6.23489802e-01  2.01298520e-01  9.79529941e-01\n",
            "   1.72133562e-02  9.99851839e-01  9.10000000e+00  6.90000000e+00\n",
            "   0.00000000e+00  1.94000000e+01  1.00180000e+03  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
            " [ 9.74927912e-01 -2.22520934e-01  3.94355855e-01  9.18957812e-01\n",
            "   3.44216116e-02  9.99407401e-01  7.10000000e+00  1.80000000e+00\n",
            "   0.00000000e+00  2.02000000e+01  1.01750000e+03  3.00000000e+01\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
            " [ 4.33883739e-01 -9.00968868e-01  5.71268215e-01  8.20763441e-01\n",
            "   5.16196672e-02  9.98666816e-01  1.06000000e+01  9.00000000e-01\n",
            "   0.00000000e+00  2.38000000e+01  1.02450000e+03  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  1.00000000e+00]\n",
            " [-4.33883739e-01 -9.00968868e-01  7.24792787e-01  6.88966919e-01\n",
            "   6.88024268e-02  9.97630305e-01  9.70000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  2.52000000e+01  1.02950000e+03  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  1.00000000e+00]], shape=(4, 23), dtype=float64) tf.Tensor(1228.0, shape=(), dtype=float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n#for x, y in dataset.take(10):\\n#    print(x, y)\\n\\ny_trainnnn = tf.keras.utils.timeseries_dataset_from_array(\\n    data=targets, targets=None, sequence_length=4, batch_size=None, shuffle=False)\\n\\n\\nfor y in y_trainnnn.take(10):\\n    print(y)\\n\\nx_trainnnn.to_numpy()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbcfecb9-fa5d-448f-b654-204e76c36108",
        "id": "lI1NinnLJ1tc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Standardize and fit to the training set only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the same standardization to the dev set\n",
        "X_dev_scaled = scaler.transform(X_dev)\n",
        "\n",
        "#X_train_scaled = X_train\n",
        "#_dev_scaled = X_dev"
      ],
      "id": "lI1NinnLJ1tc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of timesteps\n",
        "timesteps = 4\n",
        "\n",
        "# Step 1: Create sequences of length 4\n",
        "X_train_scaled_3d, X_dev_scaled_3d = [], []\n",
        "y_train_3d, y_dev_3d = [], []\n",
        "\n",
        "for i in range(len(X_train_scaled) - timesteps + 1):\n",
        "    X_train_scaled_3d.append(X_train_scaled[i : i + timesteps])\n",
        "    y_train_3d.append(y_train[i : i + timesteps])\n",
        "\n",
        "X_train_scaled_3d = np.array(X_train_scaled_3d)\n",
        "#y_train = y_train [timesteps-1:]\n",
        "y_train_3d = np.array(y_train_3d)\n",
        "#y_train_3d = np.expand_dims(y_train_3d, axis=2)\n",
        "\n",
        "for i in range(len(X_dev_scaled) - timesteps + 1):\n",
        "    X_dev_scaled_3d.append(X_dev_scaled[i : i + timesteps])\n",
        "    y_dev_3d.append(y_dev[i : i + timesteps])\n",
        "\n",
        "X_dev_scaled_3d = np.array(X_dev_scaled_3d)\n",
        "#y_dev = y_dev [timesteps-1:]\n",
        "y_dev_3d = np.array(y_dev_3d)\n",
        "#y_dev_3d = np.expand_dims(y_dev_3d, axis=2)\n",
        "\n",
        "print(X_train_scaled_3d.shape)\n",
        "#print(y_train.shape)\n",
        "print(y_train_3d.shape)\n",
        "\n",
        "print(X_dev_scaled_3d.shape)\n",
        "#print(y_dev.shape)\n",
        "print(y_dev_3d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG3uW6OfVD4n",
        "outputId": "c1ce7b34-f4c6-4eb2-d67b-7bd9e6fc5068"
      },
      "id": "jG3uW6OfVD4n",
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2918, 4, 23)\n",
            "(2918, 4)\n",
            "(728, 4, 23)\n",
            "(728, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled_3d.shape)\n",
        "X_train_scaled_3d[0]"
      ],
      "metadata": {
        "id": "rtg30jVKrzsI",
        "outputId": "349eb17a-e89f-4317-df3e-7201455a2ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rtg30jVKrzsI",
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2921, 1, 23)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.10461413,  0.8817232 ,  0.28024778,  1.42493607,  0.02433919,\n",
              "         1.41327836, -0.71259085,  1.45245197, -0.13112669,  0.67096715,\n",
              "        -1.40081458, -1.06115073, -0.05240524, -0.05240524, -0.05240524,\n",
              "        -0.05240524, 19.08205964, -0.05240524, -0.05240524, -0.03703069,\n",
              "        -0.05240524, -0.05240524,  1.73086569]])"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_3d.shape)\n",
        "y_train_3d[0]"
      ],
      "metadata": {
        "id": "JehbnWBGsArT",
        "outputId": "3e9e4b9e-2383-4753-b1f7-f4957dee28fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JehbnWBGsArT",
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2921, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1228.])"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_y = np.expand_dims(y_train_3d,axis=2)\n",
        "print(testing_y.shape)\n",
        "testing_y[0:2]"
      ],
      "metadata": {
        "id": "Gg4umzElpUFh"
      },
      "id": "Gg4umzElpUFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled_3d[0:2])\n",
        "print(y_train_3d[0:2])"
      ],
      "metadata": {
        "id": "2tfeCnmzdXW4"
      },
      "id": "2tfeCnmzdXW4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "id": "sOTf5esj1181",
      "metadata": {
        "id": "sOTf5esj1181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034e2086-b3c3-42b6-ceba-2d44ee77ae2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_57 (InputLayer)       [(None, 4, 23)]           0         \n",
            "                                                                 \n",
            " bidirectional_14 (Bidirecti  (None, 4, 128)           45056     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_15 (Bidirecti  (None, 4, 64)            41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 4, 1)              65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86,337\n",
            "Trainable params: 86,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "92/92 [==============================] - 18s 58ms/step - loss: 34166780.0000 - root_mean_squared_error: 5845.2358 - val_loss: 12901031.0000 - val_root_mean_squared_error: 3591.8005\n",
            "Epoch 2/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 8221441.0000 - root_mean_squared_error: 2867.3054 - val_loss: 7142027.5000 - val_root_mean_squared_error: 2672.4573\n",
            "Epoch 3/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 4799138.0000 - root_mean_squared_error: 2190.6934 - val_loss: 5318239.5000 - val_root_mean_squared_error: 2306.1309\n",
            "Epoch 4/200\n",
            "92/92 [==============================] - 2s 27ms/step - loss: 4021350.5000 - root_mean_squared_error: 2005.3306 - val_loss: 5084012.5000 - val_root_mean_squared_error: 2254.7754\n",
            "Epoch 5/200\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 3860798.0000 - root_mean_squared_error: 1964.8914 - val_loss: 4168547.2500 - val_root_mean_squared_error: 2041.7020\n",
            "Epoch 6/200\n",
            "92/92 [==============================] - 4s 39ms/step - loss: 3761429.5000 - root_mean_squared_error: 1939.4406 - val_loss: 4572766.5000 - val_root_mean_squared_error: 2138.4028\n",
            "Epoch 7/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 3737653.2500 - root_mean_squared_error: 1933.3011 - val_loss: 4049235.7500 - val_root_mean_squared_error: 2012.2712\n",
            "Epoch 8/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3588222.2500 - root_mean_squared_error: 1894.2604 - val_loss: 3892606.5000 - val_root_mean_squared_error: 1972.9690\n",
            "Epoch 9/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 3527170.0000 - root_mean_squared_error: 1878.0760 - val_loss: 3846572.2500 - val_root_mean_squared_error: 1961.2681\n",
            "Epoch 10/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 3454373.7500 - root_mean_squared_error: 1858.5946 - val_loss: 4105302.7500 - val_root_mean_squared_error: 2026.1547\n",
            "Epoch 11/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 3359411.2500 - root_mean_squared_error: 1832.8696 - val_loss: 3842061.2500 - val_root_mean_squared_error: 1960.1177\n",
            "Epoch 12/200\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 3400360.0000 - root_mean_squared_error: 1844.0065 - val_loss: 3741291.5000 - val_root_mean_squared_error: 1934.2418\n",
            "Epoch 13/200\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 3368756.5000 - root_mean_squared_error: 1835.4172 - val_loss: 3669755.5000 - val_root_mean_squared_error: 1915.6606\n",
            "Epoch 14/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 3260183.2500 - root_mean_squared_error: 1805.5978 - val_loss: 3680837.2500 - val_root_mean_squared_error: 1918.5508\n",
            "Epoch 15/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 3245129.7500 - root_mean_squared_error: 1801.4242 - val_loss: 3521054.2500 - val_root_mean_squared_error: 1876.4473\n",
            "Epoch 16/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3267589.5000 - root_mean_squared_error: 1807.6476 - val_loss: 3473132.2500 - val_root_mean_squared_error: 1863.6343\n",
            "Epoch 17/200\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 3248142.0000 - root_mean_squared_error: 1802.2603 - val_loss: 3640918.2500 - val_root_mean_squared_error: 1908.1190\n",
            "Epoch 18/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 3223195.0000 - root_mean_squared_error: 1795.3259 - val_loss: 3694856.0000 - val_root_mean_squared_error: 1922.2009\n",
            "Epoch 19/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 3169602.7500 - root_mean_squared_error: 1780.3378 - val_loss: 3478294.2500 - val_root_mean_squared_error: 1865.0186\n",
            "Epoch 20/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 3135078.0000 - root_mean_squared_error: 1770.6152 - val_loss: 3727359.7500 - val_root_mean_squared_error: 1930.6370\n",
            "Epoch 21/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 3151685.2500 - root_mean_squared_error: 1775.2986 - val_loss: 3449447.5000 - val_root_mean_squared_error: 1857.2689\n",
            "Epoch 22/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 3105163.5000 - root_mean_squared_error: 1762.1475 - val_loss: 3476597.0000 - val_root_mean_squared_error: 1864.5635\n",
            "Epoch 23/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 3159638.2500 - root_mean_squared_error: 1777.5372 - val_loss: 3811335.5000 - val_root_mean_squared_error: 1952.2642\n",
            "Epoch 24/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 3166973.7500 - root_mean_squared_error: 1779.5994 - val_loss: 3177078.2500 - val_root_mean_squared_error: 1782.4360\n",
            "Epoch 25/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 3068720.2500 - root_mean_squared_error: 1751.7764 - val_loss: 3462498.0000 - val_root_mean_squared_error: 1860.7788\n",
            "Epoch 26/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 3058767.2500 - root_mean_squared_error: 1748.9331 - val_loss: 3212833.5000 - val_root_mean_squared_error: 1792.4380\n",
            "Epoch 27/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 3092897.0000 - root_mean_squared_error: 1758.6635 - val_loss: 3279014.7500 - val_root_mean_squared_error: 1810.8051\n",
            "Epoch 28/200\n",
            "92/92 [==============================] - 2s 16ms/step - loss: 2987368.0000 - root_mean_squared_error: 1728.4004 - val_loss: 3319003.7500 - val_root_mean_squared_error: 1821.8134\n",
            "Epoch 29/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 3011240.0000 - root_mean_squared_error: 1735.2925 - val_loss: 3629000.7500 - val_root_mean_squared_error: 1904.9937\n",
            "Epoch 30/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 3031820.7500 - root_mean_squared_error: 1741.2124 - val_loss: 3212489.2500 - val_root_mean_squared_error: 1792.3419\n",
            "Epoch 31/200\n",
            "92/92 [==============================] - 3s 27ms/step - loss: 2964375.7500 - root_mean_squared_error: 1721.7362 - val_loss: 3266220.7500 - val_root_mean_squared_error: 1807.2689\n",
            "Epoch 32/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2962866.7500 - root_mean_squared_error: 1721.2980 - val_loss: 3388950.5000 - val_root_mean_squared_error: 1840.9103\n",
            "Epoch 33/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2884448.2500 - root_mean_squared_error: 1698.3663 - val_loss: 3269555.7500 - val_root_mean_squared_error: 1808.1912\n",
            "Epoch 34/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 2949209.2500 - root_mean_squared_error: 1717.3263 - val_loss: 3539646.2500 - val_root_mean_squared_error: 1881.3948\n",
            "Epoch 35/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2984295.2500 - root_mean_squared_error: 1727.5112 - val_loss: 3295119.5000 - val_root_mean_squared_error: 1815.2465\n",
            "Epoch 36/200\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 2939745.0000 - root_mean_squared_error: 1714.5685 - val_loss: 3074414.5000 - val_root_mean_squared_error: 1753.4009\n",
            "Epoch 37/200\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 2928189.7500 - root_mean_squared_error: 1711.1954 - val_loss: 3436793.7500 - val_root_mean_squared_error: 1853.8591\n",
            "Epoch 38/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2886358.5000 - root_mean_squared_error: 1698.9286 - val_loss: 3087169.7500 - val_root_mean_squared_error: 1757.0343\n",
            "Epoch 39/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 2849434.0000 - root_mean_squared_error: 1688.0266 - val_loss: 3163090.7500 - val_root_mean_squared_error: 1778.5081\n",
            "Epoch 40/200\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 2869667.0000 - root_mean_squared_error: 1694.0092 - val_loss: 3149642.5000 - val_root_mean_squared_error: 1774.7233\n",
            "Epoch 41/200\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 2857587.0000 - root_mean_squared_error: 1690.4399 - val_loss: 3178851.2500 - val_root_mean_squared_error: 1782.9333\n",
            "Epoch 42/200\n",
            "92/92 [==============================] - 4s 43ms/step - loss: 2809485.7500 - root_mean_squared_error: 1676.1521 - val_loss: 3444566.5000 - val_root_mean_squared_error: 1855.9543\n",
            "Epoch 43/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2783144.2500 - root_mean_squared_error: 1668.2758 - val_loss: 3314186.2500 - val_root_mean_squared_error: 1820.4907\n",
            "Epoch 44/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 2839940.0000 - root_mean_squared_error: 1685.2122 - val_loss: 3547989.7500 - val_root_mean_squared_error: 1883.6108\n",
            "Epoch 45/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 2778785.0000 - root_mean_squared_error: 1666.9688 - val_loss: 3225496.0000 - val_root_mean_squared_error: 1795.9666\n",
            "Epoch 46/200\n",
            "92/92 [==============================] - 4s 41ms/step - loss: 2789532.0000 - root_mean_squared_error: 1670.1891 - val_loss: 3106121.5000 - val_root_mean_squared_error: 1762.4192\n",
            "Epoch 47/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 2762989.0000 - root_mean_squared_error: 1662.2241 - val_loss: 3467673.7500 - val_root_mean_squared_error: 1862.1691\n",
            "Epoch 48/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2738701.7500 - root_mean_squared_error: 1654.9022 - val_loss: 3556493.0000 - val_root_mean_squared_error: 1885.8667\n",
            "Epoch 49/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2757087.2500 - root_mean_squared_error: 1660.4479 - val_loss: 2990301.5000 - val_root_mean_squared_error: 1729.2488\n",
            "Epoch 50/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 2750730.0000 - root_mean_squared_error: 1658.5323 - val_loss: 3107657.7500 - val_root_mean_squared_error: 1762.8550\n",
            "Epoch 51/200\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 2709451.2500 - root_mean_squared_error: 1646.0411 - val_loss: 3217559.5000 - val_root_mean_squared_error: 1793.7557\n",
            "Epoch 52/200\n",
            "92/92 [==============================] - 2s 27ms/step - loss: 2680766.2500 - root_mean_squared_error: 1637.3046 - val_loss: 3117027.7500 - val_root_mean_squared_error: 1765.5106\n",
            "Epoch 53/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2846193.0000 - root_mean_squared_error: 1687.0664 - val_loss: 3131959.5000 - val_root_mean_squared_error: 1769.7343\n",
            "Epoch 54/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2821062.7500 - root_mean_squared_error: 1679.6021 - val_loss: 2946839.7500 - val_root_mean_squared_error: 1716.6362\n",
            "Epoch 55/200\n",
            "92/92 [==============================] - 2s 16ms/step - loss: 2719899.7500 - root_mean_squared_error: 1649.2119 - val_loss: 3049848.0000 - val_root_mean_squared_error: 1746.3813\n",
            "Epoch 56/200\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 2722851.0000 - root_mean_squared_error: 1650.1063 - val_loss: 3155293.2500 - val_root_mean_squared_error: 1776.3143\n",
            "Epoch 57/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2713408.7500 - root_mean_squared_error: 1647.2428 - val_loss: 3047619.2500 - val_root_mean_squared_error: 1745.7430\n",
            "Epoch 58/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2684725.7500 - root_mean_squared_error: 1638.5132 - val_loss: 3103546.2500 - val_root_mean_squared_error: 1761.6886\n",
            "Epoch 59/200\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 2753648.0000 - root_mean_squared_error: 1659.4120 - val_loss: 3164059.0000 - val_root_mean_squared_error: 1778.7802\n",
            "Epoch 60/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 2677808.0000 - root_mean_squared_error: 1636.4009 - val_loss: 3181347.5000 - val_root_mean_squared_error: 1783.6332\n",
            "Epoch 61/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2687214.0000 - root_mean_squared_error: 1639.2723 - val_loss: 3237236.7500 - val_root_mean_squared_error: 1799.2323\n",
            "Epoch 62/200\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 2649647.0000 - root_mean_squared_error: 1627.7737 - val_loss: 2958738.2500 - val_root_mean_squared_error: 1720.0983\n",
            "Epoch 63/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2656770.5000 - root_mean_squared_error: 1629.9602 - val_loss: 2945788.2500 - val_root_mean_squared_error: 1716.3298\n",
            "Epoch 64/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 2643739.5000 - root_mean_squared_error: 1625.9580 - val_loss: 3182531.7500 - val_root_mean_squared_error: 1783.9653\n",
            "Epoch 65/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2675952.5000 - root_mean_squared_error: 1635.8339 - val_loss: 3168006.0000 - val_root_mean_squared_error: 1779.8893\n",
            "Epoch 66/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2683062.5000 - root_mean_squared_error: 1638.0056 - val_loss: 3431358.0000 - val_root_mean_squared_error: 1852.3925\n",
            "Epoch 67/200\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 2664325.2500 - root_mean_squared_error: 1632.2761 - val_loss: 3080852.0000 - val_root_mean_squared_error: 1755.2356\n",
            "Epoch 68/200\n",
            "92/92 [==============================] - 4s 41ms/step - loss: 2637391.2500 - root_mean_squared_error: 1624.0046 - val_loss: 2844199.0000 - val_root_mean_squared_error: 1686.4753\n",
            "Epoch 69/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2630002.7500 - root_mean_squared_error: 1621.7283 - val_loss: 3385106.7500 - val_root_mean_squared_error: 1839.8660\n",
            "Epoch 70/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2573260.5000 - root_mean_squared_error: 1604.1385 - val_loss: 2903702.7500 - val_root_mean_squared_error: 1704.0255\n",
            "Epoch 71/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 2561236.2500 - root_mean_squared_error: 1600.3862 - val_loss: 3239656.0000 - val_root_mean_squared_error: 1799.9044\n",
            "Epoch 72/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 2541606.0000 - root_mean_squared_error: 1594.2415 - val_loss: 2943577.2500 - val_root_mean_squared_error: 1715.6857\n",
            "Epoch 73/200\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 2547478.5000 - root_mean_squared_error: 1596.0823 - val_loss: 3140263.7500 - val_root_mean_squared_error: 1772.0790\n",
            "Epoch 74/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2504554.2500 - root_mean_squared_error: 1582.5782 - val_loss: 2850993.5000 - val_root_mean_squared_error: 1688.4886\n",
            "Epoch 75/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 2492298.2500 - root_mean_squared_error: 1578.7014 - val_loss: 3056649.7500 - val_root_mean_squared_error: 1748.3278\n",
            "Epoch 76/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2521778.5000 - root_mean_squared_error: 1588.0110 - val_loss: 2847262.2500 - val_root_mean_squared_error: 1687.3832\n",
            "Epoch 77/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2504389.5000 - root_mean_squared_error: 1582.5264 - val_loss: 2853280.2500 - val_root_mean_squared_error: 1689.1655\n",
            "Epoch 78/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 2413646.7500 - root_mean_squared_error: 1553.5917 - val_loss: 3130856.5000 - val_root_mean_squared_error: 1769.4225\n",
            "Epoch 79/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2487021.0000 - root_mean_squared_error: 1577.0292 - val_loss: 3157282.0000 - val_root_mean_squared_error: 1776.8743\n",
            "Epoch 80/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 2482466.0000 - root_mean_squared_error: 1575.5844 - val_loss: 3224796.7500 - val_root_mean_squared_error: 1795.7719\n",
            "Epoch 81/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 2474504.0000 - root_mean_squared_error: 1573.0555 - val_loss: 2822381.2500 - val_root_mean_squared_error: 1679.9944\n",
            "Epoch 82/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 2424113.2500 - root_mean_squared_error: 1556.9564 - val_loss: 3124110.7500 - val_root_mean_squared_error: 1767.5154\n",
            "Epoch 83/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2407499.5000 - root_mean_squared_error: 1551.6119 - val_loss: 3074721.0000 - val_root_mean_squared_error: 1753.4883\n",
            "Epoch 84/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2362064.0000 - root_mean_squared_error: 1536.9008 - val_loss: 2903534.0000 - val_root_mean_squared_error: 1703.9758\n",
            "Epoch 85/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2377312.7500 - root_mean_squared_error: 1541.8536 - val_loss: 2864895.7500 - val_root_mean_squared_error: 1692.6003\n",
            "Epoch 86/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2425919.7500 - root_mean_squared_error: 1557.5364 - val_loss: 2890630.7500 - val_root_mean_squared_error: 1700.1855\n",
            "Epoch 87/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2394786.2500 - root_mean_squared_error: 1547.5096 - val_loss: 2779112.5000 - val_root_mean_squared_error: 1667.0670\n",
            "Epoch 88/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2345318.5000 - root_mean_squared_error: 1531.4432 - val_loss: 3200598.7500 - val_root_mean_squared_error: 1789.0217\n",
            "Epoch 89/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2371018.0000 - root_mean_squared_error: 1539.8109 - val_loss: 2674210.7500 - val_root_mean_squared_error: 1635.3014\n",
            "Epoch 90/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 2342212.0000 - root_mean_squared_error: 1530.4287 - val_loss: 2816274.7500 - val_root_mean_squared_error: 1678.1760\n",
            "Epoch 91/200\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 2371882.5000 - root_mean_squared_error: 1540.0918 - val_loss: 2986915.5000 - val_root_mean_squared_error: 1728.2695\n",
            "Epoch 92/200\n",
            "92/92 [==============================] - 4s 40ms/step - loss: 2335343.5000 - root_mean_squared_error: 1528.1829 - val_loss: 2954201.0000 - val_root_mean_squared_error: 1718.7789\n",
            "Epoch 93/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2343327.2500 - root_mean_squared_error: 1530.7930 - val_loss: 2995967.7500 - val_root_mean_squared_error: 1730.8864\n",
            "Epoch 94/200\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 2348721.7500 - root_mean_squared_error: 1532.5540 - val_loss: 2725015.7500 - val_root_mean_squared_error: 1650.7622\n",
            "Epoch 95/200\n",
            "92/92 [==============================] - 4s 46ms/step - loss: 2304328.7500 - root_mean_squared_error: 1518.0016 - val_loss: 2679084.7500 - val_root_mean_squared_error: 1636.7910\n",
            "Epoch 96/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 2341015.7500 - root_mean_squared_error: 1530.0377 - val_loss: 2924297.2500 - val_root_mean_squared_error: 1710.0576\n",
            "Epoch 97/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 2345685.5000 - root_mean_squared_error: 1531.5631 - val_loss: 2747521.0000 - val_root_mean_squared_error: 1657.5648\n",
            "Epoch 98/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 2358242.0000 - root_mean_squared_error: 1535.6569 - val_loss: 3068262.0000 - val_root_mean_squared_error: 1751.6455\n",
            "Epoch 99/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 2336310.2500 - root_mean_squared_error: 1528.4994 - val_loss: 3169998.7500 - val_root_mean_squared_error: 1780.4490\n",
            "Epoch 100/200\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 2274658.5000 - root_mean_squared_error: 1508.1971 - val_loss: 2818566.0000 - val_root_mean_squared_error: 1678.8585\n",
            "Epoch 101/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 2317091.5000 - root_mean_squared_error: 1522.1996 - val_loss: 2828902.0000 - val_root_mean_squared_error: 1681.9340\n",
            "Epoch 102/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2307658.7500 - root_mean_squared_error: 1519.0980 - val_loss: 2807062.7500 - val_root_mean_squared_error: 1675.4291\n",
            "Epoch 103/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2299417.5000 - root_mean_squared_error: 1516.3831 - val_loss: 2739307.5000 - val_root_mean_squared_error: 1655.0853\n",
            "Epoch 104/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 2322408.2500 - root_mean_squared_error: 1523.9449 - val_loss: 2852344.0000 - val_root_mean_squared_error: 1688.8884\n",
            "Epoch 105/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2286325.2500 - root_mean_squared_error: 1512.0599 - val_loss: 2982477.0000 - val_root_mean_squared_error: 1726.9850\n",
            "Epoch 106/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 2264711.0000 - root_mean_squared_error: 1504.8958 - val_loss: 2868959.5000 - val_root_mean_squared_error: 1693.8003\n",
            "Epoch 107/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2292887.2500 - root_mean_squared_error: 1514.2281 - val_loss: 2946592.0000 - val_root_mean_squared_error: 1716.5640\n",
            "Epoch 108/200\n",
            "92/92 [==============================] - 2s 27ms/step - loss: 2269926.2500 - root_mean_squared_error: 1506.6274 - val_loss: 2901942.7500 - val_root_mean_squared_error: 1703.5089\n",
            "Epoch 109/200\n",
            "92/92 [==============================] - 4s 40ms/step - loss: 2264313.2500 - root_mean_squared_error: 1504.7635 - val_loss: 2706146.2500 - val_root_mean_squared_error: 1645.0369\n",
            "Epoch 110/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 2296120.2500 - root_mean_squared_error: 1515.2954 - val_loss: 2794770.0000 - val_root_mean_squared_error: 1671.7566\n",
            "Epoch 111/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 2239968.7500 - root_mean_squared_error: 1496.6525 - val_loss: 2828812.5000 - val_root_mean_squared_error: 1681.9073\n",
            "Epoch 112/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 2249951.2500 - root_mean_squared_error: 1499.9838 - val_loss: 2951550.0000 - val_root_mean_squared_error: 1718.0076\n",
            "Epoch 113/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2288099.5000 - root_mean_squared_error: 1512.6465 - val_loss: 2840920.0000 - val_root_mean_squared_error: 1685.5029\n",
            "Epoch 114/200\n",
            "92/92 [==============================] - 4s 40ms/step - loss: 2259751.0000 - root_mean_squared_error: 1503.2467 - val_loss: 2796072.0000 - val_root_mean_squared_error: 1672.1459\n",
            "Epoch 115/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2358173.2500 - root_mean_squared_error: 1535.6345 - val_loss: 3340813.2500 - val_root_mean_squared_error: 1827.7892\n",
            "Epoch 116/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2265373.2500 - root_mean_squared_error: 1505.1157 - val_loss: 2894187.5000 - val_root_mean_squared_error: 1701.2311\n",
            "Epoch 117/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2306231.5000 - root_mean_squared_error: 1518.6282 - val_loss: 3089499.5000 - val_root_mean_squared_error: 1757.6973\n",
            "Epoch 118/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2265689.7500 - root_mean_squared_error: 1505.2207 - val_loss: 3061774.5000 - val_root_mean_squared_error: 1749.7927\n",
            "Epoch 119/200\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 2219478.7500 - root_mean_squared_error: 1489.7915 - val_loss: 2730363.5000 - val_root_mean_squared_error: 1652.3810\n",
            "Epoch 120/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 2222760.2500 - root_mean_squared_error: 1490.8926 - val_loss: 2811370.2500 - val_root_mean_squared_error: 1676.7141\n",
            "Epoch 121/200\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 2241433.2500 - root_mean_squared_error: 1497.1417 - val_loss: 3051727.7500 - val_root_mean_squared_error: 1746.9196\n",
            "Epoch 122/200\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 2239095.7500 - root_mean_squared_error: 1496.3608 - val_loss: 3001746.0000 - val_root_mean_squared_error: 1732.5548\n",
            "Epoch 123/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2219326.5000 - root_mean_squared_error: 1489.7404 - val_loss: 2920356.5000 - val_root_mean_squared_error: 1708.9050\n",
            "Epoch 124/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 2229317.5000 - root_mean_squared_error: 1493.0900 - val_loss: 3159670.5000 - val_root_mean_squared_error: 1777.5461\n",
            "Epoch 125/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2198971.7500 - root_mean_squared_error: 1482.8931 - val_loss: 3126211.5000 - val_root_mean_squared_error: 1768.1096\n",
            "Epoch 126/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 2184626.5000 - root_mean_squared_error: 1478.0482 - val_loss: 3507447.5000 - val_root_mean_squared_error: 1872.8181\n",
            "Epoch 127/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2156180.0000 - root_mean_squared_error: 1468.3938 - val_loss: 3178464.2500 - val_root_mean_squared_error: 1782.8248\n",
            "Epoch 128/200\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 2183482.0000 - root_mean_squared_error: 1477.6610 - val_loss: 2760382.0000 - val_root_mean_squared_error: 1661.4397\n",
            "Epoch 129/200\n",
            "92/92 [==============================] - 4s 43ms/step - loss: 2192683.7500 - root_mean_squared_error: 1480.7714 - val_loss: 3120795.7500 - val_root_mean_squared_error: 1766.5774\n",
            "Epoch 130/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2260815.7500 - root_mean_squared_error: 1503.6010 - val_loss: 3287970.0000 - val_root_mean_squared_error: 1813.2760\n",
            "Epoch 131/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2207306.5000 - root_mean_squared_error: 1485.7007 - val_loss: 2939374.0000 - val_root_mean_squared_error: 1714.4602\n",
            "Epoch 132/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2172883.0000 - root_mean_squared_error: 1474.0702 - val_loss: 2977293.2500 - val_root_mean_squared_error: 1725.4835\n",
            "Epoch 133/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2150176.0000 - root_mean_squared_error: 1466.3479 - val_loss: 3172584.7500 - val_root_mean_squared_error: 1781.1750\n",
            "Epoch 134/200\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 2157586.2500 - root_mean_squared_error: 1468.8726 - val_loss: 3225544.7500 - val_root_mean_squared_error: 1795.9802\n",
            "Epoch 135/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2138255.0000 - root_mean_squared_error: 1462.2775 - val_loss: 3006490.0000 - val_root_mean_squared_error: 1733.9233\n",
            "Epoch 136/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 2173492.0000 - root_mean_squared_error: 1474.2767 - val_loss: 2912827.5000 - val_root_mean_squared_error: 1706.7007\n",
            "Epoch 137/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 2152350.7500 - root_mean_squared_error: 1467.0892 - val_loss: 2954670.0000 - val_root_mean_squared_error: 1718.9154\n",
            "Epoch 138/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 2140087.7500 - root_mean_squared_error: 1462.9039 - val_loss: 3398216.5000 - val_root_mean_squared_error: 1843.4252\n",
            "Epoch 139/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2154986.0000 - root_mean_squared_error: 1467.9871 - val_loss: 2831183.7500 - val_root_mean_squared_error: 1682.6122\n",
            "Epoch 140/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 2118628.7500 - root_mean_squared_error: 1455.5510 - val_loss: 3018539.5000 - val_root_mean_squared_error: 1737.3944\n",
            "Epoch 141/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2147329.0000 - root_mean_squared_error: 1465.3767 - val_loss: 3295438.0000 - val_root_mean_squared_error: 1815.3341\n",
            "Epoch 142/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2139733.0000 - root_mean_squared_error: 1462.7826 - val_loss: 3131769.2500 - val_root_mean_squared_error: 1769.6807\n",
            "Epoch 143/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2101969.7500 - root_mean_squared_error: 1449.8171 - val_loss: 2882298.2500 - val_root_mean_squared_error: 1697.7333\n",
            "Epoch 144/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 2160889.7500 - root_mean_squared_error: 1469.9965 - val_loss: 3018614.2500 - val_root_mean_squared_error: 1737.4160\n",
            "Epoch 145/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 2115844.7500 - root_mean_squared_error: 1454.5944 - val_loss: 3332199.7500 - val_root_mean_squared_error: 1825.4314\n",
            "Epoch 146/200\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 2138969.7500 - root_mean_squared_error: 1462.5217 - val_loss: 3479432.5000 - val_root_mean_squared_error: 1865.3237\n",
            "Epoch 147/200\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 2115940.2500 - root_mean_squared_error: 1454.6272 - val_loss: 2998877.5000 - val_root_mean_squared_error: 1731.7267\n",
            "Epoch 148/200\n",
            "92/92 [==============================] - 4s 41ms/step - loss: 2107751.7500 - root_mean_squared_error: 1451.8098 - val_loss: 2957709.2500 - val_root_mean_squared_error: 1719.7992\n",
            "Epoch 149/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 2115632.7500 - root_mean_squared_error: 1454.5215 - val_loss: 3364076.7500 - val_root_mean_squared_error: 1834.1420\n",
            "Epoch 150/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 2143241.7500 - root_mean_squared_error: 1463.9814 - val_loss: 3096679.7500 - val_root_mean_squared_error: 1759.7385\n",
            "Epoch 151/200\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 2114612.2500 - root_mean_squared_error: 1454.1707 - val_loss: 3233970.0000 - val_root_mean_squared_error: 1798.3242\n",
            "Epoch 152/200\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 2082118.3750 - root_mean_squared_error: 1442.9547 - val_loss: 2926746.7500 - val_root_mean_squared_error: 1710.7737\n",
            "Epoch 153/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 2078240.5000 - root_mean_squared_error: 1441.6104 - val_loss: 3069023.0000 - val_root_mean_squared_error: 1751.8627\n",
            "Epoch 154/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 2098958.2500 - root_mean_squared_error: 1448.7782 - val_loss: 3183653.2500 - val_root_mean_squared_error: 1784.2794\n",
            "Epoch 155/200\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 2099804.2500 - root_mean_squared_error: 1449.0702 - val_loss: 3121415.7500 - val_root_mean_squared_error: 1766.7529\n",
            "Epoch 156/200\n",
            "92/92 [==============================] - 4s 40ms/step - loss: 2050522.2500 - root_mean_squared_error: 1431.9645 - val_loss: 3271419.0000 - val_root_mean_squared_error: 1808.7064\n",
            "Epoch 157/200\n",
            "92/92 [==============================] - 4s 48ms/step - loss: 2100832.2500 - root_mean_squared_error: 1449.4248 - val_loss: 3165693.5000 - val_root_mean_squared_error: 1779.2396\n",
            "Epoch 158/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 2118878.2500 - root_mean_squared_error: 1455.6367 - val_loss: 3496755.0000 - val_root_mean_squared_error: 1869.9612\n",
            "Epoch 159/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2116488.5000 - root_mean_squared_error: 1454.8157 - val_loss: 3350317.7500 - val_root_mean_squared_error: 1830.3873\n",
            "Epoch 160/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 2114542.2500 - root_mean_squared_error: 1454.1466 - val_loss: 3481516.7500 - val_root_mean_squared_error: 1865.8822\n",
            "Epoch 161/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2084433.1250 - root_mean_squared_error: 1443.7566 - val_loss: 3240331.0000 - val_root_mean_squared_error: 1800.0918\n",
            "Epoch 162/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2083496.2500 - root_mean_squared_error: 1443.4323 - val_loss: 3301626.7500 - val_root_mean_squared_error: 1817.0380\n",
            "Epoch 163/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2047004.7500 - root_mean_squared_error: 1430.7357 - val_loss: 2843339.5000 - val_root_mean_squared_error: 1686.2205\n",
            "Epoch 164/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 2075351.8750 - root_mean_squared_error: 1440.6082 - val_loss: 2985275.7500 - val_root_mean_squared_error: 1727.7950\n",
            "Epoch 165/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 2067648.0000 - root_mean_squared_error: 1437.9319 - val_loss: 3083945.7500 - val_root_mean_squared_error: 1756.1168\n",
            "Epoch 166/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2065220.3750 - root_mean_squared_error: 1437.0874 - val_loss: 3140756.5000 - val_root_mean_squared_error: 1772.2180\n",
            "Epoch 167/200\n",
            "92/92 [==============================] - 4s 47ms/step - loss: 2040566.1250 - root_mean_squared_error: 1428.4839 - val_loss: 2971213.2500 - val_root_mean_squared_error: 1723.7207\n",
            "Epoch 168/200\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 2078800.8750 - root_mean_squared_error: 1441.8047 - val_loss: 3508475.5000 - val_root_mean_squared_error: 1873.0925\n",
            "Epoch 169/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 2054480.0000 - root_mean_squared_error: 1433.3457 - val_loss: 3697857.0000 - val_root_mean_squared_error: 1922.9812\n",
            "Epoch 170/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 2051654.5000 - root_mean_squared_error: 1432.3597 - val_loss: 3511367.7500 - val_root_mean_squared_error: 1873.8644\n",
            "Epoch 171/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2043260.8750 - root_mean_squared_error: 1429.4268 - val_loss: 3213304.2500 - val_root_mean_squared_error: 1792.5692\n",
            "Epoch 172/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 2041989.5000 - root_mean_squared_error: 1428.9819 - val_loss: 3267669.0000 - val_root_mean_squared_error: 1807.6694\n",
            "Epoch 173/200\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 2040118.6250 - root_mean_squared_error: 1428.3273 - val_loss: 3604134.7500 - val_root_mean_squared_error: 1898.4559\n",
            "Epoch 174/200\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 2067272.0000 - root_mean_squared_error: 1437.8011 - val_loss: 3123150.0000 - val_root_mean_squared_error: 1767.2437\n",
            "Epoch 175/200\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 2025787.6250 - root_mean_squared_error: 1423.3016 - val_loss: 3321830.0000 - val_root_mean_squared_error: 1822.5889\n",
            "Epoch 176/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2046754.6250 - root_mean_squared_error: 1430.6483 - val_loss: 3490893.2500 - val_root_mean_squared_error: 1868.3932\n",
            "Epoch 177/200\n",
            "92/92 [==============================] - 2s 17ms/step - loss: 1998167.0000 - root_mean_squared_error: 1413.5653 - val_loss: 3404862.0000 - val_root_mean_squared_error: 1845.2268\n",
            "Epoch 178/200\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 2041255.7500 - root_mean_squared_error: 1428.7252 - val_loss: 3461703.5000 - val_root_mean_squared_error: 1860.5654\n",
            "Epoch 179/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 2038638.7500 - root_mean_squared_error: 1427.8091 - val_loss: 3349089.0000 - val_root_mean_squared_error: 1830.0516\n",
            "Epoch 180/200\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2009599.5000 - root_mean_squared_error: 1417.6034 - val_loss: 2972283.5000 - val_root_mean_squared_error: 1724.0311\n",
            "Epoch 181/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2000985.2500 - root_mean_squared_error: 1414.5619 - val_loss: 3207168.0000 - val_root_mean_squared_error: 1790.8568\n",
            "Epoch 182/200\n",
            "92/92 [==============================] - 3s 27ms/step - loss: 2035608.1250 - root_mean_squared_error: 1426.7474 - val_loss: 3346676.7500 - val_root_mean_squared_error: 1829.3925\n",
            "Epoch 183/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 1997068.1250 - root_mean_squared_error: 1413.1766 - val_loss: 3532924.5000 - val_root_mean_squared_error: 1879.6075\n",
            "Epoch 184/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 2021615.5000 - root_mean_squared_error: 1421.8352 - val_loss: 3651955.7500 - val_root_mean_squared_error: 1911.0090\n",
            "Epoch 185/200\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 2002104.2500 - root_mean_squared_error: 1414.9574 - val_loss: 3059277.0000 - val_root_mean_squared_error: 1749.0789\n",
            "Epoch 186/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2006652.7500 - root_mean_squared_error: 1416.5637 - val_loss: 3531672.0000 - val_root_mean_squared_error: 1879.2743\n",
            "Epoch 187/200\n",
            "92/92 [==============================] - 4s 39ms/step - loss: 2039212.8750 - root_mean_squared_error: 1428.0101 - val_loss: 3137247.2500 - val_root_mean_squared_error: 1771.2277\n",
            "Epoch 188/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 2003919.0000 - root_mean_squared_error: 1415.5985 - val_loss: 2889583.0000 - val_root_mean_squared_error: 1699.8773\n",
            "Epoch 189/200\n",
            "92/92 [==============================] - 2s 27ms/step - loss: 2004524.2500 - root_mean_squared_error: 1415.8123 - val_loss: 3562471.7500 - val_root_mean_squared_error: 1887.4510\n",
            "Epoch 190/200\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 1957129.5000 - root_mean_squared_error: 1398.9745 - val_loss: 3266974.0000 - val_root_mean_squared_error: 1807.4773\n",
            "Epoch 191/200\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 2010235.5000 - root_mean_squared_error: 1417.8278 - val_loss: 3124532.0000 - val_root_mean_squared_error: 1767.6345\n",
            "Epoch 192/200\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 1952032.2500 - root_mean_squared_error: 1397.1515 - val_loss: 3007055.0000 - val_root_mean_squared_error: 1734.0862\n",
            "Epoch 193/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 1949879.1250 - root_mean_squared_error: 1396.3807 - val_loss: 2984467.7500 - val_root_mean_squared_error: 1727.5612\n",
            "Epoch 194/200\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 1965549.3750 - root_mean_squared_error: 1401.9805 - val_loss: 3571831.5000 - val_root_mean_squared_error: 1889.9290\n",
            "Epoch 195/200\n",
            "92/92 [==============================] - 4s 47ms/step - loss: 1984296.5000 - root_mean_squared_error: 1408.6505 - val_loss: 3268107.5000 - val_root_mean_squared_error: 1807.7908\n",
            "Epoch 196/200\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 1958754.6250 - root_mean_squared_error: 1399.5552 - val_loss: 3271231.0000 - val_root_mean_squared_error: 1808.6544\n",
            "Epoch 197/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 1959998.1250 - root_mean_squared_error: 1399.9994 - val_loss: 3219407.7500 - val_root_mean_squared_error: 1794.2708\n",
            "Epoch 198/200\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 1979203.3750 - root_mean_squared_error: 1406.8417 - val_loss: 3314113.7500 - val_root_mean_squared_error: 1820.4707\n",
            "Epoch 199/200\n",
            "92/92 [==============================] - 4s 40ms/step - loss: 1949159.1250 - root_mean_squared_error: 1396.1229 - val_loss: 3129870.0000 - val_root_mean_squared_error: 1769.1439\n",
            "Epoch 200/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 1958155.8750 - root_mean_squared_error: 1399.3412 - val_loss: 3302691.5000 - val_root_mean_squared_error: 1817.3309\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Simple bidrectional LSTM model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "num_sequence = 4\n",
        "# Build the LSTM model\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=256, input_shape=(1, X_train.shape[1]), activation='relu'))\n",
        "# Add a dense output layer with a single unit (for regression) and no activation function\n",
        "model.add(Dense(units=1))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\"\"\"\n",
        "# Build the LSTM model\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(num_sequence, 21)))\n",
        "model.add(LSTM(units=32, activation='relu', dropout=0.1))\n",
        "model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "model = Sequential([\n",
        "    #Input(shape=(num_sequence, 21)),\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    LSTM(32, activation='relu', dropout=0.1, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    Dense(units=1, activation='linear')\n",
        "])\"\"\"\n",
        "\n",
        "CONV_WIDTH = 3\n",
        "\n",
        "\n",
        "\"\"\"OUT_STEPS = 4\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        Input(shape=(num_sequence, 23)),\n",
        "        tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "        tf.keras.layers.Conv1D(256, activation=\"relu\", kernel_size=(CONV_WIDTH)),\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(32, return_sequences=True)\n",
        "        ),\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(32, return_sequences=False)\n",
        "        ),\n",
        "        tf.keras.layers.Dense(\n",
        "            OUT_STEPS * 1, kernel_initializer=tf.initializers.zeros()\n",
        "        ),\n",
        "        tf.keras.layers.Reshape([OUT_STEPS, 1]),\n",
        "    ]\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "inputs = Input(shape=(num_sequence, 23))\n",
        "#x = tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :])(inputs)\n",
        "#x = tf.keras.layers.Conv1D(256, activation=\"relu\", kernel_size=(CONV_WIDTH))(x)\n",
        "x = Bidirectional(LSTM(64, activation='relu', dropout=0.25, return_sequences=True))(inputs)\n",
        "x = Bidirectional(LSTM(32, activation='relu', dropout=0.25, return_sequences=True))(x)\n",
        "#x = LSTM(64, activation='relu', dropout=0.2, return_sequences=True)(inputs)\n",
        "#x = LSTM(32, activation='relu', dropout=0.2, return_sequences=True)(x)\n",
        "#x = LSTM(32, activation='relu', dropout=0.0, return_sequences=True)(x)\n",
        "outputs = Dense(1, activation='linear')(x)\n",
        "#outputs = Reshape([num_sequence, 1])(x)\n",
        "\n",
        "\"\"\"\n",
        "inputs = Input(shape=(num_sequence, 21))\n",
        "x = LSTM(64, activation='relu', dropout=0.1, return_sequences=True)(inputs)\n",
        "outputs = Dense(1, activation='linear', name=\"custom_output\")(x)\n",
        "\"\"\"\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_train_scaled_3d = np.reshape(X_train_scaled, (num_samples, num_sequence, X_train_scaled.shape[1]))  # Fix variable name\n",
        "\n",
        "#num_samples = X_dev_scaled.shape[0]\n",
        "#X_dev_scaled_3d = np.reshape(X_dev_scaled, (num_samples, num_sequence, X_dev_scaled.shape[1]))\n",
        "\n",
        "# Train the model\n",
        "#X_train_scaled_3d = np.expand_dims(X_train_scaled_3d[0], axis=0)\n",
        "#y_train_3d = np.expand_dims(y_train_3d[0], axis=0)\n",
        "#print(X_train_scaled_3d)\n",
        "#print(y_train_3d)\n",
        "#print(testing_y.shape)\n",
        "\n",
        "#X = X_train_scaled_3d.reshape((X_train_scaled_3d.shape[0], 2, 1, 2, 23))\n",
        "#Xdev = X_dev_scaled_3d.reshape((X_dev_scaled_3d.shape[0], 2, 1, 2, 23))\n",
        "\n",
        "\n",
        "#history = model.fit(X_train_scaled_3d, testing_y, epochs=10, batch_size=32, verbose=2, validation_data=(X_dev_scaled_3d, y_dev_3d))\n",
        "#history = model.fit(X, y_train_3d, epochs=50, batch_size=32, validation_data=(Xdev, y_dev_3d))\n",
        "\n",
        "history = model.fit(X_train_scaled_3d, y_train_3d, epochs=200, batch_size=32, validation_data=(X_dev_scaled_3d, y_dev_3d))\n",
        "#history = model.fit(dataset, epochs=10, batch_size=32, verbose=2, validation_data=(X_dev_scaled_3d, y_dev_3d))\n",
        "#history = model.fit(x_trainnnn, y_trainnnn, epochs=10, batch_size=32, verbose=2)\n",
        "\n",
        "#validation_data=(X_dev_scaled, y_dev)\n",
        "\n",
        "#output = model.predict(X_train_scaled_3d)\n",
        "#output = model.predict(X_train_scaled_3d)\n",
        "#intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(\"custom_output\").output)\n",
        "#intermediate_model.predict(X_train_scaled_3d)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-QSP6ba9x2S"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Complex model takes very long and val score is not much better. It overfitted\n",
        "Epoch 50/50\n",
        "92/92 [==============================] - 25s 273ms/step - loss: 1557592.7500 - root_mean_squared_error: 1248.0355 - val_loss: 2976063.0000 - val_root_mean_squared_error: 1725.1270\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#num_samples = len(X_train_scaled_3d)\n",
        "num_sequence = 4\n",
        "# Build the LSTM model\n",
        "\n",
        "CONV_WIDTH = 3\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.ConvLSTM2D(filters=512, kernel_size=(1,2), activation='relu', dropout=0.2, input_shape=(2, 1, 2, 23)),\n",
        "            tf.keras.layers.Dense(\n",
        "                num_sequence, kernel_initializer=tf.initializers.zeros()\n",
        "            ),\n",
        "            tf.keras.layers.Reshape([num_sequence, 1]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "X = X_train_scaled_3d.reshape((X_train_scaled_3d.shape[0], 2, 1, 2, 23))\n",
        "Xdev = X_dev_scaled_3d.reshape((X_dev_scaled_3d.shape[0], 2, 1, 2, 23))\n",
        "\n",
        "history = model.fit(X, y_train_3d, epochs=50, batch_size=32, validation_data=(Xdev, y_dev_3d))"
      ],
      "id": "t-QSP6ba9x2S"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the array for the x axis, starting from 1\n",
        "epochs = np.arange(1, len(history.history[\"root_mean_squared_error\"])+1)\n",
        "train_rmse = history.history[\"root_mean_squared_error\"]\n",
        "dev_rmse = history.history[\"val_root_mean_squared_error\"]\n",
        "\n",
        "# Create a line chart with two lines using Plotly Express\n",
        "fig = px.line(title='train RMSE vs. dev RMSE')\n",
        "fig.add_scatter(x=epochs, y=train_rmse, mode='lines+markers', name='Train RMSE', line=dict(color='red'))\n",
        "fig.add_scatter(x=epochs, y=dev_rmse, mode='lines+markers', name='Dev RMSE', line=dict(color='blue'))\n",
        "\n",
        "\n",
        "# Set chart title and axis labels\n",
        "fig.update_layout(\n",
        "    xaxis_title='Epochs',\n",
        "    yaxis_title='RMSE'\n",
        ")\n",
        "\n",
        "# Show the chart\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7i6bKNcPps07",
        "outputId": "d133587b-9b1b-4c9e-d93c-497f20405874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "id": "7i6bKNcPps07",
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"8653c762-4b5a-42d1-b11b-a48cd98a1a0a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8653c762-4b5a-42d1-b11b-a48cd98a1a0a\")) {                    Plotly.newPlot(                        \"8653c762-4b5a-42d1-b11b-a48cd98a1a0a\",                        [{\"hovertemplate\":\"\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"mode\":\"lines+markers\",\"name\":\"Train RMSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"y\":[5845.23583984375,2867.305419921875,2190.693359375,2005.33056640625,1964.891357421875,1939.4405517578125,1933.3011474609375,1894.2603759765625,1878.0760498046875,1858.5946044921875,1832.86962890625,1844.0064697265625,1835.417236328125,1805.5977783203125,1801.4241943359375,1807.6475830078125,1802.26025390625,1795.325927734375,1780.3377685546875,1770.615234375,1775.298583984375,1762.1474609375,1777.5372314453125,1779.599365234375,1751.7763671875,1748.93310546875,1758.6634521484375,1728.400390625,1735.29248046875,1741.21240234375,1721.7362060546875,1721.2979736328125,1698.3663330078125,1717.3262939453125,1727.51123046875,1714.5684814453125,1711.1954345703125,1698.9285888671875,1688.026611328125,1694.0091552734375,1690.43994140625,1676.152099609375,1668.2757568359375,1685.212158203125,1666.96875,1670.1890869140625,1662.22412109375,1654.9022216796875,1660.4478759765625,1658.5323486328125,1646.0411376953125,1637.3045654296875,1687.06640625,1679.60205078125,1649.2119140625,1650.1063232421875,1647.2427978515625,1638.51318359375,1659.4119873046875,1636.40087890625,1639.2723388671875,1627.773681640625,1629.960205078125,1625.9580078125,1635.8338623046875,1638.005615234375,1632.276123046875,1624.004638671875,1621.728271484375,1604.1385498046875,1600.38623046875,1594.241455078125,1596.082275390625,1582.5782470703125,1578.701416015625,1588.010986328125,1582.5263671875,1553.5916748046875,1577.0291748046875,1575.5843505859375,1573.0555419921875,1556.9564208984375,1551.6119384765625,1536.9007568359375,1541.8536376953125,1557.536376953125,1547.5096435546875,1531.4432373046875,1539.8109130859375,1530.4287109375,1540.091796875,1528.182861328125,1530.79296875,1532.553955078125,1518.0015869140625,1530.0377197265625,1531.5631103515625,1535.6568603515625,1528.4993896484375,1508.1971435546875,1522.1995849609375,1519.0980224609375,1516.383056640625,1523.9449462890625,1512.0599365234375,1504.895751953125,1514.2281494140625,1506.62744140625,1504.7635498046875,1515.29541015625,1496.6524658203125,1499.9837646484375,1512.646484375,1503.2467041015625,1535.634521484375,1505.11572265625,1518.628173828125,1505.220703125,1489.79150390625,1490.892578125,1497.1417236328125,1496.36083984375,1489.7403564453125,1493.0899658203125,1482.89306640625,1478.0482177734375,1468.393798828125,1477.6610107421875,1480.7713623046875,1503.6009521484375,1485.70068359375,1474.0701904296875,1466.347900390625,1468.87255859375,1462.2774658203125,1474.2767333984375,1467.0892333984375,1462.9039306640625,1467.987060546875,1455.551025390625,1465.376708984375,1462.7825927734375,1449.817138671875,1469.9964599609375,1454.5943603515625,1462.521728515625,1454.627197265625,1451.809814453125,1454.521484375,1463.9814453125,1454.170654296875,1442.9547119140625,1441.6103515625,1448.7781982421875,1449.0701904296875,1431.9644775390625,1449.4248046875,1455.63671875,1454.815673828125,1454.1466064453125,1443.756591796875,1443.4322509765625,1430.7357177734375,1440.608154296875,1437.931884765625,1437.08740234375,1428.48388671875,1441.8046875,1433.345703125,1432.3597412109375,1429.4267578125,1428.98193359375,1428.3272705078125,1437.8011474609375,1423.3016357421875,1430.6483154296875,1413.5653076171875,1428.7252197265625,1427.80908203125,1417.6033935546875,1414.5618896484375,1426.7474365234375,1413.1766357421875,1421.835205078125,1414.9573974609375,1416.563720703125,1428.0101318359375,1415.5985107421875,1415.812255859375,1398.9744873046875,1417.8277587890625,1397.1514892578125,1396.3807373046875,1401.98046875,1408.6505126953125,1399.55517578125,1399.9993896484375,1406.8416748046875,1396.1229248046875,1399.3411865234375],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Dev RMSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200],\"y\":[3591.800537109375,2672.457275390625,2306.130859375,2254.775390625,2041.7020263671875,2138.40283203125,2012.271240234375,1972.968994140625,1961.26806640625,2026.1546630859375,1960.11767578125,1934.2418212890625,1915.66064453125,1918.55078125,1876.447265625,1863.63427734375,1908.1190185546875,1922.200927734375,1865.0185546875,1930.636962890625,1857.2689208984375,1864.5634765625,1952.26416015625,1782.43603515625,1860.77880859375,1792.43798828125,1810.8050537109375,1821.8133544921875,1904.99365234375,1792.3419189453125,1807.2689208984375,1840.9102783203125,1808.191162109375,1881.394775390625,1815.2464599609375,1753.40087890625,1853.859130859375,1757.0343017578125,1778.508056640625,1774.7232666015625,1782.933349609375,1855.954345703125,1820.49072265625,1883.61083984375,1795.966552734375,1762.419189453125,1862.1690673828125,1885.86669921875,1729.248779296875,1762.85498046875,1793.7557373046875,1765.5106201171875,1769.7342529296875,1716.63623046875,1746.38134765625,1776.3143310546875,1745.7430419921875,1761.6885986328125,1778.7801513671875,1783.6331787109375,1799.2322998046875,1720.0982666015625,1716.329833984375,1783.96533203125,1779.8892822265625,1852.3924560546875,1755.235595703125,1686.475341796875,1839.865966796875,1704.0255126953125,1799.9044189453125,1715.6856689453125,1772.0789794921875,1688.4886474609375,1748.3277587890625,1687.3831787109375,1689.16552734375,1769.4224853515625,1776.874267578125,1795.7718505859375,1679.994384765625,1767.515380859375,1753.48828125,1703.975830078125,1692.600341796875,1700.185546875,1667.0670166015625,1789.021728515625,1635.3013916015625,1678.176025390625,1728.26953125,1718.7789306640625,1730.8863525390625,1650.76220703125,1636.791015625,1710.0576171875,1657.5648193359375,1751.6455078125,1780.448974609375,1678.8585205078125,1681.9339599609375,1675.4290771484375,1655.0853271484375,1688.888427734375,1726.9849853515625,1693.80029296875,1716.56396484375,1703.5089111328125,1645.036865234375,1671.756591796875,1681.9073486328125,1718.007568359375,1685.5029296875,1672.1458740234375,1827.7891845703125,1701.2310791015625,1757.697265625,1749.792724609375,1652.3809814453125,1676.714111328125,1746.9195556640625,1732.5548095703125,1708.905029296875,1777.546142578125,1768.109619140625,1872.818115234375,1782.8248291015625,1661.439697265625,1766.577392578125,1813.2760009765625,1714.460205078125,1725.4835205078125,1781.175048828125,1795.980224609375,1733.92333984375,1706.70068359375,1718.9154052734375,1843.4251708984375,1682.6121826171875,1737.3944091796875,1815.3341064453125,1769.6806640625,1697.7332763671875,1737.416015625,1825.431396484375,1865.32373046875,1731.7266845703125,1719.7991943359375,1834.1419677734375,1759.738525390625,1798.32421875,1710.773681640625,1751.8626708984375,1784.2794189453125,1766.7529296875,1808.7064208984375,1779.2396240234375,1869.961181640625,1830.3873291015625,1865.8822021484375,1800.091796875,1817.0379638671875,1686.220458984375,1727.7950439453125,1756.1168212890625,1772.218017578125,1723.720703125,1873.092529296875,1922.981201171875,1873.8643798828125,1792.5692138671875,1807.66943359375,1898.4559326171875,1767.24365234375,1822.5888671875,1868.3931884765625,1845.226806640625,1860.5654296875,1830.0516357421875,1724.0311279296875,1790.8568115234375,1829.3924560546875,1879.6075439453125,1911.009033203125,1749.078857421875,1879.2742919921875,1771.2276611328125,1699.8773193359375,1887.4510498046875,1807.477294921875,1767.634521484375,1734.086181640625,1727.5611572265625,1889.928955078125,1807.790771484375,1808.6544189453125,1794.270751953125,1820.470703125,1769.1439208984375,1817.3309326171875],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"RMSE\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"train RMSE vs. dev RMSE\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8653c762-4b5a-42d1-b11b-a48cd98a1a0a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3FCqONIDCU2"
      },
      "source": [
        "<a name=\"6.\"></a>\n",
        "## 6. Summary and conclusion\n",
        "[Content](#content)"
      ],
      "id": "v3FCqONIDCU2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have trained three different models with increasing complexity. For the problem at hand it can be said that the more complex MLP model or LSTM model did not perform better, than the simpler XGBoost model. In fact, the LSTM model performt worse than the two previous ones.\n",
        "\n",
        "While the XGBoost model already did well with standard parameters, it was more difficult to find a good architecture with the more complex model MLP and LSTM which was especially true for the last model.\n",
        "\n",
        "A possible reason, why the LSTM model performed worse could be, that the problem at hand has not a strong sequential nature. The dataset is clearly time series data, but the different data points or not very dependent on the previous data points. An easy ilustration to this is, that the people taking a bycicle today, do not care about the weather of yesterday or how many people took the bicyle one day ago. Much more relevant is the current day of the week and the weather of today. Therefore the sequential LSTM model mostly added complexity without adding much of value."
      ],
      "metadata": {
        "id": "urK_A--4Duuj"
      },
      "id": "urK_A--4Duuj"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}