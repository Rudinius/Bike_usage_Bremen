{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "CBLnLwZIZpWJ",
      "metadata": {
        "id": "CBLnLwZIZpWJ"
      },
      "source": [
        "# Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lZXvJFJqZuRE",
      "metadata": {
        "id": "lZXvJFJqZuRE"
      },
      "source": [
        "In the Model learning step, the prepared dataset from [2_EDA](https://github.com/Rudinius/Bike_usage_Bremen/blob/57e21c8dd687aadc1498f82241cf662840c8b871/2_EDA.ipynb) is loaded. Then different machine learning algorithms are trained and compared to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c910711",
      "metadata": {
        "id": "0c910711"
      },
      "source": [
        "<a name=\"content\"></a>\n",
        "# Content\n",
        "\n",
        "* [1. Import libraries and mount drive](#1)\n",
        "* [2. Import datasets](#2)\n",
        "* [3. Transform columns](#3)\n",
        "* [4. Establish baseline benchmark](#4)\n",
        "* [5. Training machine learning algorithms](#5)\n",
        "    * [5.2. XGBoost](#5.2.)\n",
        "    * [5.3. Multilayer perceptron](#5.3.)\n",
        "    * [5.4. Recurrent Neural Network](#5.4.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f76996",
      "metadata": {
        "id": "85f76996"
      },
      "source": [
        "<a name=\"1\"></a>\n",
        "# 1.&nbsp;Import libraries\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3731ea33",
      "metadata": {
        "id": "3731ea33"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "import random\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, TimeSeriesSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import RootMeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "LcKvjPd27cDu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcKvjPd27cDu",
        "outputId": "cef5253a-2055-443c-a4fc-bd2e036128e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyjanitor\n",
            "  Downloading pyjanitor-0.24.0-py3-none-any.whl (158 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.4/158.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from pyjanitor) (8.3.1)\n",
            "Collecting pandas-flavor (from pyjanitor)\n",
            "  Downloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from pyjanitor) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyjanitor) (1.10.1)\n",
            "Requirement already satisfied: lazy-loader in /usr/local/lib/python3.10/dist-packages (from pyjanitor) (0.3)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.10/dist-packages (from pandas-flavor->pyjanitor) (1.5.3)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from pandas-flavor->pyjanitor) (2022.12.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->pyjanitor) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-flavor->pyjanitor) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-flavor->pyjanitor) (2022.7.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from xarray->pandas-flavor->pyjanitor) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas-flavor->pyjanitor) (1.16.0)\n",
            "Installing collected packages: pandas-flavor, pyjanitor\n",
            "Successfully installed pandas-flavor-0.6.0 pyjanitor-0.24.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lazy_loader/__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "# Install package pyjanitor since it is not part of the standard packages\n",
        "# of Google Colab\n",
        "\n",
        "import importlib\n",
        "\n",
        "# Check if package is installed\n",
        "package_name = \"pyjanitor\"\n",
        "spec = importlib.util.find_spec(package_name)\n",
        "if spec is None:\n",
        "    # Package is not installed, install it via pip\n",
        "    !pip install pyjanitor\n",
        "else:\n",
        "    print(f\"{package_name} is already installed\")\n",
        "\n",
        "import janitor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2516jhMiVxrJ",
      "metadata": {
        "id": "2516jhMiVxrJ"
      },
      "source": [
        "<a name=\"2\"></a>\n",
        "#2.&nbsp;Import dataset\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IF9lS_3ok1tO",
      "metadata": {
        "id": "IF9lS_3ok1tO"
      },
      "source": [
        "Next, we will import the processed dataset from [2_EDA](../Bike_usage_Bremen/2_EDA.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Xu3OXfHqVxfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu3OXfHqVxfa",
        "outputId": "adc9b723-a728-448e-a92a-d66e73776d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Set base url\n",
        "url = \"https://raw.githubusercontent.com/Rudinius/Bike_usage_Bremen/main/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2etHV6ODVsUV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "2etHV6ODVsUV",
        "outputId": "e2d4d2c6-e374-48df-c4de-6af6705d5fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            weekday  graf_moltke_straße_ostseite  \\\n",
              "date                                               \n",
              "2013-01-01        1                        261.0   \n",
              "2013-01-02        2                        750.0   \n",
              "2013-01-03        3                        931.0   \n",
              "2013-01-04        4                        500.0   \n",
              "2013-01-05        5                       1013.0   \n",
              "\n",
              "            graf_moltke_straße_westseite  hastedter_bruckenstraße  \\\n",
              "date                                                                \n",
              "2013-01-01                         290.0                    381.0   \n",
              "2013-01-02                         876.0                   1109.0   \n",
              "2013-01-03                        1015.0                   1603.0   \n",
              "2013-01-04                         587.0                   1284.0   \n",
              "2013-01-05                        1011.0                   1284.0   \n",
              "\n",
              "            langemarckstraße_ostseite  langemarckstraße_westseite  osterdeich  \\\n",
              "date                                                                            \n",
              "2013-01-01                      312.0                       308.0       870.0   \n",
              "2013-01-02                     1258.0                      1120.0      2169.0   \n",
              "2013-01-03                     1556.0                      1480.0      2295.0   \n",
              "2013-01-04                      703.0                       626.0      1640.0   \n",
              "2013-01-05                     1856.0                      1621.0      4128.0   \n",
              "\n",
              "            radweg_kleine_weser  schwachhauser_ring  \\\n",
              "date                                                  \n",
              "2013-01-01                410.0               391.0   \n",
              "2013-01-02               1762.0               829.0   \n",
              "2013-01-03               2287.0              1196.0   \n",
              "2013-01-04               1548.0              1418.0   \n",
              "2013-01-05               4256.0              3075.0   \n",
              "\n",
              "            wachmannstraße_auswarts_sud  ...  tmax  prcp  snow   wdir  wspd  \\\n",
              "date                                     ...                                  \n",
              "2013-01-01                        514.0  ...   9.1   6.9   0.0  233.0  19.4   \n",
              "2013-01-02                       1786.0  ...   7.1   1.8   0.0  246.0  20.2   \n",
              "2013-01-03                       2412.0  ...  10.6   0.9   0.0  257.0  23.8   \n",
              "2013-01-04                        964.0  ...   9.7   0.0   0.0  276.0  25.2   \n",
              "2013-01-05                       2065.0  ...   8.6   0.1   0.0  293.0  20.2   \n",
              "\n",
              "            wpgt    pres  tsun  holiday          vacation  \n",
              "date                                                       \n",
              "2013-01-01  50.4  1001.8     0  Neujahr  Weihnachtsferien  \n",
              "2013-01-02  40.0  1017.5    30      NaN  Weihnachtsferien  \n",
              "2013-01-03  45.7  1024.5     0      NaN  Weihnachtsferien  \n",
              "2013-01-04  48.2  1029.5     0      NaN  Weihnachtsferien  \n",
              "2013-01-05  41.0  1029.9     0      NaN  Weihnachtsferien  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-5f213d07-d671-48bf-afc1-981ac579999e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weekday</th>\n",
              "      <th>graf_moltke_straße_ostseite</th>\n",
              "      <th>graf_moltke_straße_westseite</th>\n",
              "      <th>hastedter_bruckenstraße</th>\n",
              "      <th>langemarckstraße_ostseite</th>\n",
              "      <th>langemarckstraße_westseite</th>\n",
              "      <th>osterdeich</th>\n",
              "      <th>radweg_kleine_weser</th>\n",
              "      <th>schwachhauser_ring</th>\n",
              "      <th>wachmannstraße_auswarts_sud</th>\n",
              "      <th>...</th>\n",
              "      <th>tmax</th>\n",
              "      <th>prcp</th>\n",
              "      <th>snow</th>\n",
              "      <th>wdir</th>\n",
              "      <th>wspd</th>\n",
              "      <th>wpgt</th>\n",
              "      <th>pres</th>\n",
              "      <th>tsun</th>\n",
              "      <th>holiday</th>\n",
              "      <th>vacation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>1</td>\n",
              "      <td>261.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>870.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.1</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>50.4</td>\n",
              "      <td>1001.8</td>\n",
              "      <td>0</td>\n",
              "      <td>Neujahr</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>2</td>\n",
              "      <td>750.0</td>\n",
              "      <td>876.0</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>2169.0</td>\n",
              "      <td>1762.0</td>\n",
              "      <td>829.0</td>\n",
              "      <td>1786.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1017.5</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>3</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>1603.0</td>\n",
              "      <td>1556.0</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>2287.0</td>\n",
              "      <td>1196.0</td>\n",
              "      <td>2412.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>257.0</td>\n",
              "      <td>23.8</td>\n",
              "      <td>45.7</td>\n",
              "      <td>1024.5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>4</td>\n",
              "      <td>500.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>703.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>1640.0</td>\n",
              "      <td>1548.0</td>\n",
              "      <td>1418.0</td>\n",
              "      <td>964.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>25.2</td>\n",
              "      <td>48.2</td>\n",
              "      <td>1029.5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>5</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>1856.0</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>4128.0</td>\n",
              "      <td>4256.0</td>\n",
              "      <td>3075.0</td>\n",
              "      <td>2065.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1029.9</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f213d07-d671-48bf-afc1-981ac579999e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-47210fdb-b4ba-48b3-a417-a43d2698a65e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47210fdb-b4ba-48b3-a417-a43d2698a65e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-47210fdb-b4ba-48b3-a417-a43d2698a65e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f213d07-d671-48bf-afc1-981ac579999e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f213d07-d671-48bf-afc1-981ac579999e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Import dataset\n",
        "\n",
        "# We will also parse the date column as datetime64 and set it to the index column\n",
        "df = pd.read_csv(url + \"03_training_data/\" + \"2023-04-21_df_full.csv\",\n",
        "                         parse_dates=[0], index_col=[0])\n",
        "\n",
        "# Check the correct loading of dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LIog4gAun3Gh",
      "metadata": {
        "id": "LIog4gAun3Gh"
      },
      "source": [
        "<a name=\"3\"></a>\n",
        "# 3.&nbsp;Transform columns\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1KinSwc3oDMj",
      "metadata": {
        "id": "1KinSwc3oDMj"
      },
      "source": [
        "We need to transform the columns `holiday` and `vacation` using `One-Hot-Encoding` and masking to change the categorical columns to numerical columns. Then we need to drop the original columns.\n",
        "\n",
        "We will use `One-Hot-Encoding` for the `holiday` feature. We will use masking (replacing) for the `vacation` feature and thus only having one column for `vacation` with 1 for vacation and 0 for no vcation.\n",
        "\n",
        "The reason for keeping only this reduced information on `vacation` had been explained in [2_EDA](https://github.com/Rudinius/Bike_usage_Bremen/blob/57e21c8dd687aadc1498f82241cf662840c8b871/2_EDA.ipynb) and it turns out, that this actually decreased the train and dev error."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use One Hot Encoder only for encoding holiday feature\n",
        "OH_encoder = OneHotEncoder()\n",
        "\n",
        "transformed_array = OH_encoder.fit_transform(df[[\"holiday\"]]).toarray()\n",
        "df_holiday_transformed = pd.DataFrame(transformed_array,\n",
        "                              columns=OH_encoder.get_feature_names_out(),\n",
        "                              index = df.index)\n",
        "# Drop the columns with Holiday_nan as this hold no additional value\n",
        "df_holiday_transformed = df_holiday_transformed.drop([\"holiday_nan\"], axis=1)\n",
        "\n",
        "# Drop the old categorical column holiday\n",
        "df_transformed = df.drop([\"holiday\"], axis=1)\n",
        "\n",
        "# Add the new columns from OHE\n",
        "df_transformed = pd.concat([df_transformed, df_holiday_transformed], axis=1)\n",
        "\n",
        "# Create a mask for vacation or no vacation\n",
        "mask = df_transformed[\"vacation\"].isna()\n",
        "\n",
        "# Set the values to `0` or `1` according to mask\n",
        "df_transformed.loc[mask, \"vacation\"] = 0\n",
        "df_transformed.loc[np.invert(mask), \"vacation\"] = 1\n",
        "\n",
        "# Set datatype of column to int\n",
        "df_transformed[\"vacation\"] = df_transformed[\"vacation\"].astype(int)"
      ],
      "metadata": {
        "id": "NFVvATarzRGa",
        "outputId": "9a31270e-d751-43b9-abae-f25a6d4a80f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NFVvATarzRGa",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ex0TAxa6xPK6",
      "metadata": {
        "id": "Ex0TAxa6xPK6"
      },
      "source": [
        "We will add the year, month and day as seperate columns to give the algorithm the chance to pick up more granular and seasonal patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ZFMh5fPazIDm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "ZFMh5fPazIDm",
        "outputId": "891d844a-c2a1-4933-8ed6-e67b2cdd95ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            year  month  day  weekday  graf_moltke_straße_ostseite  \\\n",
              "2013-01-01  2013      1    1        1                        261.0   \n",
              "2013-01-02  2013      1    2        2                        750.0   \n",
              "2013-01-03  2013      1    3        3                        931.0   \n",
              "2013-01-04  2013      1    4        4                        500.0   \n",
              "2013-01-05  2013      1    5        5                       1013.0   \n",
              "\n",
              "            graf_moltke_straße_westseite  hastedter_bruckenstraße  \\\n",
              "2013-01-01                         290.0                    381.0   \n",
              "2013-01-02                         876.0                   1109.0   \n",
              "2013-01-03                        1015.0                   1603.0   \n",
              "2013-01-04                         587.0                   1284.0   \n",
              "2013-01-05                        1011.0                   1284.0   \n",
              "\n",
              "            langemarckstraße_ostseite  langemarckstraße_westseite  osterdeich  \\\n",
              "2013-01-01                      312.0                       308.0       870.0   \n",
              "2013-01-02                     1258.0                      1120.0      2169.0   \n",
              "2013-01-03                     1556.0                      1480.0      2295.0   \n",
              "2013-01-04                      703.0                       626.0      1640.0   \n",
              "2013-01-05                     1856.0                      1621.0      4128.0   \n",
              "\n",
              "            ...  holiday_1_weihnachtsfeiertag  holiday_2_weihnachtsfeiertag  \\\n",
              "2013-01-01  ...                           0.0                           0.0   \n",
              "2013-01-02  ...                           0.0                           0.0   \n",
              "2013-01-03  ...                           0.0                           0.0   \n",
              "2013-01-04  ...                           0.0                           0.0   \n",
              "2013-01-05  ...                           0.0                           0.0   \n",
              "\n",
              "            holiday_christi_himmelfahrt  holiday_karfreitag  holiday_neujahr  \\\n",
              "2013-01-01                          0.0                 0.0              1.0   \n",
              "2013-01-02                          0.0                 0.0              0.0   \n",
              "2013-01-03                          0.0                 0.0              0.0   \n",
              "2013-01-04                          0.0                 0.0              0.0   \n",
              "2013-01-05                          0.0                 0.0              0.0   \n",
              "\n",
              "            holiday_ostermontag  holiday_pfingstmontag  \\\n",
              "2013-01-01                  0.0                    0.0   \n",
              "2013-01-02                  0.0                    0.0   \n",
              "2013-01-03                  0.0                    0.0   \n",
              "2013-01-04                  0.0                    0.0   \n",
              "2013-01-05                  0.0                    0.0   \n",
              "\n",
              "            holiday_reformationstag  holiday_tag_der_arbeit  \\\n",
              "2013-01-01                      0.0                     0.0   \n",
              "2013-01-02                      0.0                     0.0   \n",
              "2013-01-03                      0.0                     0.0   \n",
              "2013-01-04                      0.0                     0.0   \n",
              "2013-01-05                      0.0                     0.0   \n",
              "\n",
              "            holiday_tag_der_deutschen_einheit  \n",
              "2013-01-01                                0.0  \n",
              "2013-01-02                                0.0  \n",
              "2013-01-03                                0.0  \n",
              "2013-01-04                                0.0  \n",
              "2013-01-05                                0.0  \n",
              "\n",
              "[5 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1796f9fd-e1fb-4c15-ac2e-a46de750b847\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>weekday</th>\n",
              "      <th>graf_moltke_straße_ostseite</th>\n",
              "      <th>graf_moltke_straße_westseite</th>\n",
              "      <th>hastedter_bruckenstraße</th>\n",
              "      <th>langemarckstraße_ostseite</th>\n",
              "      <th>langemarckstraße_westseite</th>\n",
              "      <th>osterdeich</th>\n",
              "      <th>...</th>\n",
              "      <th>holiday_1_weihnachtsfeiertag</th>\n",
              "      <th>holiday_2_weihnachtsfeiertag</th>\n",
              "      <th>holiday_christi_himmelfahrt</th>\n",
              "      <th>holiday_karfreitag</th>\n",
              "      <th>holiday_neujahr</th>\n",
              "      <th>holiday_ostermontag</th>\n",
              "      <th>holiday_pfingstmontag</th>\n",
              "      <th>holiday_reformationstag</th>\n",
              "      <th>holiday_tag_der_arbeit</th>\n",
              "      <th>holiday_tag_der_deutschen_einheit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>261.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>870.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>750.0</td>\n",
              "      <td>876.0</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>2169.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>1603.0</td>\n",
              "      <td>1556.0</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>500.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>703.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>1640.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>1856.0</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>4128.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1796f9fd-e1fb-4c15-ac2e-a46de750b847')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-31ea68b1-06b9-4a9d-b1ea-055ac111e4ee\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31ea68b1-06b9-4a9d-b1ea-055ac111e4ee')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-31ea68b1-06b9-4a9d-b1ea-055ac111e4ee button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1796f9fd-e1fb-4c15-ac2e-a46de750b847 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1796f9fd-e1fb-4c15-ac2e-a46de750b847');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_date = pd.DataFrame(data = {\n",
        "    \"year\": df.index.year,\n",
        "    \"month\": df.index.month,\n",
        "    \"day\": df.index.day\n",
        "}, index=pd.to_datetime(df.index.values))\n",
        "\n",
        "df_transformed_date = (pd.concat([df_date, df_transformed], axis=1)\n",
        "                        .clean_names(strip_underscores=\"both\"))\n",
        "\n",
        "# Check dataframe\n",
        "df_transformed_date.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cYhxv0nmxmEp",
      "metadata": {
        "id": "cYhxv0nmxmEp"
      },
      "source": [
        "Now, after all those transformations, we have out final dataset, to train our machine learning algorithms on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gBM3I6LFOHL9",
      "metadata": {
        "id": "gBM3I6LFOHL9"
      },
      "source": [
        "<a name=\"4\"></a>\n",
        "# 4.&nbsp;Establish baseline benchmark\n",
        "[Content](#content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VgkVXhdAx6zB",
      "metadata": {
        "id": "VgkVXhdAx6zB"
      },
      "source": [
        "For our current task of creating model a to predict the amount of cyclers for a given day, we do not have any baseline metric score to measure our model against.\n",
        "For this reason, we will create a naive baseline model. For this, we will simply predict the amount of a day based on the value of previous day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6mu5aaMpO42j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mu5aaMpO42j",
        "outputId": "e1858375-ec2c-4aac-e27f-8112ca7f6b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 9083.225418\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model's performance using RMSE\n",
        "\n",
        "# Select the `Total` column as our y_dev and preds arrays\n",
        "y = y_hat = df.loc[:,\"total\"]\n",
        "\n",
        "rmse = 0\n",
        "length = y.shape[0]\n",
        "\n",
        "# Loop from 0 to second last entry, as we can only use seconds last entry to\n",
        "# predict the last entry of series\n",
        "for i in range(length-1):\n",
        "    # The mean_sqared_error function expects an array as input, therfore we\n",
        "    # concatenate the range from current value to current value + 1 (excluding)\n",
        "    rmse += np.sqrt(mean_squared_error(y[i+1:i+2], y_hat[i:i+1]))\n",
        "\n",
        "# Divide rmse value by number of pairs\n",
        "rmse = rmse / (length-1)\n",
        "print(\"RMSE: %f\" % (rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6O5OFAwW9Pm",
      "metadata": {
        "id": "f6O5OFAwW9Pm"
      },
      "source": [
        "If we were naivly predicting the current value with the last value, we get an error over the entire dataset of approximately $9,100$.\n",
        "\n",
        "This is our naive benchmark to compare our model against."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YHm0GDHUmczY",
      "metadata": {
        "id": "YHm0GDHUmczY"
      },
      "source": [
        "Another method would be to predict the value of a given day by the average of all the other equal days in the dataset (e.g., to predict 18.08.2017, we take the average of all other 18.08. days in the dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "kOSNaRxAdoCA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOSNaRxAdoCA",
        "outputId": "8f854266-b8ef-40d1-c04e-7c65b8bd3eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 10282.852522084184\n"
          ]
        }
      ],
      "source": [
        "# Initialize squared error\n",
        "se = 0\n",
        "\n",
        "# Get the total number of examples\n",
        "m = df.shape[0]\n",
        "\n",
        "for i in df.index:\n",
        "    day = i.day\n",
        "    month = i.month\n",
        "    year = i.year\n",
        "\n",
        "    # create a mask for given day but exclude the day we want to predict\n",
        "    mask = (df.index.day == day) & (df.index.month == month) & (df.index.year != year)\n",
        "\n",
        "    # Get value for current day and mean values of all the other same days in the dataset\n",
        "    y = df.loc[i, \"total\"]\n",
        "    y_hat = df.loc[mask,\"total\"].mean()\n",
        "\n",
        "    # Calculate the squared error\n",
        "    se += (y - y_hat)**2\n",
        "\n",
        "# Calculate mean squared error\n",
        "mse = se / m\n",
        "\n",
        "# Calcualte root mean squared error\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SQ-iEzyHoc8M",
      "metadata": {
        "id": "SQ-iEzyHoc8M"
      },
      "source": [
        "With this second approach, of average all our previous values for the given day and using this as our forecast, we get an error over the entire dataset of approximately $10,300$.\n",
        "\n",
        "The error of this second naive approach is close to the first approach.\n",
        "Both approaches could be seen as human-level as this would be a typical approach of a human, to predict the value of any given day. A domain expert, who also looks at more data and e.g., compares also the temperatures, could come up with better estimates. However humans are typically not very good in accurately predicting complex time-series data. The expected Bayes error (least possible error) should therefore be much lower."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5HqwjOgkxauH",
      "metadata": {
        "id": "5HqwjOgkxauH"
      },
      "source": [
        "<a name=\"5\"></a>\n",
        "# 5.&nbsp;Training machine learning algorithms\n",
        "[Content](#content)\n",
        "\n",
        "We are going to train 1 shallow machine learning algorithm and 2 deep machine learning algorithms to be able to compare performances. Those are:\n",
        "\n",
        "* XGBoost\n",
        "* Multilayer Perceptron (MLP -- standard NN)\n",
        "* Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b154c25",
      "metadata": {
        "id": "9b154c25"
      },
      "source": [
        "<a name=\"5.1.\"></a>\n",
        "## 5.1. Adding sequential data to our model\n",
        "\n",
        "[Content](#content)\n",
        "\n",
        "In contrast to RNNs where the algorithm takes automically the datapoints of previous timesteps into account, XGBoost and MLPs do not have direct access to the sequential data of previous time steps.\n",
        "Those algorithms have only indirect knowledge via the learned model parameters. RNNs however directly include the previous timestep for learning the parameters of the current timestep.\n",
        "\n",
        "We will add the data points of the previous time steps as features to the feature vector.\n",
        "\n",
        "In this case, we will only add the last 3 values, as the observed improvement of accuracy (RMSE score) is drastically decressing with each further time step added after 3 steps.\n",
        "\n",
        "Improvements:\n",
        "* 1 day 6291 2,8%\n",
        "* 2 day 6157 2,1%\n",
        "* 3 day 6120 0,6%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842f23eb",
      "metadata": {
        "id": "842f23eb"
      },
      "source": [
        "The following code creates a dataframe with a variable amount of time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a03f3499",
      "metadata": {
        "id": "a03f3499",
        "outputId": "9556145d-c418-411a-b9db-fed7d9d6b360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Create empty new dataframe\n",
        "df_lagged_days = pd.DataFrame({})\n",
        "\n",
        "# Select the number of lagged days\n",
        "go_back_x_days = 3\n",
        "\n",
        "for i in range(go_back_x_days):\n",
        "    # Shift the values in \"Total\" by i and assign to new column prev_Total_i+1\n",
        "    df_lagged_days[f'prev_total_{i+1}'] = df_transformed_date['total'].shift(i+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mO2Xt87cykEf",
      "metadata": {
        "id": "mO2Xt87cykEf"
      },
      "source": [
        "<a name=\"5.2.\"></a>\n",
        "## 5.2. XGBoost\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZgSdeq3fOxaQ",
      "metadata": {
        "id": "ZgSdeq3fOxaQ"
      },
      "source": [
        "For XGBoost, we will add the dataframe `df_lagged_days` to our dataset. Because we do not have all the information about the previous days for the first `go_back_x_days`, we drop the rows with `na` values. The parameter on how far to go back in time, has therefore an impact on the length of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "outputId": "ab544948-821c-406c-83f5-a734701062a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "p8e0WfWKj6Gn"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            year  month  day  weekday  graf_moltke_straße_ostseite  \\\n",
              "2013-01-04  2013      1    4        4                        500.0   \n",
              "2013-01-05  2013      1    5        5                       1013.0   \n",
              "2013-01-06  2013      1    6        6                        819.0   \n",
              "2013-01-07  2013      1    7        0                       1123.0   \n",
              "2013-01-08  2013      1    8        1                       1321.0   \n",
              "...          ...    ...  ...      ...                          ...   \n",
              "2022-12-27  2022     12   27        1                        693.0   \n",
              "2022-12-28  2022     12   28        2                        643.0   \n",
              "2022-12-29  2022     12   29        3                        654.0   \n",
              "2022-12-30  2022     12   30        4                        757.0   \n",
              "2022-12-31  2022     12   31        5                        371.0   \n",
              "\n",
              "            graf_moltke_straße_westseite  hastedter_bruckenstraße  \\\n",
              "2013-01-04                         587.0                   1284.0   \n",
              "2013-01-05                        1011.0                   1284.0   \n",
              "2013-01-06                         905.0                   1284.0   \n",
              "2013-01-07                        1318.0                   3070.0   \n",
              "2013-01-08                        1584.0                   4673.0   \n",
              "...                                  ...                      ...   \n",
              "2022-12-27                         612.0                   1495.0   \n",
              "2022-12-28                         585.0                   1076.0   \n",
              "2022-12-29                         648.0                   1076.0   \n",
              "2022-12-30                         665.0                   1076.0   \n",
              "2022-12-31                         367.0                    557.0   \n",
              "\n",
              "            langemarckstraße_ostseite  langemarckstraße_westseite  osterdeich  \\\n",
              "2013-01-04                      703.0                       626.0      1640.0   \n",
              "2013-01-05                     1856.0                      1621.0      4128.0   \n",
              "2013-01-06                     1602.0                      1215.0      4128.0   \n",
              "2013-01-07                     2637.0                      2268.0      3240.0   \n",
              "2013-01-08                     3082.0                      2694.0      4957.0   \n",
              "...                               ...                         ...         ...   \n",
              "2022-12-27                     1062.0                       915.0      2123.0   \n",
              "2022-12-28                      884.0                       820.0      1819.0   \n",
              "2022-12-29                     1014.0                       907.0      2013.0   \n",
              "2022-12-30                     1106.0                       976.0      2088.0   \n",
              "2022-12-31                      656.0                       404.0      1156.0   \n",
              "\n",
              "            ...  holiday_karfreitag  holiday_neujahr  holiday_ostermontag  \\\n",
              "2013-01-04  ...                 0.0              0.0                  0.0   \n",
              "2013-01-05  ...                 0.0              0.0                  0.0   \n",
              "2013-01-06  ...                 0.0              0.0                  0.0   \n",
              "2013-01-07  ...                 0.0              0.0                  0.0   \n",
              "2013-01-08  ...                 0.0              0.0                  0.0   \n",
              "...         ...                 ...              ...                  ...   \n",
              "2022-12-27  ...                 0.0              0.0                  0.0   \n",
              "2022-12-28  ...                 0.0              0.0                  0.0   \n",
              "2022-12-29  ...                 0.0              0.0                  0.0   \n",
              "2022-12-30  ...                 0.0              0.0                  0.0   \n",
              "2022-12-31  ...                 0.0              0.0                  0.0   \n",
              "\n",
              "            holiday_pfingstmontag  holiday_reformationstag  \\\n",
              "2013-01-04                    0.0                      0.0   \n",
              "2013-01-05                    0.0                      0.0   \n",
              "2013-01-06                    0.0                      0.0   \n",
              "2013-01-07                    0.0                      0.0   \n",
              "2013-01-08                    0.0                      0.0   \n",
              "...                           ...                      ...   \n",
              "2022-12-27                    0.0                      0.0   \n",
              "2022-12-28                    0.0                      0.0   \n",
              "2022-12-29                    0.0                      0.0   \n",
              "2022-12-30                    0.0                      0.0   \n",
              "2022-12-31                    0.0                      0.0   \n",
              "\n",
              "            holiday_tag_der_arbeit  holiday_tag_der_deutschen_einheit  \\\n",
              "2013-01-04                     0.0                                0.0   \n",
              "2013-01-05                     0.0                                0.0   \n",
              "2013-01-06                     0.0                                0.0   \n",
              "2013-01-07                     0.0                                0.0   \n",
              "2013-01-08                     0.0                                0.0   \n",
              "...                            ...                                ...   \n",
              "2022-12-27                     0.0                                0.0   \n",
              "2022-12-28                     0.0                                0.0   \n",
              "2022-12-29                     0.0                                0.0   \n",
              "2022-12-30                     0.0                                0.0   \n",
              "2022-12-31                     0.0                                0.0   \n",
              "\n",
              "            prev_total_1  prev_total_2  prev_total_3  \n",
              "2013-01-04       24851.0       19494.0        5795.0  \n",
              "2013-01-05       13475.0       24851.0       19494.0  \n",
              "2013-01-06       30643.0       13475.0       24851.0  \n",
              "2013-01-07       23582.0       30643.0       13475.0  \n",
              "2013-01-08       36246.0       23582.0       30643.0  \n",
              "...                  ...           ...           ...  \n",
              "2022-12-27        9520.0        8067.0       11206.0  \n",
              "2022-12-28       19231.0        9520.0        8067.0  \n",
              "2022-12-29       16241.0       19231.0        9520.0  \n",
              "2022-12-30       18006.0       16241.0       19231.0  \n",
              "2022-12-31       19176.0       18006.0       16241.0  \n",
              "\n",
              "[3649 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-33ea58fa-45f0-4aca-aa1f-554fbab7f417\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>weekday</th>\n",
              "      <th>graf_moltke_straße_ostseite</th>\n",
              "      <th>graf_moltke_straße_westseite</th>\n",
              "      <th>hastedter_bruckenstraße</th>\n",
              "      <th>langemarckstraße_ostseite</th>\n",
              "      <th>langemarckstraße_westseite</th>\n",
              "      <th>osterdeich</th>\n",
              "      <th>...</th>\n",
              "      <th>holiday_karfreitag</th>\n",
              "      <th>holiday_neujahr</th>\n",
              "      <th>holiday_ostermontag</th>\n",
              "      <th>holiday_pfingstmontag</th>\n",
              "      <th>holiday_reformationstag</th>\n",
              "      <th>holiday_tag_der_arbeit</th>\n",
              "      <th>holiday_tag_der_deutschen_einheit</th>\n",
              "      <th>prev_total_1</th>\n",
              "      <th>prev_total_2</th>\n",
              "      <th>prev_total_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>500.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>703.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>1640.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24851.0</td>\n",
              "      <td>19494.0</td>\n",
              "      <td>5795.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>1856.0</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>4128.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13475.0</td>\n",
              "      <td>24851.0</td>\n",
              "      <td>19494.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-06</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>819.0</td>\n",
              "      <td>905.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>1602.0</td>\n",
              "      <td>1215.0</td>\n",
              "      <td>4128.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30643.0</td>\n",
              "      <td>13475.0</td>\n",
              "      <td>24851.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-07</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>1318.0</td>\n",
              "      <td>3070.0</td>\n",
              "      <td>2637.0</td>\n",
              "      <td>2268.0</td>\n",
              "      <td>3240.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23582.0</td>\n",
              "      <td>30643.0</td>\n",
              "      <td>13475.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-08</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1321.0</td>\n",
              "      <td>1584.0</td>\n",
              "      <td>4673.0</td>\n",
              "      <td>3082.0</td>\n",
              "      <td>2694.0</td>\n",
              "      <td>4957.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36246.0</td>\n",
              "      <td>23582.0</td>\n",
              "      <td>30643.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>2022</td>\n",
              "      <td>12</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>693.0</td>\n",
              "      <td>612.0</td>\n",
              "      <td>1495.0</td>\n",
              "      <td>1062.0</td>\n",
              "      <td>915.0</td>\n",
              "      <td>2123.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9520.0</td>\n",
              "      <td>8067.0</td>\n",
              "      <td>11206.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>2022</td>\n",
              "      <td>12</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>643.0</td>\n",
              "      <td>585.0</td>\n",
              "      <td>1076.0</td>\n",
              "      <td>884.0</td>\n",
              "      <td>820.0</td>\n",
              "      <td>1819.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19231.0</td>\n",
              "      <td>9520.0</td>\n",
              "      <td>8067.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>2022</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>654.0</td>\n",
              "      <td>648.0</td>\n",
              "      <td>1076.0</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>907.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16241.0</td>\n",
              "      <td>19231.0</td>\n",
              "      <td>9520.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>2022</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>757.0</td>\n",
              "      <td>665.0</td>\n",
              "      <td>1076.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>2088.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18006.0</td>\n",
              "      <td>16241.0</td>\n",
              "      <td>19231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-31</th>\n",
              "      <td>2022</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>371.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>557.0</td>\n",
              "      <td>656.0</td>\n",
              "      <td>404.0</td>\n",
              "      <td>1156.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19176.0</td>\n",
              "      <td>18006.0</td>\n",
              "      <td>16241.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3649 rows × 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33ea58fa-45f0-4aca-aa1f-554fbab7f417')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-3f2ef619-f159-4eb7-998f-c7b894587f24\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f2ef619-f159-4eb7-998f-c7b894587f24')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-3f2ef619-f159-4eb7-998f-c7b894587f24 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33ea58fa-45f0-4aca-aa1f-554fbab7f417 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33ea58fa-45f0-4aca-aa1f-554fbab7f417');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Concat new dataframe with old dataframe\n",
        "# Using bfill strategy on dataset since the first few days will have NaN values\n",
        "# Using pyjanitor to clean up names\n",
        "df_transformed_date_lagged = (pd.concat([df_transformed_date, df_lagged_days], axis=1)\n",
        "                              .dropna(axis=0)\n",
        "                              .clean_names(strip_underscores=\"both\"))\n",
        "\n",
        "# Check output\n",
        "df_transformed_date_lagged"
      ],
      "id": "p8e0WfWKj6Gn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5.2.1\"></a>\n",
        "### 5.2.1 Split data into train and dev set and standardize training data\n",
        "[Content](#content)\n",
        "\n",
        "Now, we will split the data into a training set and into a dev set. Also here we select the final futures, which we want to use to train our model.\n",
        "\n",
        "Highly correlated features `tavg`, `tmin`, `wpgt` will be removed and features with no correlation to our target value will be also removed (`wdir`).\n",
        "\n",
        "When splitting into train and dev set, we will not shuffle the data. This ensures that the validation results are more realistic since they are being evaluated on the data collected after the model was trained. Otherwise we would introduce a \"leakage error\" into our data."
      ],
      "metadata": {
        "id": "XH_6MbWERL_5"
      },
      "id": "XH_6MbWERL_5"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "nxeQ39ojh2Y-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxeQ39ojh2Y-",
        "outputId": "57b0c09f-d439-460e-f855-0c7791b9b418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (2919, 24) y_train:  (2919,)\n",
            "X_dev:  (730, 24) y_dev:  (730,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Load the data into a pandas dataframe\n",
        "data = df_transformed_date_lagged\n",
        "# Define the features and target\n",
        "# Higly correlated features have been removed (tavg, tmin, wpgt)\n",
        "# Features with no correlation have been removed (wdir)\n",
        "\n",
        "# Only vacation\n",
        "features = ['year', 'month', 'day', 'weekday', 'tmax', 'prcp',\n",
        "            'snow', 'wspd', 'pres', 'tsun',\n",
        "            'holiday_1_weihnachtsfeiertag', 'holiday_2_weihnachtsfeiertag',\n",
        "            'holiday_christi_himmelfahrt', 'holiday_karfreitag', 'holiday_neujahr',\n",
        "            'holiday_ostermontag', 'holiday_pfingstmontag', 'holiday_reformationstag',\n",
        "            'holiday_tag_der_arbeit', 'holiday_tag_der_deutschen_einheit',\n",
        "            'vacation', 'prev_total_1', 'prev_total_2', 'prev_total_3']\n",
        "\n",
        "target = 'total'\n",
        "\n",
        "# Split the data into training and dev sets\n",
        "# We set shuffle to False\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(data[features], data[target],\n",
        "                                                    test_size=0.2, shuffle=False, random_state=0)\n",
        "\n",
        "print(\"X_train: \", X_train.shape, \"y_train: \", y_train.shape)\n",
        "print(\"X_dev: \", X_dev.shape, \"y_dev: \", y_dev.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1GVZoPCdit-",
      "metadata": {
        "id": "a1GVZoPCdit-"
      },
      "source": [
        "Finally, we will standardize our dataset. Standarization will generally improve learning speed of the models and can help to improve the accuarcy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc0f786-c2e5-440c-d67a-3236f137110d",
        "id": "ZwsuKeAWsUr8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Standardize and fit to the training set only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the same standardization to the dev set\n",
        "X_dev_scaled = scaler.transform(X_dev)"
      ],
      "id": "ZwsuKeAWsUr8"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s-R4SrdPL4NX"
      },
      "id": "s-R4SrdPL4NX"
    },
    {
      "cell_type": "markdown",
      "id": "amR72D-bg9Ea",
      "metadata": {
        "id": "amR72D-bg9Ea"
      },
      "source": [
        "<a name=\"5.2.2\"></a>\n",
        "### 5.2.2 Using GridSeachCV to select the optimal parameters\n",
        "[Content](#content)\n",
        "\n",
        "We will use `GridSearchCV` to select optimal parameters among the preselected ranges for the training data. Furthermore we will create our own scoring metric, to evaluate the performance of the parameters found with `GridSearchCV`.\n",
        "\n",
        "`GridSearchCV` is using `KFold` for regression problems as default. However `KFold` would split the training data in such a way, that later data will be evaluated against earlier data, introducing `leackage error`.\n",
        "Therefore we do not use the default, but create splits with `TimeSeriesSplit` and pass this to `GridSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom function for evaluating GridSearchCV\n",
        "def custom_rmse(y, y_hat):\n",
        "    return np.sqrt(mean_squared_error(y, y_hat))\n",
        "\n",
        "# Create the scoring object using the custom scoring function\n",
        "custom_scorer_rmse = make_scorer(custom_rmse)"
      ],
      "metadata": {
        "id": "TB-c62B8Je2b",
        "outputId": "138b9087-56a3-4d39-ce49-a18b35c68c3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TB-c62B8Je2b",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "248a44d8-1fc5-4bf2-d5f2-428c3e60df94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU0g5nDdCaX4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 162 candidates, totalling 648 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 12, 'n_estimators': 1000, 'reg_alpha': 8.0, 'reg_lambda': 8.0}\n",
            "7136.89129076001\n",
            "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
            "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
            "             min_child_weight=12, missing=nan, monotone_constraints=None,\n",
            "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
            "             predictor=None, random_state=0, ...)\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    'n_estimators': [1000],\n",
        "    'learning_rate': [0.05],\n",
        "    'max_depth': [5, 10, 20],           # max. depth of tree\n",
        "    'min_child_weight': [3, 6, 12],     # min. weight for splitting into new node\n",
        "    'colsample_bytree': [0.7, 0.8],     # subsample ratio of columns\n",
        "    'reg_alpha': [2.0, 4.0, 8.0],       # L1 regularization\n",
        "    'reg_lambda': [4.0, 8.0, 16.0],    # L2 regularization\n",
        "}\n",
        "\n",
        "# Getting time series splits using TimeSeriesSplit\n",
        "n = 4\n",
        "tscv = TimeSeriesSplit(n_splits=n)\n",
        "splits = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(tscv.split(X_train)):\n",
        "    splits.append((train_index, test_index))\n",
        "\n",
        "# Define the estimator\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)\n",
        "\n",
        "# Define GridSearch and fit GridSearch on the training data with the custom scorer and custom splits\n",
        "grid_search = GridSearchCV(xg_reg, param_grid=params, cv=splits, scoring=custom_scorer_rmse, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and score as well as the best model to that score\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)"
      ],
      "id": "dU0g5nDdCaX4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 7, 'n_estimators': 1000, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'subsample': 1.0}\n"
      ],
      "metadata": {
        "id": "b8nRHJ0YVnGd"
      },
      "id": "b8nRHJ0YVnGd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 13, 'min_child_weight': 5, 'n_estimators': 1000, 'reg_alpha': 7.0, 'reg_lambda': 4.0, 'subsample': 1.0}\n"
      ],
      "metadata": {
        "id": "XLWBhuPRf01z"
      },
      "id": "XLWBhuPRf01z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 12, 'n_estimators': 1000, 'reg_alpha': 8.0, 'reg_lambda': 8.0}\n"
      ],
      "metadata": {
        "id": "PTRgEhqMF0p9"
      },
      "id": "PTRgEhqMF0p9"
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "u9DKLFqkmIRm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9DKLFqkmIRm",
        "outputId": "d6523388-a0a7-4e1d-ede5-93bb0b899c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 8.210400\n",
            "Dev RMSE: 7201.797497\n"
          ]
        }
      ],
      "source": [
        "# Build the XGBoost regressor model with selected hyper parameters\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.8, learning_rate = 0.05,\n",
        "                          max_depth = 12, n_estimators = 1000, reg_alpha = 5.0, reg_lambda = 5.0,\n",
        "                          subsample = 1.0, min_child_weight=5)\n",
        "\n",
        "xg_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the train set\n",
        "y_train_hat = xg_reg.predict(X_train_scaled)\n",
        "\n",
        "# Predict on the dev set\n",
        "y_dev_hat = xg_reg.predict(X_dev_scaled)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "# Training set\n",
        "rmse_train = custom_rmse(y_train, y_train_hat)\n",
        "print(\"Train RMSE: %f\" % (rmse_train))\n",
        "\n",
        "# Dev set\n",
        "rmse_dev = custom_rmse(y_dev, y_dev_hat)\n",
        "print(\"Dev RMSE: %f\" % (rmse_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fOFZ5oXgTT7V",
      "metadata": {
        "id": "fOFZ5oXgTT7V"
      },
      "source": [
        "<a name=\"5.3.\"></a>\n",
        "## 5.3. Multilayer Perceptron\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pWGJlB8pNl7m",
      "metadata": {
        "id": "pWGJlB8pNl7m"
      },
      "source": [
        "TO CHECK: Performance when standardizing/normalizing dataset\n",
        "TO CHECK: When adding the prev_total values, the accuracy becomes less. Check later with optimized MLP again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "CFbCaX6sKhZF",
      "metadata": {
        "id": "CFbCaX6sKhZF",
        "outputId": "a729b1a8-37e6-401f-ae50-93a1b4bf821e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 1s 4ms/step - loss: 1102781568.0000 - root_mean_squared_error: 33208.1562 - val_loss: 963155136.0000 - val_root_mean_squared_error: 31034.7402\n",
            "Epoch 2/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 681721216.0000 - root_mean_squared_error: 26109.7910 - val_loss: 405147104.0000 - val_root_mean_squared_error: 20128.2656\n",
            "Epoch 3/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 300345888.0000 - root_mean_squared_error: 17330.4902 - val_loss: 209261056.0000 - val_root_mean_squared_error: 14465.8584\n",
            "Epoch 4/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 172865904.0000 - root_mean_squared_error: 13147.8477 - val_loss: 150732384.0000 - val_root_mean_squared_error: 12277.3115\n",
            "Epoch 5/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 136477392.0000 - root_mean_squared_error: 11682.3535 - val_loss: 129532248.0000 - val_root_mean_squared_error: 11381.2236\n",
            "Epoch 6/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 119899552.0000 - root_mean_squared_error: 10949.8652 - val_loss: 119449200.0000 - val_root_mean_squared_error: 10929.2822\n",
            "Epoch 7/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 114695160.0000 - root_mean_squared_error: 10709.5830 - val_loss: 112337952.0000 - val_root_mean_squared_error: 10598.9600\n",
            "Epoch 8/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 104846552.0000 - root_mean_squared_error: 10239.4609 - val_loss: 109059680.0000 - val_root_mean_squared_error: 10443.1641\n",
            "Epoch 9/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 104422368.0000 - root_mean_squared_error: 10218.7266 - val_loss: 106545624.0000 - val_root_mean_squared_error: 10322.0938\n",
            "Epoch 10/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 99352864.0000 - root_mean_squared_error: 9967.5908 - val_loss: 104134336.0000 - val_root_mean_squared_error: 10204.6230\n",
            "Epoch 11/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 97776184.0000 - root_mean_squared_error: 9888.1836 - val_loss: 103692432.0000 - val_root_mean_squared_error: 10182.9482\n",
            "Epoch 12/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 100051288.0000 - root_mean_squared_error: 10002.5645 - val_loss: 103240320.0000 - val_root_mean_squared_error: 10160.7246\n",
            "Epoch 13/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 96135000.0000 - root_mean_squared_error: 9804.8457 - val_loss: 103918304.0000 - val_root_mean_squared_error: 10194.0332\n",
            "Epoch 14/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 96666416.0000 - root_mean_squared_error: 9831.9082 - val_loss: 101496712.0000 - val_root_mean_squared_error: 10074.5576\n",
            "Epoch 15/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 94781624.0000 - root_mean_squared_error: 9735.5850 - val_loss: 101972040.0000 - val_root_mean_squared_error: 10098.1211\n",
            "Epoch 16/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 95447144.0000 - root_mean_squared_error: 9769.7051 - val_loss: 101410184.0000 - val_root_mean_squared_error: 10070.2627\n",
            "Epoch 17/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 96469056.0000 - root_mean_squared_error: 9821.8662 - val_loss: 100448104.0000 - val_root_mean_squared_error: 10022.3799\n",
            "Epoch 18/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 92851072.0000 - root_mean_squared_error: 9635.9258 - val_loss: 101231056.0000 - val_root_mean_squared_error: 10061.3643\n",
            "Epoch 19/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 93773704.0000 - root_mean_squared_error: 9683.6826 - val_loss: 99401952.0000 - val_root_mean_squared_error: 9970.0527\n",
            "Epoch 20/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 95787352.0000 - root_mean_squared_error: 9787.1016 - val_loss: 100595008.0000 - val_root_mean_squared_error: 10029.7061\n",
            "Epoch 21/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 94747368.0000 - root_mean_squared_error: 9733.8262 - val_loss: 98781704.0000 - val_root_mean_squared_error: 9938.8984\n",
            "Epoch 22/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 94200680.0000 - root_mean_squared_error: 9705.7031 - val_loss: 101665872.0000 - val_root_mean_squared_error: 10082.9492\n",
            "Epoch 23/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 92687120.0000 - root_mean_squared_error: 9627.4150 - val_loss: 100586496.0000 - val_root_mean_squared_error: 10029.2822\n",
            "Epoch 24/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 93906032.0000 - root_mean_squared_error: 9690.5127 - val_loss: 99391816.0000 - val_root_mean_squared_error: 9969.5439\n",
            "Epoch 25/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 93356856.0000 - root_mean_squared_error: 9662.1348 - val_loss: 97592464.0000 - val_root_mean_squared_error: 9878.8896\n",
            "Epoch 26/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 93279360.0000 - root_mean_squared_error: 9658.1240 - val_loss: 99880544.0000 - val_root_mean_squared_error: 9994.0254\n",
            "Epoch 27/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 92157896.0000 - root_mean_squared_error: 9599.8906 - val_loss: 98437784.0000 - val_root_mean_squared_error: 9921.5820\n",
            "Epoch 28/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 93072584.0000 - root_mean_squared_error: 9647.4131 - val_loss: 97825328.0000 - val_root_mean_squared_error: 9890.6689\n",
            "Epoch 29/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 92432168.0000 - root_mean_squared_error: 9614.1650 - val_loss: 98803600.0000 - val_root_mean_squared_error: 9940.0000\n",
            "Epoch 30/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 91011344.0000 - root_mean_squared_error: 9539.9863 - val_loss: 98906776.0000 - val_root_mean_squared_error: 9945.1885\n",
            "Epoch 31/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 92617536.0000 - root_mean_squared_error: 9623.8008 - val_loss: 97154760.0000 - val_root_mean_squared_error: 9856.7109\n",
            "Epoch 32/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 92069816.0000 - root_mean_squared_error: 9595.3018 - val_loss: 97891064.0000 - val_root_mean_squared_error: 9893.9912\n",
            "Epoch 33/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 91396592.0000 - root_mean_squared_error: 9560.1562 - val_loss: 97294104.0000 - val_root_mean_squared_error: 9863.7773\n",
            "Epoch 34/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 90830128.0000 - root_mean_squared_error: 9530.4844 - val_loss: 97725912.0000 - val_root_mean_squared_error: 9885.6416\n",
            "Epoch 35/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 90586456.0000 - root_mean_squared_error: 9517.6914 - val_loss: 96552760.0000 - val_root_mean_squared_error: 9826.1260\n",
            "Epoch 36/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 90517152.0000 - root_mean_squared_error: 9514.0498 - val_loss: 98074536.0000 - val_root_mean_squared_error: 9903.2588\n",
            "Epoch 37/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 92679248.0000 - root_mean_squared_error: 9627.0059 - val_loss: 97098968.0000 - val_root_mean_squared_error: 9853.8809\n",
            "Epoch 38/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89239104.0000 - root_mean_squared_error: 9446.6455 - val_loss: 98338096.0000 - val_root_mean_squared_error: 9916.5566\n",
            "Epoch 39/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 90414072.0000 - root_mean_squared_error: 9508.6318 - val_loss: 95954632.0000 - val_root_mean_squared_error: 9795.6436\n",
            "Epoch 40/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 91889440.0000 - root_mean_squared_error: 9585.8984 - val_loss: 95532456.0000 - val_root_mean_squared_error: 9774.0703\n",
            "Epoch 41/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 89324000.0000 - root_mean_squared_error: 9451.1377 - val_loss: 96482704.0000 - val_root_mean_squared_error: 9822.5605\n",
            "Epoch 42/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 92023896.0000 - root_mean_squared_error: 9592.9082 - val_loss: 96964472.0000 - val_root_mean_squared_error: 9847.0537\n",
            "Epoch 43/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 90986208.0000 - root_mean_squared_error: 9538.6689 - val_loss: 95572920.0000 - val_root_mean_squared_error: 9776.1406\n",
            "Epoch 44/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 89660120.0000 - root_mean_squared_error: 9468.9023 - val_loss: 95574792.0000 - val_root_mean_squared_error: 9776.2363\n",
            "Epoch 45/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 90652640.0000 - root_mean_squared_error: 9521.1680 - val_loss: 94886744.0000 - val_root_mean_squared_error: 9740.9824\n",
            "Epoch 46/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 92036488.0000 - root_mean_squared_error: 9593.5645 - val_loss: 95033072.0000 - val_root_mean_squared_error: 9748.4912\n",
            "Epoch 47/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 91093448.0000 - root_mean_squared_error: 9544.2891 - val_loss: 94819976.0000 - val_root_mean_squared_error: 9737.5547\n",
            "Epoch 48/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 88657032.0000 - root_mean_squared_error: 9415.7861 - val_loss: 94709832.0000 - val_root_mean_squared_error: 9731.8975\n",
            "Epoch 49/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 87555552.0000 - root_mean_squared_error: 9357.1123 - val_loss: 95675680.0000 - val_root_mean_squared_error: 9781.3945\n",
            "Epoch 50/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 89423344.0000 - root_mean_squared_error: 9456.3916 - val_loss: 94634096.0000 - val_root_mean_squared_error: 9728.0059\n",
            "Epoch 51/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 91240112.0000 - root_mean_squared_error: 9551.9688 - val_loss: 94987048.0000 - val_root_mean_squared_error: 9746.1299\n",
            "Epoch 52/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 87967568.0000 - root_mean_squared_error: 9379.1025 - val_loss: 94586456.0000 - val_root_mean_squared_error: 9725.5566\n",
            "Epoch 53/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89439528.0000 - root_mean_squared_error: 9457.2471 - val_loss: 93947160.0000 - val_root_mean_squared_error: 9692.6348\n",
            "Epoch 54/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 88526536.0000 - root_mean_squared_error: 9408.8545 - val_loss: 95061912.0000 - val_root_mean_squared_error: 9749.9697\n",
            "Epoch 55/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 89194128.0000 - root_mean_squared_error: 9444.2646 - val_loss: 96230024.0000 - val_root_mean_squared_error: 9809.6904\n",
            "Epoch 56/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 88294984.0000 - root_mean_squared_error: 9396.5410 - val_loss: 93823952.0000 - val_root_mean_squared_error: 9686.2764\n",
            "Epoch 57/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 87841728.0000 - root_mean_squared_error: 9372.3916 - val_loss: 94723848.0000 - val_root_mean_squared_error: 9732.6182\n",
            "Epoch 58/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 85831576.0000 - root_mean_squared_error: 9264.5332 - val_loss: 95231896.0000 - val_root_mean_squared_error: 9758.6836\n",
            "Epoch 59/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 92532160.0000 - root_mean_squared_error: 9619.3643 - val_loss: 93783824.0000 - val_root_mean_squared_error: 9684.2051\n",
            "Epoch 60/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88914104.0000 - root_mean_squared_error: 9429.4277 - val_loss: 94003640.0000 - val_root_mean_squared_error: 9695.5479\n",
            "Epoch 61/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 90462768.0000 - root_mean_squared_error: 9511.1914 - val_loss: 96874944.0000 - val_root_mean_squared_error: 9842.5068\n",
            "Epoch 62/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88764096.0000 - root_mean_squared_error: 9421.4697 - val_loss: 95927800.0000 - val_root_mean_squared_error: 9794.2734\n",
            "Epoch 63/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 92463112.0000 - root_mean_squared_error: 9615.7744 - val_loss: 93542784.0000 - val_root_mean_squared_error: 9671.7520\n",
            "Epoch 64/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 89687032.0000 - root_mean_squared_error: 9470.3242 - val_loss: 93315360.0000 - val_root_mean_squared_error: 9659.9873\n",
            "Epoch 65/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 90253560.0000 - root_mean_squared_error: 9500.1875 - val_loss: 94043104.0000 - val_root_mean_squared_error: 9697.5820\n",
            "Epoch 66/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 89142976.0000 - root_mean_squared_error: 9441.5557 - val_loss: 94357240.0000 - val_root_mean_squared_error: 9713.7656\n",
            "Epoch 67/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 90645688.0000 - root_mean_squared_error: 9520.8027 - val_loss: 93242304.0000 - val_root_mean_squared_error: 9656.2051\n",
            "Epoch 68/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89050192.0000 - root_mean_squared_error: 9436.6406 - val_loss: 93533392.0000 - val_root_mean_squared_error: 9671.2666\n",
            "Epoch 69/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 90446648.0000 - root_mean_squared_error: 9510.3447 - val_loss: 93989168.0000 - val_root_mean_squared_error: 9694.8008\n",
            "Epoch 70/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89100624.0000 - root_mean_squared_error: 9439.3125 - val_loss: 93507048.0000 - val_root_mean_squared_error: 9669.9043\n",
            "Epoch 71/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 88267760.0000 - root_mean_squared_error: 9395.0928 - val_loss: 93144952.0000 - val_root_mean_squared_error: 9651.1631\n",
            "Epoch 72/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89444880.0000 - root_mean_squared_error: 9457.5303 - val_loss: 93328968.0000 - val_root_mean_squared_error: 9660.6924\n",
            "Epoch 73/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 87534752.0000 - root_mean_squared_error: 9356.0010 - val_loss: 92430024.0000 - val_root_mean_squared_error: 9614.0537\n",
            "Epoch 74/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 91396352.0000 - root_mean_squared_error: 9560.1436 - val_loss: 92805544.0000 - val_root_mean_squared_error: 9633.5635\n",
            "Epoch 75/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89211520.0000 - root_mean_squared_error: 9445.1846 - val_loss: 92191360.0000 - val_root_mean_squared_error: 9601.6328\n",
            "Epoch 76/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 88573312.0000 - root_mean_squared_error: 9411.3398 - val_loss: 94011456.0000 - val_root_mean_squared_error: 9695.9502\n",
            "Epoch 77/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89015944.0000 - root_mean_squared_error: 9434.8262 - val_loss: 94973616.0000 - val_root_mean_squared_error: 9745.4404\n",
            "Epoch 78/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 87224544.0000 - root_mean_squared_error: 9339.4082 - val_loss: 91808856.0000 - val_root_mean_squared_error: 9581.6934\n",
            "Epoch 79/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 90266896.0000 - root_mean_squared_error: 9500.8896 - val_loss: 92719544.0000 - val_root_mean_squared_error: 9629.0986\n",
            "Epoch 80/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89079880.0000 - root_mean_squared_error: 9438.2139 - val_loss: 91947856.0000 - val_root_mean_squared_error: 9588.9443\n",
            "Epoch 81/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88456656.0000 - root_mean_squared_error: 9405.1396 - val_loss: 93755792.0000 - val_root_mean_squared_error: 9682.7578\n",
            "Epoch 82/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 88332640.0000 - root_mean_squared_error: 9398.5449 - val_loss: 93173296.0000 - val_root_mean_squared_error: 9652.6318\n",
            "Epoch 83/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 90283544.0000 - root_mean_squared_error: 9501.7656 - val_loss: 91844560.0000 - val_root_mean_squared_error: 9583.5566\n",
            "Epoch 84/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88217920.0000 - root_mean_squared_error: 9392.4395 - val_loss: 93285896.0000 - val_root_mean_squared_error: 9658.4629\n",
            "Epoch 85/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 87638456.0000 - root_mean_squared_error: 9361.5410 - val_loss: 93860040.0000 - val_root_mean_squared_error: 9688.1387\n",
            "Epoch 86/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 89439912.0000 - root_mean_squared_error: 9457.2676 - val_loss: 93237560.0000 - val_root_mean_squared_error: 9655.9600\n",
            "Epoch 87/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 87969456.0000 - root_mean_squared_error: 9379.2031 - val_loss: 92069576.0000 - val_root_mean_squared_error: 9595.2891\n",
            "Epoch 88/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88827848.0000 - root_mean_squared_error: 9424.8525 - val_loss: 92596552.0000 - val_root_mean_squared_error: 9622.7100\n",
            "Epoch 89/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89529728.0000 - root_mean_squared_error: 9462.0146 - val_loss: 92338672.0000 - val_root_mean_squared_error: 9609.3018\n",
            "Epoch 90/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89014400.0000 - root_mean_squared_error: 9434.7441 - val_loss: 92942424.0000 - val_root_mean_squared_error: 9640.6650\n",
            "Epoch 91/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88130120.0000 - root_mean_squared_error: 9387.7646 - val_loss: 93537144.0000 - val_root_mean_squared_error: 9671.4600\n",
            "Epoch 92/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88898352.0000 - root_mean_squared_error: 9428.5918 - val_loss: 92686048.0000 - val_root_mean_squared_error: 9627.3594\n",
            "Epoch 93/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 90333168.0000 - root_mean_squared_error: 9504.3760 - val_loss: 93052240.0000 - val_root_mean_squared_error: 9646.3594\n",
            "Epoch 94/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88268496.0000 - root_mean_squared_error: 9395.1318 - val_loss: 91464552.0000 - val_root_mean_squared_error: 9563.7100\n",
            "Epoch 95/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 87559416.0000 - root_mean_squared_error: 9357.3184 - val_loss: 90855328.0000 - val_root_mean_squared_error: 9531.8057\n",
            "Epoch 96/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 88043112.0000 - root_mean_squared_error: 9383.1289 - val_loss: 90148280.0000 - val_root_mean_squared_error: 9494.6445\n",
            "Epoch 97/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 89634200.0000 - root_mean_squared_error: 9467.5342 - val_loss: 90494536.0000 - val_root_mean_squared_error: 9512.8613\n",
            "Epoch 98/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 86299864.0000 - root_mean_squared_error: 9289.7725 - val_loss: 90185368.0000 - val_root_mean_squared_error: 9496.5977\n",
            "Epoch 99/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 87179784.0000 - root_mean_squared_error: 9337.0117 - val_loss: 90062632.0000 - val_root_mean_squared_error: 9490.1338\n",
            "Epoch 100/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 86704688.0000 - root_mean_squared_error: 9311.5352 - val_loss: 91428896.0000 - val_root_mean_squared_error: 9561.8457\n",
            "Epoch 101/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 85672448.0000 - root_mean_squared_error: 9255.9414 - val_loss: 90827608.0000 - val_root_mean_squared_error: 9530.3516\n",
            "Epoch 102/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 87006232.0000 - root_mean_squared_error: 9327.7129 - val_loss: 90102368.0000 - val_root_mean_squared_error: 9492.2266\n",
            "Epoch 103/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 85965600.0000 - root_mean_squared_error: 9271.7637 - val_loss: 90171080.0000 - val_root_mean_squared_error: 9495.8457\n",
            "Epoch 104/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 86676440.0000 - root_mean_squared_error: 9310.0186 - val_loss: 92335456.0000 - val_root_mean_squared_error: 9609.1338\n",
            "Epoch 105/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 86499272.0000 - root_mean_squared_error: 9300.4980 - val_loss: 91026280.0000 - val_root_mean_squared_error: 9540.7695\n",
            "Epoch 106/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 88408376.0000 - root_mean_squared_error: 9402.5732 - val_loss: 91090720.0000 - val_root_mean_squared_error: 9544.1455\n",
            "Epoch 107/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 89485896.0000 - root_mean_squared_error: 9459.6982 - val_loss: 89758848.0000 - val_root_mean_squared_error: 9474.1143\n",
            "Epoch 108/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83911688.0000 - root_mean_squared_error: 9160.3320 - val_loss: 89297248.0000 - val_root_mean_squared_error: 9449.7217\n",
            "Epoch 109/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 85274008.0000 - root_mean_squared_error: 9234.3926 - val_loss: 88282032.0000 - val_root_mean_squared_error: 9395.8516\n",
            "Epoch 110/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 84855360.0000 - root_mean_squared_error: 9211.6973 - val_loss: 87407488.0000 - val_root_mean_squared_error: 9349.1973\n",
            "Epoch 111/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83702688.0000 - root_mean_squared_error: 9148.9170 - val_loss: 88482232.0000 - val_root_mean_squared_error: 9406.4990\n",
            "Epoch 112/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 87506960.0000 - root_mean_squared_error: 9354.5156 - val_loss: 86474904.0000 - val_root_mean_squared_error: 9299.1885\n",
            "Epoch 113/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 88288832.0000 - root_mean_squared_error: 9396.2139 - val_loss: 86428280.0000 - val_root_mean_squared_error: 9296.6807\n",
            "Epoch 114/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 85261408.0000 - root_mean_squared_error: 9233.7100 - val_loss: 88465864.0000 - val_root_mean_squared_error: 9405.6289\n",
            "Epoch 115/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84676656.0000 - root_mean_squared_error: 9201.9922 - val_loss: 86777016.0000 - val_root_mean_squared_error: 9315.4180\n",
            "Epoch 116/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 86956712.0000 - root_mean_squared_error: 9325.0586 - val_loss: 86469184.0000 - val_root_mean_squared_error: 9298.8809\n",
            "Epoch 117/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 84305312.0000 - root_mean_squared_error: 9181.7920 - val_loss: 87947408.0000 - val_root_mean_squared_error: 9378.0283\n",
            "Epoch 118/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83346360.0000 - root_mean_squared_error: 9129.4229 - val_loss: 85902112.0000 - val_root_mean_squared_error: 9268.3389\n",
            "Epoch 119/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 85195968.0000 - root_mean_squared_error: 9230.1660 - val_loss: 85585208.0000 - val_root_mean_squared_error: 9251.2275\n",
            "Epoch 120/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 86208424.0000 - root_mean_squared_error: 9284.8496 - val_loss: 85250960.0000 - val_root_mean_squared_error: 9233.1445\n",
            "Epoch 121/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 84999304.0000 - root_mean_squared_error: 9219.5068 - val_loss: 85258192.0000 - val_root_mean_squared_error: 9233.5361\n",
            "Epoch 122/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 84776720.0000 - root_mean_squared_error: 9207.4277 - val_loss: 85769064.0000 - val_root_mean_squared_error: 9261.1592\n",
            "Epoch 123/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80506056.0000 - root_mean_squared_error: 8972.5166 - val_loss: 85821672.0000 - val_root_mean_squared_error: 9263.9990\n",
            "Epoch 124/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84448904.0000 - root_mean_squared_error: 9189.6084 - val_loss: 85174736.0000 - val_root_mean_squared_error: 9229.0156\n",
            "Epoch 125/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 87028376.0000 - root_mean_squared_error: 9328.9004 - val_loss: 85869360.0000 - val_root_mean_squared_error: 9266.5723\n",
            "Epoch 126/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84549088.0000 - root_mean_squared_error: 9195.0576 - val_loss: 85602360.0000 - val_root_mean_squared_error: 9252.1543\n",
            "Epoch 127/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 84543672.0000 - root_mean_squared_error: 9194.7637 - val_loss: 85650208.0000 - val_root_mean_squared_error: 9254.7402\n",
            "Epoch 128/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83579112.0000 - root_mean_squared_error: 9142.1611 - val_loss: 85141048.0000 - val_root_mean_squared_error: 9227.1904\n",
            "Epoch 129/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 84210272.0000 - root_mean_squared_error: 9176.6152 - val_loss: 85689664.0000 - val_root_mean_squared_error: 9256.8711\n",
            "Epoch 130/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84753648.0000 - root_mean_squared_error: 9206.1748 - val_loss: 85566136.0000 - val_root_mean_squared_error: 9250.1963\n",
            "Epoch 131/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83618504.0000 - root_mean_squared_error: 9144.3154 - val_loss: 85538816.0000 - val_root_mean_squared_error: 9248.7197\n",
            "Epoch 132/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82354440.0000 - root_mean_squared_error: 9074.9346 - val_loss: 86148360.0000 - val_root_mean_squared_error: 9281.6143\n",
            "Epoch 133/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 85709456.0000 - root_mean_squared_error: 9257.9404 - val_loss: 86106160.0000 - val_root_mean_squared_error: 9279.3408\n",
            "Epoch 134/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82941712.0000 - root_mean_squared_error: 9107.2344 - val_loss: 85400872.0000 - val_root_mean_squared_error: 9241.2588\n",
            "Epoch 135/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83638200.0000 - root_mean_squared_error: 9145.3926 - val_loss: 85881984.0000 - val_root_mean_squared_error: 9267.2529\n",
            "Epoch 136/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 85279600.0000 - root_mean_squared_error: 9234.6953 - val_loss: 85495104.0000 - val_root_mean_squared_error: 9246.3564\n",
            "Epoch 137/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84893000.0000 - root_mean_squared_error: 9213.7393 - val_loss: 85477488.0000 - val_root_mean_squared_error: 9245.4033\n",
            "Epoch 138/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 85738648.0000 - root_mean_squared_error: 9259.5166 - val_loss: 86380568.0000 - val_root_mean_squared_error: 9294.1143\n",
            "Epoch 139/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83429600.0000 - root_mean_squared_error: 9133.9805 - val_loss: 84796336.0000 - val_root_mean_squared_error: 9208.4922\n",
            "Epoch 140/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84779912.0000 - root_mean_squared_error: 9207.6006 - val_loss: 84575304.0000 - val_root_mean_squared_error: 9196.4834\n",
            "Epoch 141/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84204360.0000 - root_mean_squared_error: 9176.2930 - val_loss: 85843568.0000 - val_root_mean_squared_error: 9265.1807\n",
            "Epoch 142/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84738896.0000 - root_mean_squared_error: 9205.3730 - val_loss: 85144048.0000 - val_root_mean_squared_error: 9227.3535\n",
            "Epoch 143/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83500088.0000 - root_mean_squared_error: 9137.8379 - val_loss: 85591024.0000 - val_root_mean_squared_error: 9251.5420\n",
            "Epoch 144/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83891888.0000 - root_mean_squared_error: 9159.2520 - val_loss: 84197816.0000 - val_root_mean_squared_error: 9175.9365\n",
            "Epoch 145/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83579872.0000 - root_mean_squared_error: 9142.2031 - val_loss: 85226136.0000 - val_root_mean_squared_error: 9231.7998\n",
            "Epoch 146/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80883904.0000 - root_mean_squared_error: 8993.5479 - val_loss: 85500200.0000 - val_root_mean_squared_error: 9246.6318\n",
            "Epoch 147/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 84392880.0000 - root_mean_squared_error: 9186.5596 - val_loss: 83581880.0000 - val_root_mean_squared_error: 9142.3125\n",
            "Epoch 148/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78304752.0000 - root_mean_squared_error: 8848.9971 - val_loss: 85477920.0000 - val_root_mean_squared_error: 9245.4268\n",
            "Epoch 149/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84187200.0000 - root_mean_squared_error: 9175.3584 - val_loss: 84403200.0000 - val_root_mean_squared_error: 9187.1211\n",
            "Epoch 150/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84891944.0000 - root_mean_squared_error: 9213.6826 - val_loss: 84233640.0000 - val_root_mean_squared_error: 9177.8887\n",
            "Epoch 151/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82899672.0000 - root_mean_squared_error: 9104.9258 - val_loss: 84394016.0000 - val_root_mean_squared_error: 9186.6211\n",
            "Epoch 152/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83655288.0000 - root_mean_squared_error: 9146.3262 - val_loss: 84665248.0000 - val_root_mean_squared_error: 9201.3721\n",
            "Epoch 153/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81615544.0000 - root_mean_squared_error: 9034.1318 - val_loss: 84477584.0000 - val_root_mean_squared_error: 9191.1689\n",
            "Epoch 154/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81099152.0000 - root_mean_squared_error: 9005.5068 - val_loss: 84334984.0000 - val_root_mean_squared_error: 9183.4082\n",
            "Epoch 155/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83426368.0000 - root_mean_squared_error: 9133.8037 - val_loss: 86742480.0000 - val_root_mean_squared_error: 9313.5645\n",
            "Epoch 156/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 84142056.0000 - root_mean_squared_error: 9172.8975 - val_loss: 84562184.0000 - val_root_mean_squared_error: 9195.7695\n",
            "Epoch 157/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82013536.0000 - root_mean_squared_error: 9056.1328 - val_loss: 85225336.0000 - val_root_mean_squared_error: 9231.7568\n",
            "Epoch 158/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84367384.0000 - root_mean_squared_error: 9185.1719 - val_loss: 85364672.0000 - val_root_mean_squared_error: 9239.3008\n",
            "Epoch 159/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79218312.0000 - root_mean_squared_error: 8900.4668 - val_loss: 84199168.0000 - val_root_mean_squared_error: 9176.0107\n",
            "Epoch 160/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80814104.0000 - root_mean_squared_error: 8989.6670 - val_loss: 84726000.0000 - val_root_mean_squared_error: 9204.6729\n",
            "Epoch 161/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83708464.0000 - root_mean_squared_error: 9149.2334 - val_loss: 84644968.0000 - val_root_mean_squared_error: 9200.2695\n",
            "Epoch 162/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81216232.0000 - root_mean_squared_error: 9012.0049 - val_loss: 85103688.0000 - val_root_mean_squared_error: 9225.1660\n",
            "Epoch 163/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82781512.0000 - root_mean_squared_error: 9098.4346 - val_loss: 83741352.0000 - val_root_mean_squared_error: 9151.0303\n",
            "Epoch 164/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80320720.0000 - root_mean_squared_error: 8962.1826 - val_loss: 84004672.0000 - val_root_mean_squared_error: 9165.4062\n",
            "Epoch 165/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79872640.0000 - root_mean_squared_error: 8937.1494 - val_loss: 85281152.0000 - val_root_mean_squared_error: 9234.7793\n",
            "Epoch 166/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82224008.0000 - root_mean_squared_error: 9067.7451 - val_loss: 83290216.0000 - val_root_mean_squared_error: 9126.3477\n",
            "Epoch 167/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81847096.0000 - root_mean_squared_error: 9046.9385 - val_loss: 85080128.0000 - val_root_mean_squared_error: 9223.8887\n",
            "Epoch 168/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82605752.0000 - root_mean_squared_error: 9088.7705 - val_loss: 84721952.0000 - val_root_mean_squared_error: 9204.4531\n",
            "Epoch 169/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83494056.0000 - root_mean_squared_error: 9137.5078 - val_loss: 84725072.0000 - val_root_mean_squared_error: 9204.6221\n",
            "Epoch 170/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82420040.0000 - root_mean_squared_error: 9078.5488 - val_loss: 84042192.0000 - val_root_mean_squared_error: 9167.4531\n",
            "Epoch 171/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82208184.0000 - root_mean_squared_error: 9066.8730 - val_loss: 84192408.0000 - val_root_mean_squared_error: 9175.6426\n",
            "Epoch 172/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82052656.0000 - root_mean_squared_error: 9058.2920 - val_loss: 85511848.0000 - val_root_mean_squared_error: 9247.2617\n",
            "Epoch 173/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82433464.0000 - root_mean_squared_error: 9079.2881 - val_loss: 84384288.0000 - val_root_mean_squared_error: 9186.0918\n",
            "Epoch 174/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80995536.0000 - root_mean_squared_error: 8999.7520 - val_loss: 85018656.0000 - val_root_mean_squared_error: 9220.5566\n",
            "Epoch 175/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82175504.0000 - root_mean_squared_error: 9065.0703 - val_loss: 85653216.0000 - val_root_mean_squared_error: 9254.9023\n",
            "Epoch 176/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83251432.0000 - root_mean_squared_error: 9124.2227 - val_loss: 84209656.0000 - val_root_mean_squared_error: 9176.5820\n",
            "Epoch 177/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79785352.0000 - root_mean_squared_error: 8932.2646 - val_loss: 84986872.0000 - val_root_mean_squared_error: 9218.8320\n",
            "Epoch 178/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79819976.0000 - root_mean_squared_error: 8934.2021 - val_loss: 84443416.0000 - val_root_mean_squared_error: 9189.3096\n",
            "Epoch 179/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79921616.0000 - root_mean_squared_error: 8939.8887 - val_loss: 84408840.0000 - val_root_mean_squared_error: 9187.4287\n",
            "Epoch 180/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84889480.0000 - root_mean_squared_error: 9213.5488 - val_loss: 84505008.0000 - val_root_mean_squared_error: 9192.6602\n",
            "Epoch 181/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81214920.0000 - root_mean_squared_error: 9011.9316 - val_loss: 83821256.0000 - val_root_mean_squared_error: 9155.3945\n",
            "Epoch 182/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83327624.0000 - root_mean_squared_error: 9128.3965 - val_loss: 84031472.0000 - val_root_mean_squared_error: 9166.8682\n",
            "Epoch 183/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82289680.0000 - root_mean_squared_error: 9071.3662 - val_loss: 84979520.0000 - val_root_mean_squared_error: 9218.4336\n",
            "Epoch 184/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82733408.0000 - root_mean_squared_error: 9095.7910 - val_loss: 84886056.0000 - val_root_mean_squared_error: 9213.3633\n",
            "Epoch 185/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82098032.0000 - root_mean_squared_error: 9060.7969 - val_loss: 86058976.0000 - val_root_mean_squared_error: 9276.7979\n",
            "Epoch 186/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80406056.0000 - root_mean_squared_error: 8966.9424 - val_loss: 84135408.0000 - val_root_mean_squared_error: 9172.5352\n",
            "Epoch 187/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79901504.0000 - root_mean_squared_error: 8938.7637 - val_loss: 85168984.0000 - val_root_mean_squared_error: 9228.7041\n",
            "Epoch 188/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81131288.0000 - root_mean_squared_error: 9007.2910 - val_loss: 84806896.0000 - val_root_mean_squared_error: 9209.0664\n",
            "Epoch 189/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 82497584.0000 - root_mean_squared_error: 9082.8184 - val_loss: 83775120.0000 - val_root_mean_squared_error: 9152.8750\n",
            "Epoch 190/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84168168.0000 - root_mean_squared_error: 9174.3213 - val_loss: 84182720.0000 - val_root_mean_squared_error: 9175.1143\n",
            "Epoch 191/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83268240.0000 - root_mean_squared_error: 9125.1436 - val_loss: 85377488.0000 - val_root_mean_squared_error: 9239.9941\n",
            "Epoch 192/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83973992.0000 - root_mean_squared_error: 9163.7324 - val_loss: 84372440.0000 - val_root_mean_squared_error: 9185.4473\n",
            "Epoch 193/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82435624.0000 - root_mean_squared_error: 9079.4062 - val_loss: 85634280.0000 - val_root_mean_squared_error: 9253.8789\n",
            "Epoch 194/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80738992.0000 - root_mean_squared_error: 8985.4883 - val_loss: 86282744.0000 - val_root_mean_squared_error: 9288.8506\n",
            "Epoch 195/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83933616.0000 - root_mean_squared_error: 9161.5293 - val_loss: 84693288.0000 - val_root_mean_squared_error: 9202.8955\n",
            "Epoch 196/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79412936.0000 - root_mean_squared_error: 8911.3936 - val_loss: 84210632.0000 - val_root_mean_squared_error: 9176.6348\n",
            "Epoch 197/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 82566208.0000 - root_mean_squared_error: 9086.5947 - val_loss: 83763552.0000 - val_root_mean_squared_error: 9152.2432\n",
            "Epoch 198/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82098280.0000 - root_mean_squared_error: 9060.8105 - val_loss: 84571888.0000 - val_root_mean_squared_error: 9196.2979\n",
            "Epoch 199/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82389240.0000 - root_mean_squared_error: 9076.8516 - val_loss: 83820384.0000 - val_root_mean_squared_error: 9155.3477\n",
            "Epoch 200/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80263272.0000 - root_mean_squared_error: 8958.9775 - val_loss: 85266352.0000 - val_root_mean_squared_error: 9233.9785\n",
            "Epoch 201/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81951384.0000 - root_mean_squared_error: 9052.7002 - val_loss: 84295704.0000 - val_root_mean_squared_error: 9181.2695\n",
            "Epoch 202/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80570904.0000 - root_mean_squared_error: 8976.1299 - val_loss: 83998024.0000 - val_root_mean_squared_error: 9165.0439\n",
            "Epoch 203/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81575528.0000 - root_mean_squared_error: 9031.9170 - val_loss: 83242960.0000 - val_root_mean_squared_error: 9123.7578\n",
            "Epoch 204/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80605536.0000 - root_mean_squared_error: 8978.0586 - val_loss: 83454376.0000 - val_root_mean_squared_error: 9135.3369\n",
            "Epoch 205/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82705600.0000 - root_mean_squared_error: 9094.2617 - val_loss: 83899864.0000 - val_root_mean_squared_error: 9159.6865\n",
            "Epoch 206/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82513192.0000 - root_mean_squared_error: 9083.6768 - val_loss: 85191152.0000 - val_root_mean_squared_error: 9229.9053\n",
            "Epoch 207/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80796640.0000 - root_mean_squared_error: 8988.6953 - val_loss: 83647712.0000 - val_root_mean_squared_error: 9145.9121\n",
            "Epoch 208/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79684848.0000 - root_mean_squared_error: 8926.6367 - val_loss: 84096344.0000 - val_root_mean_squared_error: 9170.4062\n",
            "Epoch 209/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82565192.0000 - root_mean_squared_error: 9086.5391 - val_loss: 83915824.0000 - val_root_mean_squared_error: 9160.5576\n",
            "Epoch 210/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80617944.0000 - root_mean_squared_error: 8978.7500 - val_loss: 84621832.0000 - val_root_mean_squared_error: 9199.0127\n",
            "Epoch 211/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80957032.0000 - root_mean_squared_error: 8997.6123 - val_loss: 84310984.0000 - val_root_mean_squared_error: 9182.1016\n",
            "Epoch 212/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80701648.0000 - root_mean_squared_error: 8983.4092 - val_loss: 84190336.0000 - val_root_mean_squared_error: 9175.5293\n",
            "Epoch 213/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 79780624.0000 - root_mean_squared_error: 8932.0000 - val_loss: 83628760.0000 - val_root_mean_squared_error: 9144.8760\n",
            "Epoch 214/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81796096.0000 - root_mean_squared_error: 9044.1191 - val_loss: 84274512.0000 - val_root_mean_squared_error: 9180.1152\n",
            "Epoch 215/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82698728.0000 - root_mean_squared_error: 9093.8838 - val_loss: 83947024.0000 - val_root_mean_squared_error: 9162.2607\n",
            "Epoch 216/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81704168.0000 - root_mean_squared_error: 9039.0361 - val_loss: 84967192.0000 - val_root_mean_squared_error: 9217.7646\n",
            "Epoch 217/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82001104.0000 - root_mean_squared_error: 9055.4463 - val_loss: 84752768.0000 - val_root_mean_squared_error: 9206.1270\n",
            "Epoch 218/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81354600.0000 - root_mean_squared_error: 9019.6787 - val_loss: 83952208.0000 - val_root_mean_squared_error: 9162.5439\n",
            "Epoch 219/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81504808.0000 - root_mean_squared_error: 9028.0010 - val_loss: 85398848.0000 - val_root_mean_squared_error: 9241.1494\n",
            "Epoch 220/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81588584.0000 - root_mean_squared_error: 9032.6396 - val_loss: 84576144.0000 - val_root_mean_squared_error: 9196.5293\n",
            "Epoch 221/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79612496.0000 - root_mean_squared_error: 8922.5830 - val_loss: 84063528.0000 - val_root_mean_squared_error: 9168.6162\n",
            "Epoch 222/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 85048472.0000 - root_mean_squared_error: 9222.1729 - val_loss: 84369504.0000 - val_root_mean_squared_error: 9185.2871\n",
            "Epoch 223/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82002840.0000 - root_mean_squared_error: 9055.5420 - val_loss: 83567776.0000 - val_root_mean_squared_error: 9141.5410\n",
            "Epoch 224/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81651808.0000 - root_mean_squared_error: 9036.1387 - val_loss: 83355040.0000 - val_root_mean_squared_error: 9129.8984\n",
            "Epoch 225/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82623040.0000 - root_mean_squared_error: 9089.7217 - val_loss: 84720136.0000 - val_root_mean_squared_error: 9204.3545\n",
            "Epoch 226/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81557128.0000 - root_mean_squared_error: 9030.8984 - val_loss: 83626480.0000 - val_root_mean_squared_error: 9144.7520\n",
            "Epoch 227/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84286088.0000 - root_mean_squared_error: 9180.7451 - val_loss: 85277056.0000 - val_root_mean_squared_error: 9234.5576\n",
            "Epoch 228/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81950352.0000 - root_mean_squared_error: 9052.6436 - val_loss: 83742880.0000 - val_root_mean_squared_error: 9151.1133\n",
            "Epoch 229/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 80199584.0000 - root_mean_squared_error: 8955.4219 - val_loss: 84366784.0000 - val_root_mean_squared_error: 9185.1396\n",
            "Epoch 230/500\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 80783152.0000 - root_mean_squared_error: 8987.9443 - val_loss: 84647440.0000 - val_root_mean_squared_error: 9200.4043\n",
            "Epoch 231/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81574024.0000 - root_mean_squared_error: 9031.8340 - val_loss: 85173984.0000 - val_root_mean_squared_error: 9228.9756\n",
            "Epoch 232/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81728648.0000 - root_mean_squared_error: 9040.3896 - val_loss: 87698528.0000 - val_root_mean_squared_error: 9364.7490\n",
            "Epoch 233/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81978504.0000 - root_mean_squared_error: 9054.1982 - val_loss: 83601400.0000 - val_root_mean_squared_error: 9143.3799\n",
            "Epoch 234/500\n",
            "92/92 [==============================] - 0s 5ms/step - loss: 83637800.0000 - root_mean_squared_error: 9145.3701 - val_loss: 83096824.0000 - val_root_mean_squared_error: 9115.7461\n",
            "Epoch 235/500\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 82498296.0000 - root_mean_squared_error: 9082.8574 - val_loss: 83316368.0000 - val_root_mean_squared_error: 9127.7803\n",
            "Epoch 236/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81242024.0000 - root_mean_squared_error: 9013.4355 - val_loss: 83902624.0000 - val_root_mean_squared_error: 9159.8379\n",
            "Epoch 237/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81638048.0000 - root_mean_squared_error: 9035.3779 - val_loss: 84615992.0000 - val_root_mean_squared_error: 9198.6953\n",
            "Epoch 238/500\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 83443848.0000 - root_mean_squared_error: 9134.7607 - val_loss: 83462864.0000 - val_root_mean_squared_error: 9135.8008\n",
            "Epoch 239/500\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 82200512.0000 - root_mean_squared_error: 9066.4502 - val_loss: 83567720.0000 - val_root_mean_squared_error: 9141.5381\n",
            "Epoch 240/500\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 80879848.0000 - root_mean_squared_error: 8993.3223 - val_loss: 83853648.0000 - val_root_mean_squared_error: 9157.1641\n",
            "Epoch 241/500\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 80799352.0000 - root_mean_squared_error: 8988.8457 - val_loss: 83971808.0000 - val_root_mean_squared_error: 9163.6133\n",
            "Epoch 242/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81873960.0000 - root_mean_squared_error: 9048.4229 - val_loss: 83956272.0000 - val_root_mean_squared_error: 9162.7656\n",
            "Epoch 243/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81633960.0000 - root_mean_squared_error: 9035.1514 - val_loss: 84564520.0000 - val_root_mean_squared_error: 9195.8965\n",
            "Epoch 244/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79533792.0000 - root_mean_squared_error: 8918.1719 - val_loss: 83747944.0000 - val_root_mean_squared_error: 9151.3906\n",
            "Epoch 245/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80432752.0000 - root_mean_squared_error: 8968.4307 - val_loss: 83056048.0000 - val_root_mean_squared_error: 9113.5088\n",
            "Epoch 246/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81873512.0000 - root_mean_squared_error: 9048.3984 - val_loss: 83398224.0000 - val_root_mean_squared_error: 9132.2627\n",
            "Epoch 247/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78562192.0000 - root_mean_squared_error: 8863.5312 - val_loss: 84928720.0000 - val_root_mean_squared_error: 9215.6777\n",
            "Epoch 248/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81857760.0000 - root_mean_squared_error: 9047.5283 - val_loss: 83040664.0000 - val_root_mean_squared_error: 9112.6650\n",
            "Epoch 249/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80717336.0000 - root_mean_squared_error: 8984.2832 - val_loss: 82847088.0000 - val_root_mean_squared_error: 9102.0371\n",
            "Epoch 250/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80885648.0000 - root_mean_squared_error: 8993.6445 - val_loss: 83283560.0000 - val_root_mean_squared_error: 9125.9824\n",
            "Epoch 251/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81350072.0000 - root_mean_squared_error: 9019.4277 - val_loss: 83279984.0000 - val_root_mean_squared_error: 9125.7871\n",
            "Epoch 252/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81584992.0000 - root_mean_squared_error: 9032.4414 - val_loss: 83698272.0000 - val_root_mean_squared_error: 9148.6758\n",
            "Epoch 253/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80668232.0000 - root_mean_squared_error: 8981.5498 - val_loss: 84040216.0000 - val_root_mean_squared_error: 9167.3447\n",
            "Epoch 254/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80201080.0000 - root_mean_squared_error: 8955.5059 - val_loss: 84697256.0000 - val_root_mean_squared_error: 9203.1113\n",
            "Epoch 255/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84287560.0000 - root_mean_squared_error: 9180.8252 - val_loss: 83118104.0000 - val_root_mean_squared_error: 9116.9131\n",
            "Epoch 256/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81282408.0000 - root_mean_squared_error: 9015.6758 - val_loss: 83621144.0000 - val_root_mean_squared_error: 9144.4600\n",
            "Epoch 257/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81697784.0000 - root_mean_squared_error: 9038.6826 - val_loss: 84332032.0000 - val_root_mean_squared_error: 9183.2471\n",
            "Epoch 258/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83113160.0000 - root_mean_squared_error: 9116.6416 - val_loss: 85121576.0000 - val_root_mean_squared_error: 9226.1357\n",
            "Epoch 259/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81871480.0000 - root_mean_squared_error: 9048.2861 - val_loss: 83536968.0000 - val_root_mean_squared_error: 9139.8564\n",
            "Epoch 260/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81907008.0000 - root_mean_squared_error: 9050.2490 - val_loss: 83672448.0000 - val_root_mean_squared_error: 9147.2646\n",
            "Epoch 261/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81021696.0000 - root_mean_squared_error: 9001.2051 - val_loss: 84221328.0000 - val_root_mean_squared_error: 9177.2178\n",
            "Epoch 262/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81054720.0000 - root_mean_squared_error: 9003.0391 - val_loss: 83369072.0000 - val_root_mean_squared_error: 9130.6670\n",
            "Epoch 263/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 78058216.0000 - root_mean_squared_error: 8835.0557 - val_loss: 84346440.0000 - val_root_mean_squared_error: 9184.0322\n",
            "Epoch 264/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82451960.0000 - root_mean_squared_error: 9080.3066 - val_loss: 83272664.0000 - val_root_mean_squared_error: 9125.3857\n",
            "Epoch 265/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80504400.0000 - root_mean_squared_error: 8972.4248 - val_loss: 83017584.0000 - val_root_mean_squared_error: 9111.3984\n",
            "Epoch 266/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81626520.0000 - root_mean_squared_error: 9034.7393 - val_loss: 83191872.0000 - val_root_mean_squared_error: 9120.9580\n",
            "Epoch 267/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81871912.0000 - root_mean_squared_error: 9048.3096 - val_loss: 83860984.0000 - val_root_mean_squared_error: 9157.5645\n",
            "Epoch 268/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82839520.0000 - root_mean_squared_error: 9101.6221 - val_loss: 84162592.0000 - val_root_mean_squared_error: 9174.0176\n",
            "Epoch 269/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81348608.0000 - root_mean_squared_error: 9019.3467 - val_loss: 84808648.0000 - val_root_mean_squared_error: 9209.1611\n",
            "Epoch 270/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80546688.0000 - root_mean_squared_error: 8974.7803 - val_loss: 85250352.0000 - val_root_mean_squared_error: 9233.1113\n",
            "Epoch 271/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81832232.0000 - root_mean_squared_error: 9046.1172 - val_loss: 84004672.0000 - val_root_mean_squared_error: 9165.4062\n",
            "Epoch 272/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82128632.0000 - root_mean_squared_error: 9062.4854 - val_loss: 83600128.0000 - val_root_mean_squared_error: 9143.3105\n",
            "Epoch 273/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83418656.0000 - root_mean_squared_error: 9133.3818 - val_loss: 84948480.0000 - val_root_mean_squared_error: 9216.7500\n",
            "Epoch 274/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81739344.0000 - root_mean_squared_error: 9040.9814 - val_loss: 84358792.0000 - val_root_mean_squared_error: 9184.7041\n",
            "Epoch 275/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81003240.0000 - root_mean_squared_error: 9000.1797 - val_loss: 83360016.0000 - val_root_mean_squared_error: 9130.1709\n",
            "Epoch 276/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80926248.0000 - root_mean_squared_error: 8995.9014 - val_loss: 82901808.0000 - val_root_mean_squared_error: 9105.0430\n",
            "Epoch 277/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82006800.0000 - root_mean_squared_error: 9055.7607 - val_loss: 83440928.0000 - val_root_mean_squared_error: 9134.6006\n",
            "Epoch 278/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82535600.0000 - root_mean_squared_error: 9084.9102 - val_loss: 83668744.0000 - val_root_mean_squared_error: 9147.0625\n",
            "Epoch 279/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82025552.0000 - root_mean_squared_error: 9056.7959 - val_loss: 83741600.0000 - val_root_mean_squared_error: 9151.0439\n",
            "Epoch 280/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81761680.0000 - root_mean_squared_error: 9042.2168 - val_loss: 83815144.0000 - val_root_mean_squared_error: 9155.0615\n",
            "Epoch 281/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81324056.0000 - root_mean_squared_error: 9017.9854 - val_loss: 83395680.0000 - val_root_mean_squared_error: 9132.1230\n",
            "Epoch 282/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78060176.0000 - root_mean_squared_error: 8835.1670 - val_loss: 84200608.0000 - val_root_mean_squared_error: 9176.0889\n",
            "Epoch 283/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81225376.0000 - root_mean_squared_error: 9012.5117 - val_loss: 84381160.0000 - val_root_mean_squared_error: 9185.9219\n",
            "Epoch 284/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 83423760.0000 - root_mean_squared_error: 9133.6611 - val_loss: 83919376.0000 - val_root_mean_squared_error: 9160.7520\n",
            "Epoch 285/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82630336.0000 - root_mean_squared_error: 9090.1230 - val_loss: 83546024.0000 - val_root_mean_squared_error: 9140.3516\n",
            "Epoch 286/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83276456.0000 - root_mean_squared_error: 9125.5938 - val_loss: 83651888.0000 - val_root_mean_squared_error: 9146.1406\n",
            "Epoch 287/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78774880.0000 - root_mean_squared_error: 8875.5215 - val_loss: 84941064.0000 - val_root_mean_squared_error: 9216.3477\n",
            "Epoch 288/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81045432.0000 - root_mean_squared_error: 9002.5234 - val_loss: 83689992.0000 - val_root_mean_squared_error: 9148.2236\n",
            "Epoch 289/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84266960.0000 - root_mean_squared_error: 9179.7041 - val_loss: 83461496.0000 - val_root_mean_squared_error: 9135.7266\n",
            "Epoch 290/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81498656.0000 - root_mean_squared_error: 9027.6602 - val_loss: 83906192.0000 - val_root_mean_squared_error: 9160.0322\n",
            "Epoch 291/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81936920.0000 - root_mean_squared_error: 9051.9014 - val_loss: 83558960.0000 - val_root_mean_squared_error: 9141.0586\n",
            "Epoch 292/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 85935384.0000 - root_mean_squared_error: 9270.1338 - val_loss: 84274640.0000 - val_root_mean_squared_error: 9180.1221\n",
            "Epoch 293/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82424088.0000 - root_mean_squared_error: 9078.7715 - val_loss: 83493368.0000 - val_root_mean_squared_error: 9137.4707\n",
            "Epoch 294/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 78966320.0000 - root_mean_squared_error: 8886.2998 - val_loss: 83533856.0000 - val_root_mean_squared_error: 9139.6855\n",
            "Epoch 295/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81437312.0000 - root_mean_squared_error: 9024.2627 - val_loss: 85248080.0000 - val_root_mean_squared_error: 9232.9883\n",
            "Epoch 296/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80720352.0000 - root_mean_squared_error: 8984.4502 - val_loss: 83569136.0000 - val_root_mean_squared_error: 9141.6152\n",
            "Epoch 297/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81817656.0000 - root_mean_squared_error: 9045.3115 - val_loss: 82754816.0000 - val_root_mean_squared_error: 9096.9678\n",
            "Epoch 298/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81163176.0000 - root_mean_squared_error: 9009.0605 - val_loss: 83086672.0000 - val_root_mean_squared_error: 9115.1895\n",
            "Epoch 299/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82705184.0000 - root_mean_squared_error: 9094.2393 - val_loss: 83353272.0000 - val_root_mean_squared_error: 9129.8018\n",
            "Epoch 300/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82064608.0000 - root_mean_squared_error: 9058.9521 - val_loss: 83905152.0000 - val_root_mean_squared_error: 9159.9756\n",
            "Epoch 301/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83138504.0000 - root_mean_squared_error: 9118.0322 - val_loss: 83127688.0000 - val_root_mean_squared_error: 9117.4385\n",
            "Epoch 302/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80469192.0000 - root_mean_squared_error: 8970.4619 - val_loss: 84002184.0000 - val_root_mean_squared_error: 9165.2705\n",
            "Epoch 303/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80184096.0000 - root_mean_squared_error: 8954.5576 - val_loss: 85255688.0000 - val_root_mean_squared_error: 9233.4004\n",
            "Epoch 304/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82663960.0000 - root_mean_squared_error: 9091.9727 - val_loss: 84905984.0000 - val_root_mean_squared_error: 9214.4443\n",
            "Epoch 305/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81116584.0000 - root_mean_squared_error: 9006.4746 - val_loss: 83992608.0000 - val_root_mean_squared_error: 9164.7480\n",
            "Epoch 306/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84601928.0000 - root_mean_squared_error: 9197.9307 - val_loss: 83855856.0000 - val_root_mean_squared_error: 9157.2842\n",
            "Epoch 307/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81317256.0000 - root_mean_squared_error: 9017.6084 - val_loss: 83620312.0000 - val_root_mean_squared_error: 9144.4141\n",
            "Epoch 308/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81054904.0000 - root_mean_squared_error: 9003.0498 - val_loss: 83920456.0000 - val_root_mean_squared_error: 9160.8105\n",
            "Epoch 309/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84422896.0000 - root_mean_squared_error: 9188.1934 - val_loss: 84506880.0000 - val_root_mean_squared_error: 9192.7627\n",
            "Epoch 310/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82264928.0000 - root_mean_squared_error: 9070.0020 - val_loss: 85054696.0000 - val_root_mean_squared_error: 9222.5107\n",
            "Epoch 311/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81414112.0000 - root_mean_squared_error: 9022.9766 - val_loss: 82823768.0000 - val_root_mean_squared_error: 9100.7568\n",
            "Epoch 312/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83043376.0000 - root_mean_squared_error: 9112.8135 - val_loss: 83256056.0000 - val_root_mean_squared_error: 9124.4756\n",
            "Epoch 313/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82856056.0000 - root_mean_squared_error: 9102.5303 - val_loss: 83196872.0000 - val_root_mean_squared_error: 9121.2324\n",
            "Epoch 314/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80459168.0000 - root_mean_squared_error: 8969.9033 - val_loss: 84166776.0000 - val_root_mean_squared_error: 9174.2451\n",
            "Epoch 315/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81261104.0000 - root_mean_squared_error: 9014.4941 - val_loss: 83601136.0000 - val_root_mean_squared_error: 9143.3652\n",
            "Epoch 316/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83495456.0000 - root_mean_squared_error: 9137.5850 - val_loss: 84357112.0000 - val_root_mean_squared_error: 9184.6123\n",
            "Epoch 317/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 82435808.0000 - root_mean_squared_error: 9079.4170 - val_loss: 83199264.0000 - val_root_mean_squared_error: 9121.3633\n",
            "Epoch 318/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81273480.0000 - root_mean_squared_error: 9015.1807 - val_loss: 83714040.0000 - val_root_mean_squared_error: 9149.5381\n",
            "Epoch 319/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78908912.0000 - root_mean_squared_error: 8883.0684 - val_loss: 84477552.0000 - val_root_mean_squared_error: 9191.1670\n",
            "Epoch 320/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81985048.0000 - root_mean_squared_error: 9054.5596 - val_loss: 84062536.0000 - val_root_mean_squared_error: 9168.5625\n",
            "Epoch 321/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83555184.0000 - root_mean_squared_error: 9140.8525 - val_loss: 83672144.0000 - val_root_mean_squared_error: 9147.2480\n",
            "Epoch 322/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83670376.0000 - root_mean_squared_error: 9147.1514 - val_loss: 83948168.0000 - val_root_mean_squared_error: 9162.3232\n",
            "Epoch 323/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83729576.0000 - root_mean_squared_error: 9150.3867 - val_loss: 84313992.0000 - val_root_mean_squared_error: 9182.2646\n",
            "Epoch 324/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81053752.0000 - root_mean_squared_error: 9002.9854 - val_loss: 83689640.0000 - val_root_mean_squared_error: 9148.2041\n",
            "Epoch 325/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81185240.0000 - root_mean_squared_error: 9010.2852 - val_loss: 84482328.0000 - val_root_mean_squared_error: 9191.4268\n",
            "Epoch 326/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83948432.0000 - root_mean_squared_error: 9162.3379 - val_loss: 84786424.0000 - val_root_mean_squared_error: 9207.9541\n",
            "Epoch 327/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81930280.0000 - root_mean_squared_error: 9051.5352 - val_loss: 83985024.0000 - val_root_mean_squared_error: 9164.3340\n",
            "Epoch 328/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 84237320.0000 - root_mean_squared_error: 9178.0889 - val_loss: 84979176.0000 - val_root_mean_squared_error: 9218.4150\n",
            "Epoch 329/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83704376.0000 - root_mean_squared_error: 9149.0098 - val_loss: 83236072.0000 - val_root_mean_squared_error: 9123.3809\n",
            "Epoch 330/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82409640.0000 - root_mean_squared_error: 9077.9756 - val_loss: 83924912.0000 - val_root_mean_squared_error: 9161.0537\n",
            "Epoch 331/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80694184.0000 - root_mean_squared_error: 8982.9941 - val_loss: 84733896.0000 - val_root_mean_squared_error: 9205.1016\n",
            "Epoch 332/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82979288.0000 - root_mean_squared_error: 9109.2969 - val_loss: 83713872.0000 - val_root_mean_squared_error: 9149.5283\n",
            "Epoch 333/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82253432.0000 - root_mean_squared_error: 9069.3682 - val_loss: 85008584.0000 - val_root_mean_squared_error: 9220.0098\n",
            "Epoch 334/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 80922856.0000 - root_mean_squared_error: 8995.7129 - val_loss: 84433112.0000 - val_root_mean_squared_error: 9188.7490\n",
            "Epoch 335/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79816656.0000 - root_mean_squared_error: 8934.0166 - val_loss: 85585824.0000 - val_root_mean_squared_error: 9251.2607\n",
            "Epoch 336/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81564904.0000 - root_mean_squared_error: 9031.3291 - val_loss: 83657520.0000 - val_root_mean_squared_error: 9146.4482\n",
            "Epoch 337/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 82724144.0000 - root_mean_squared_error: 9095.2812 - val_loss: 83784424.0000 - val_root_mean_squared_error: 9153.3828\n",
            "Epoch 338/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81411920.0000 - root_mean_squared_error: 9022.8555 - val_loss: 83195504.0000 - val_root_mean_squared_error: 9121.1572\n",
            "Epoch 339/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79056176.0000 - root_mean_squared_error: 8891.3535 - val_loss: 82994400.0000 - val_root_mean_squared_error: 9110.1260\n",
            "Epoch 340/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81582584.0000 - root_mean_squared_error: 9032.3076 - val_loss: 83555952.0000 - val_root_mean_squared_error: 9140.8945\n",
            "Epoch 341/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81125056.0000 - root_mean_squared_error: 9006.9453 - val_loss: 83682128.0000 - val_root_mean_squared_error: 9147.7939\n",
            "Epoch 342/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79987288.0000 - root_mean_squared_error: 8943.5615 - val_loss: 84656416.0000 - val_root_mean_squared_error: 9200.8926\n",
            "Epoch 343/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83707032.0000 - root_mean_squared_error: 9149.1543 - val_loss: 84230760.0000 - val_root_mean_squared_error: 9177.7314\n",
            "Epoch 344/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81770784.0000 - root_mean_squared_error: 9042.7197 - val_loss: 84787640.0000 - val_root_mean_squared_error: 9208.0205\n",
            "Epoch 345/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79933504.0000 - root_mean_squared_error: 8940.5537 - val_loss: 83965192.0000 - val_root_mean_squared_error: 9163.2520\n",
            "Epoch 346/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79992920.0000 - root_mean_squared_error: 8943.8760 - val_loss: 83619440.0000 - val_root_mean_squared_error: 9144.3662\n",
            "Epoch 347/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82389912.0000 - root_mean_squared_error: 9076.8887 - val_loss: 82711856.0000 - val_root_mean_squared_error: 9094.6055\n",
            "Epoch 348/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 79577304.0000 - root_mean_squared_error: 8920.6113 - val_loss: 82748944.0000 - val_root_mean_squared_error: 9096.6445\n",
            "Epoch 349/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80866328.0000 - root_mean_squared_error: 8992.5703 - val_loss: 83736744.0000 - val_root_mean_squared_error: 9150.7783\n",
            "Epoch 350/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80689648.0000 - root_mean_squared_error: 8982.7412 - val_loss: 82978224.0000 - val_root_mean_squared_error: 9109.2383\n",
            "Epoch 351/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83532400.0000 - root_mean_squared_error: 9139.6064 - val_loss: 82750480.0000 - val_root_mean_squared_error: 9096.7295\n",
            "Epoch 352/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78856408.0000 - root_mean_squared_error: 8880.1133 - val_loss: 82585552.0000 - val_root_mean_squared_error: 9087.6592\n",
            "Epoch 353/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81361096.0000 - root_mean_squared_error: 9020.0391 - val_loss: 83684480.0000 - val_root_mean_squared_error: 9147.9219\n",
            "Epoch 354/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80394872.0000 - root_mean_squared_error: 8966.3184 - val_loss: 83917880.0000 - val_root_mean_squared_error: 9160.6699\n",
            "Epoch 355/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83669432.0000 - root_mean_squared_error: 9147.0996 - val_loss: 85038432.0000 - val_root_mean_squared_error: 9221.6289\n",
            "Epoch 356/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81518576.0000 - root_mean_squared_error: 9028.7637 - val_loss: 83716000.0000 - val_root_mean_squared_error: 9149.6445\n",
            "Epoch 357/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81284064.0000 - root_mean_squared_error: 9015.7676 - val_loss: 84931400.0000 - val_root_mean_squared_error: 9215.8232\n",
            "Epoch 358/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81222952.0000 - root_mean_squared_error: 9012.3779 - val_loss: 83345720.0000 - val_root_mean_squared_error: 9129.3877\n",
            "Epoch 359/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83344480.0000 - root_mean_squared_error: 9129.3193 - val_loss: 83242280.0000 - val_root_mean_squared_error: 9123.7207\n",
            "Epoch 360/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81916824.0000 - root_mean_squared_error: 9050.7910 - val_loss: 83051976.0000 - val_root_mean_squared_error: 9113.2861\n",
            "Epoch 361/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83318680.0000 - root_mean_squared_error: 9127.9062 - val_loss: 83982248.0000 - val_root_mean_squared_error: 9164.1826\n",
            "Epoch 362/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83068712.0000 - root_mean_squared_error: 9114.2041 - val_loss: 83408048.0000 - val_root_mean_squared_error: 9132.8008\n",
            "Epoch 363/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80756968.0000 - root_mean_squared_error: 8986.4883 - val_loss: 83481016.0000 - val_root_mean_squared_error: 9136.7949\n",
            "Epoch 364/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81950072.0000 - root_mean_squared_error: 9052.6279 - val_loss: 84298744.0000 - val_root_mean_squared_error: 9181.4346\n",
            "Epoch 365/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82463176.0000 - root_mean_squared_error: 9080.9238 - val_loss: 84396776.0000 - val_root_mean_squared_error: 9186.7715\n",
            "Epoch 366/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83964944.0000 - root_mean_squared_error: 9163.2383 - val_loss: 84972856.0000 - val_root_mean_squared_error: 9218.0723\n",
            "Epoch 367/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80993408.0000 - root_mean_squared_error: 8999.6338 - val_loss: 83487896.0000 - val_root_mean_squared_error: 9137.1709\n",
            "Epoch 368/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80944736.0000 - root_mean_squared_error: 8996.9297 - val_loss: 85779320.0000 - val_root_mean_squared_error: 9261.7129\n",
            "Epoch 369/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80921592.0000 - root_mean_squared_error: 8995.6426 - val_loss: 83991784.0000 - val_root_mean_squared_error: 9164.7031\n",
            "Epoch 370/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80233584.0000 - root_mean_squared_error: 8957.3203 - val_loss: 83720968.0000 - val_root_mean_squared_error: 9149.9160\n",
            "Epoch 371/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81455912.0000 - root_mean_squared_error: 9025.2930 - val_loss: 84461088.0000 - val_root_mean_squared_error: 9190.2715\n",
            "Epoch 372/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83372216.0000 - root_mean_squared_error: 9130.8389 - val_loss: 83075472.0000 - val_root_mean_squared_error: 9114.5742\n",
            "Epoch 373/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81216968.0000 - root_mean_squared_error: 9012.0459 - val_loss: 83877920.0000 - val_root_mean_squared_error: 9158.4893\n",
            "Epoch 374/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80927432.0000 - root_mean_squared_error: 8995.9678 - val_loss: 83136400.0000 - val_root_mean_squared_error: 9117.9160\n",
            "Epoch 375/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80968720.0000 - root_mean_squared_error: 8998.2617 - val_loss: 84207576.0000 - val_root_mean_squared_error: 9176.4688\n",
            "Epoch 376/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81424872.0000 - root_mean_squared_error: 9023.5732 - val_loss: 84567728.0000 - val_root_mean_squared_error: 9196.0713\n",
            "Epoch 377/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80377264.0000 - root_mean_squared_error: 8965.3369 - val_loss: 82841360.0000 - val_root_mean_squared_error: 9101.7227\n",
            "Epoch 378/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81850896.0000 - root_mean_squared_error: 9047.1484 - val_loss: 83429760.0000 - val_root_mean_squared_error: 9133.9893\n",
            "Epoch 379/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82746480.0000 - root_mean_squared_error: 9096.5088 - val_loss: 83279696.0000 - val_root_mean_squared_error: 9125.7705\n",
            "Epoch 380/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80589744.0000 - root_mean_squared_error: 8977.1787 - val_loss: 83079288.0000 - val_root_mean_squared_error: 9114.7842\n",
            "Epoch 381/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78433488.0000 - root_mean_squared_error: 8856.2686 - val_loss: 83908800.0000 - val_root_mean_squared_error: 9160.1748\n",
            "Epoch 382/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84017160.0000 - root_mean_squared_error: 9166.0879 - val_loss: 83245000.0000 - val_root_mean_squared_error: 9123.8701\n",
            "Epoch 383/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80711320.0000 - root_mean_squared_error: 8983.9482 - val_loss: 86027320.0000 - val_root_mean_squared_error: 9275.0918\n",
            "Epoch 384/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78726616.0000 - root_mean_squared_error: 8872.8018 - val_loss: 83295192.0000 - val_root_mean_squared_error: 9126.6201\n",
            "Epoch 385/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80839416.0000 - root_mean_squared_error: 8991.0742 - val_loss: 85550264.0000 - val_root_mean_squared_error: 9249.3389\n",
            "Epoch 386/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 82007376.0000 - root_mean_squared_error: 9055.7920 - val_loss: 84670560.0000 - val_root_mean_squared_error: 9201.6611\n",
            "Epoch 387/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82514448.0000 - root_mean_squared_error: 9083.7461 - val_loss: 83553800.0000 - val_root_mean_squared_error: 9140.7764\n",
            "Epoch 388/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80196528.0000 - root_mean_squared_error: 8955.2510 - val_loss: 83430504.0000 - val_root_mean_squared_error: 9134.0303\n",
            "Epoch 389/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 82837744.0000 - root_mean_squared_error: 9101.5244 - val_loss: 84191320.0000 - val_root_mean_squared_error: 9175.5830\n",
            "Epoch 390/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81596120.0000 - root_mean_squared_error: 9033.0566 - val_loss: 83491744.0000 - val_root_mean_squared_error: 9137.3818\n",
            "Epoch 391/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 79212704.0000 - root_mean_squared_error: 8900.1523 - val_loss: 82810120.0000 - val_root_mean_squared_error: 9100.0068\n",
            "Epoch 392/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78454032.0000 - root_mean_squared_error: 8857.4277 - val_loss: 82951664.0000 - val_root_mean_squared_error: 9107.7803\n",
            "Epoch 393/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80122248.0000 - root_mean_squared_error: 8951.1035 - val_loss: 83404160.0000 - val_root_mean_squared_error: 9132.5879\n",
            "Epoch 394/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81251448.0000 - root_mean_squared_error: 9013.9590 - val_loss: 85812784.0000 - val_root_mean_squared_error: 9263.5186\n",
            "Epoch 395/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80018848.0000 - root_mean_squared_error: 8945.3252 - val_loss: 83865072.0000 - val_root_mean_squared_error: 9157.7871\n",
            "Epoch 396/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81847680.0000 - root_mean_squared_error: 9046.9707 - val_loss: 83904168.0000 - val_root_mean_squared_error: 9159.9219\n",
            "Epoch 397/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82982928.0000 - root_mean_squared_error: 9109.4971 - val_loss: 83142472.0000 - val_root_mean_squared_error: 9118.2490\n",
            "Epoch 398/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 83095656.0000 - root_mean_squared_error: 9115.6816 - val_loss: 84729240.0000 - val_root_mean_squared_error: 9204.8486\n",
            "Epoch 399/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 84575440.0000 - root_mean_squared_error: 9196.4902 - val_loss: 84418272.0000 - val_root_mean_squared_error: 9187.9414\n",
            "Epoch 400/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81685384.0000 - root_mean_squared_error: 9037.9971 - val_loss: 85915800.0000 - val_root_mean_squared_error: 9269.0771\n",
            "Epoch 401/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81323784.0000 - root_mean_squared_error: 9017.9697 - val_loss: 83563648.0000 - val_root_mean_squared_error: 9141.3154\n",
            "Epoch 402/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79031440.0000 - root_mean_squared_error: 8889.9629 - val_loss: 82917080.0000 - val_root_mean_squared_error: 9105.8818\n",
            "Epoch 403/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80284712.0000 - root_mean_squared_error: 8960.1738 - val_loss: 82974752.0000 - val_root_mean_squared_error: 9109.0479\n",
            "Epoch 404/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82259040.0000 - root_mean_squared_error: 9069.6768 - val_loss: 82508480.0000 - val_root_mean_squared_error: 9083.4180\n",
            "Epoch 405/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81308312.0000 - root_mean_squared_error: 9017.1123 - val_loss: 82881720.0000 - val_root_mean_squared_error: 9103.9395\n",
            "Epoch 406/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81025336.0000 - root_mean_squared_error: 9001.4072 - val_loss: 83279800.0000 - val_root_mean_squared_error: 9125.7764\n",
            "Epoch 407/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81527208.0000 - root_mean_squared_error: 9029.2422 - val_loss: 83549608.0000 - val_root_mean_squared_error: 9140.5479\n",
            "Epoch 408/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82263248.0000 - root_mean_squared_error: 9069.9092 - val_loss: 83238760.0000 - val_root_mean_squared_error: 9123.5273\n",
            "Epoch 409/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82415712.0000 - root_mean_squared_error: 9078.3096 - val_loss: 82615088.0000 - val_root_mean_squared_error: 9089.2842\n",
            "Epoch 410/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79629864.0000 - root_mean_squared_error: 8923.5566 - val_loss: 83401992.0000 - val_root_mean_squared_error: 9132.4688\n",
            "Epoch 411/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79345008.0000 - root_mean_squared_error: 8907.5811 - val_loss: 82634896.0000 - val_root_mean_squared_error: 9090.3740\n",
            "Epoch 412/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80927928.0000 - root_mean_squared_error: 8995.9951 - val_loss: 83067456.0000 - val_root_mean_squared_error: 9114.1348\n",
            "Epoch 413/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82067368.0000 - root_mean_squared_error: 9059.1045 - val_loss: 85321344.0000 - val_root_mean_squared_error: 9236.9551\n",
            "Epoch 414/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80838712.0000 - root_mean_squared_error: 8991.0352 - val_loss: 83801144.0000 - val_root_mean_squared_error: 9154.2969\n",
            "Epoch 415/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81517432.0000 - root_mean_squared_error: 9028.7002 - val_loss: 84307040.0000 - val_root_mean_squared_error: 9181.8867\n",
            "Epoch 416/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79449752.0000 - root_mean_squared_error: 8913.4590 - val_loss: 83398376.0000 - val_root_mean_squared_error: 9132.2715\n",
            "Epoch 417/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 83754528.0000 - root_mean_squared_error: 9151.7500 - val_loss: 83415360.0000 - val_root_mean_squared_error: 9133.2012\n",
            "Epoch 418/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81751920.0000 - root_mean_squared_error: 9041.6768 - val_loss: 84818208.0000 - val_root_mean_squared_error: 9209.6797\n",
            "Epoch 419/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81441472.0000 - root_mean_squared_error: 9024.4932 - val_loss: 83640656.0000 - val_root_mean_squared_error: 9145.5264\n",
            "Epoch 420/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80968216.0000 - root_mean_squared_error: 8998.2344 - val_loss: 83983280.0000 - val_root_mean_squared_error: 9164.2393\n",
            "Epoch 421/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80366952.0000 - root_mean_squared_error: 8964.7617 - val_loss: 83655944.0000 - val_root_mean_squared_error: 9146.3623\n",
            "Epoch 422/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82509968.0000 - root_mean_squared_error: 9083.5000 - val_loss: 82729816.0000 - val_root_mean_squared_error: 9095.5928\n",
            "Epoch 423/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80520112.0000 - root_mean_squared_error: 8973.2998 - val_loss: 82742768.0000 - val_root_mean_squared_error: 9096.3057\n",
            "Epoch 424/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81051080.0000 - root_mean_squared_error: 9002.8369 - val_loss: 83051376.0000 - val_root_mean_squared_error: 9113.2529\n",
            "Epoch 425/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80622720.0000 - root_mean_squared_error: 8979.0156 - val_loss: 83470384.0000 - val_root_mean_squared_error: 9136.2129\n",
            "Epoch 426/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82466552.0000 - root_mean_squared_error: 9081.1094 - val_loss: 83163432.0000 - val_root_mean_squared_error: 9119.3984\n",
            "Epoch 427/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81944944.0000 - root_mean_squared_error: 9052.3447 - val_loss: 84154360.0000 - val_root_mean_squared_error: 9173.5684\n",
            "Epoch 428/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79060256.0000 - root_mean_squared_error: 8891.5830 - val_loss: 84101560.0000 - val_root_mean_squared_error: 9170.6904\n",
            "Epoch 429/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80767696.0000 - root_mean_squared_error: 8987.0850 - val_loss: 83084680.0000 - val_root_mean_squared_error: 9115.0801\n",
            "Epoch 430/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80040960.0000 - root_mean_squared_error: 8946.5615 - val_loss: 83910992.0000 - val_root_mean_squared_error: 9160.2939\n",
            "Epoch 431/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 80449120.0000 - root_mean_squared_error: 8969.3438 - val_loss: 84322888.0000 - val_root_mean_squared_error: 9182.7490\n",
            "Epoch 432/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82529720.0000 - root_mean_squared_error: 9084.5869 - val_loss: 83718864.0000 - val_root_mean_squared_error: 9149.8018\n",
            "Epoch 433/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 82839888.0000 - root_mean_squared_error: 9101.6416 - val_loss: 84531416.0000 - val_root_mean_squared_error: 9194.0967\n",
            "Epoch 434/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82330312.0000 - root_mean_squared_error: 9073.6055 - val_loss: 83802600.0000 - val_root_mean_squared_error: 9154.3760\n",
            "Epoch 435/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80529424.0000 - root_mean_squared_error: 8973.8184 - val_loss: 84153520.0000 - val_root_mean_squared_error: 9173.5225\n",
            "Epoch 436/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80358304.0000 - root_mean_squared_error: 8964.2793 - val_loss: 83017712.0000 - val_root_mean_squared_error: 9111.4053\n",
            "Epoch 437/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78989952.0000 - root_mean_squared_error: 8887.6289 - val_loss: 84116672.0000 - val_root_mean_squared_error: 9171.5146\n",
            "Epoch 438/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79425160.0000 - root_mean_squared_error: 8912.0791 - val_loss: 83254328.0000 - val_root_mean_squared_error: 9124.3809\n",
            "Epoch 439/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81027176.0000 - root_mean_squared_error: 9001.5098 - val_loss: 83398536.0000 - val_root_mean_squared_error: 9132.2803\n",
            "Epoch 440/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 82266184.0000 - root_mean_squared_error: 9070.0703 - val_loss: 82804024.0000 - val_root_mean_squared_error: 9099.6719\n",
            "Epoch 441/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81146296.0000 - root_mean_squared_error: 9008.1240 - val_loss: 82537904.0000 - val_root_mean_squared_error: 9085.0371\n",
            "Epoch 442/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82442720.0000 - root_mean_squared_error: 9079.7969 - val_loss: 83987528.0000 - val_root_mean_squared_error: 9164.4707\n",
            "Epoch 443/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82333464.0000 - root_mean_squared_error: 9073.7793 - val_loss: 84006760.0000 - val_root_mean_squared_error: 9165.5205\n",
            "Epoch 444/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82108056.0000 - root_mean_squared_error: 9061.3496 - val_loss: 84176416.0000 - val_root_mean_squared_error: 9174.7705\n",
            "Epoch 445/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81697736.0000 - root_mean_squared_error: 9038.6797 - val_loss: 84327128.0000 - val_root_mean_squared_error: 9182.9805\n",
            "Epoch 446/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80243728.0000 - root_mean_squared_error: 8957.8867 - val_loss: 82951264.0000 - val_root_mean_squared_error: 9107.7588\n",
            "Epoch 447/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 79140360.0000 - root_mean_squared_error: 8896.0869 - val_loss: 83368216.0000 - val_root_mean_squared_error: 9130.6201\n",
            "Epoch 448/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81935040.0000 - root_mean_squared_error: 9051.7979 - val_loss: 83294400.0000 - val_root_mean_squared_error: 9126.5762\n",
            "Epoch 449/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80728344.0000 - root_mean_squared_error: 8984.8955 - val_loss: 83029792.0000 - val_root_mean_squared_error: 9112.0684\n",
            "Epoch 450/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81371008.0000 - root_mean_squared_error: 9020.5879 - val_loss: 83058680.0000 - val_root_mean_squared_error: 9113.6533\n",
            "Epoch 451/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80848672.0000 - root_mean_squared_error: 8991.5889 - val_loss: 83922280.0000 - val_root_mean_squared_error: 9160.9102\n",
            "Epoch 452/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80055584.0000 - root_mean_squared_error: 8947.3789 - val_loss: 83946520.0000 - val_root_mean_squared_error: 9162.2334\n",
            "Epoch 453/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81440752.0000 - root_mean_squared_error: 9024.4531 - val_loss: 84265200.0000 - val_root_mean_squared_error: 9179.6074\n",
            "Epoch 454/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80427504.0000 - root_mean_squared_error: 8968.1387 - val_loss: 85399248.0000 - val_root_mean_squared_error: 9241.1709\n",
            "Epoch 455/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81594832.0000 - root_mean_squared_error: 9032.9854 - val_loss: 84321920.0000 - val_root_mean_squared_error: 9182.6963\n",
            "Epoch 456/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79547056.0000 - root_mean_squared_error: 8918.9160 - val_loss: 82680816.0000 - val_root_mean_squared_error: 9092.8994\n",
            "Epoch 457/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82398448.0000 - root_mean_squared_error: 9077.3594 - val_loss: 83549064.0000 - val_root_mean_squared_error: 9140.5176\n",
            "Epoch 458/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81662464.0000 - root_mean_squared_error: 9036.7285 - val_loss: 82568744.0000 - val_root_mean_squared_error: 9086.7344\n",
            "Epoch 459/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81052064.0000 - root_mean_squared_error: 9002.8916 - val_loss: 83228680.0000 - val_root_mean_squared_error: 9122.9756\n",
            "Epoch 460/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80604656.0000 - root_mean_squared_error: 8978.0098 - val_loss: 82970440.0000 - val_root_mean_squared_error: 9108.8115\n",
            "Epoch 461/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82268128.0000 - root_mean_squared_error: 9070.1777 - val_loss: 84292176.0000 - val_root_mean_squared_error: 9181.0771\n",
            "Epoch 462/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80552936.0000 - root_mean_squared_error: 8975.1289 - val_loss: 83262256.0000 - val_root_mean_squared_error: 9124.8154\n",
            "Epoch 463/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81057096.0000 - root_mean_squared_error: 9003.1719 - val_loss: 83202528.0000 - val_root_mean_squared_error: 9121.5420\n",
            "Epoch 464/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80230008.0000 - root_mean_squared_error: 8957.1201 - val_loss: 82864760.0000 - val_root_mean_squared_error: 9103.0078\n",
            "Epoch 465/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78788936.0000 - root_mean_squared_error: 8876.3135 - val_loss: 82314784.0000 - val_root_mean_squared_error: 9072.7500\n",
            "Epoch 466/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80823080.0000 - root_mean_squared_error: 8990.1660 - val_loss: 82873624.0000 - val_root_mean_squared_error: 9103.4951\n",
            "Epoch 467/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80381568.0000 - root_mean_squared_error: 8965.5771 - val_loss: 82639072.0000 - val_root_mean_squared_error: 9090.6035\n",
            "Epoch 468/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 81351304.0000 - root_mean_squared_error: 9019.4961 - val_loss: 84123336.0000 - val_root_mean_squared_error: 9171.8779\n",
            "Epoch 469/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81790736.0000 - root_mean_squared_error: 9043.8232 - val_loss: 83980456.0000 - val_root_mean_squared_error: 9164.0850\n",
            "Epoch 470/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80139248.0000 - root_mean_squared_error: 8952.0527 - val_loss: 83195712.0000 - val_root_mean_squared_error: 9121.1680\n",
            "Epoch 471/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79107944.0000 - root_mean_squared_error: 8894.2646 - val_loss: 83093248.0000 - val_root_mean_squared_error: 9115.5498\n",
            "Epoch 472/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80839328.0000 - root_mean_squared_error: 8991.0693 - val_loss: 83334216.0000 - val_root_mean_squared_error: 9128.7578\n",
            "Epoch 473/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81540320.0000 - root_mean_squared_error: 9029.9678 - val_loss: 84431496.0000 - val_root_mean_squared_error: 9188.6611\n",
            "Epoch 474/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 82269568.0000 - root_mean_squared_error: 9070.2578 - val_loss: 83274584.0000 - val_root_mean_squared_error: 9125.4912\n",
            "Epoch 475/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79890384.0000 - root_mean_squared_error: 8938.1416 - val_loss: 81906592.0000 - val_root_mean_squared_error: 9050.2266\n",
            "Epoch 476/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79208240.0000 - root_mean_squared_error: 8899.9014 - val_loss: 82804048.0000 - val_root_mean_squared_error: 9099.6729\n",
            "Epoch 477/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81565080.0000 - root_mean_squared_error: 9031.3389 - val_loss: 82138640.0000 - val_root_mean_squared_error: 9063.0371\n",
            "Epoch 478/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81942344.0000 - root_mean_squared_error: 9052.2012 - val_loss: 81502464.0000 - val_root_mean_squared_error: 9027.8711\n",
            "Epoch 479/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78203192.0000 - root_mean_squared_error: 8843.2568 - val_loss: 82759488.0000 - val_root_mean_squared_error: 9097.2246\n",
            "Epoch 480/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81923568.0000 - root_mean_squared_error: 9051.1641 - val_loss: 82395584.0000 - val_root_mean_squared_error: 9077.2012\n",
            "Epoch 481/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 77615976.0000 - root_mean_squared_error: 8809.9932 - val_loss: 81694488.0000 - val_root_mean_squared_error: 9038.5000\n",
            "Epoch 482/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 80819080.0000 - root_mean_squared_error: 8989.9434 - val_loss: 81087664.0000 - val_root_mean_squared_error: 9004.8691\n",
            "Epoch 483/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81227384.0000 - root_mean_squared_error: 9012.6240 - val_loss: 82328408.0000 - val_root_mean_squared_error: 9073.5000\n",
            "Epoch 484/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 79929704.0000 - root_mean_squared_error: 8940.3418 - val_loss: 82902768.0000 - val_root_mean_squared_error: 9105.0957\n",
            "Epoch 485/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78846256.0000 - root_mean_squared_error: 8879.5410 - val_loss: 81615160.0000 - val_root_mean_squared_error: 9034.1113\n",
            "Epoch 486/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80604360.0000 - root_mean_squared_error: 8977.9932 - val_loss: 81776576.0000 - val_root_mean_squared_error: 9043.0400\n",
            "Epoch 487/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79235064.0000 - root_mean_squared_error: 8901.4082 - val_loss: 81173288.0000 - val_root_mean_squared_error: 9009.6221\n",
            "Epoch 488/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 77983664.0000 - root_mean_squared_error: 8830.8359 - val_loss: 82004872.0000 - val_root_mean_squared_error: 9055.6543\n",
            "Epoch 489/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 85639216.0000 - root_mean_squared_error: 9254.1455 - val_loss: 82189864.0000 - val_root_mean_squared_error: 9065.8623\n",
            "Epoch 490/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81837152.0000 - root_mean_squared_error: 9046.3887 - val_loss: 84037848.0000 - val_root_mean_squared_error: 9167.2158\n",
            "Epoch 491/500\n",
            "92/92 [==============================] - 0s 4ms/step - loss: 81267904.0000 - root_mean_squared_error: 9014.8711 - val_loss: 81647832.0000 - val_root_mean_squared_error: 9035.9189\n",
            "Epoch 492/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81829328.0000 - root_mean_squared_error: 9045.9561 - val_loss: 81772848.0000 - val_root_mean_squared_error: 9042.8340\n",
            "Epoch 493/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80208128.0000 - root_mean_squared_error: 8955.8994 - val_loss: 82460128.0000 - val_root_mean_squared_error: 9080.7559\n",
            "Epoch 494/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 80210224.0000 - root_mean_squared_error: 8956.0156 - val_loss: 82498848.0000 - val_root_mean_squared_error: 9082.8877\n",
            "Epoch 495/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79838552.0000 - root_mean_squared_error: 8935.2422 - val_loss: 81778720.0000 - val_root_mean_squared_error: 9043.1592\n",
            "Epoch 496/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 81807224.0000 - root_mean_squared_error: 9044.7354 - val_loss: 81792112.0000 - val_root_mean_squared_error: 9043.8994\n",
            "Epoch 497/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 77160200.0000 - root_mean_squared_error: 8784.0879 - val_loss: 83051656.0000 - val_root_mean_squared_error: 9113.2686\n",
            "Epoch 498/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 79751784.0000 - root_mean_squared_error: 8930.3857 - val_loss: 81881432.0000 - val_root_mean_squared_error: 9048.8359\n",
            "Epoch 499/500\n",
            "92/92 [==============================] - 0s 2ms/step - loss: 80469208.0000 - root_mean_squared_error: 8970.4629 - val_loss: 81311680.0000 - val_root_mean_squared_error: 9017.2988\n",
            "Epoch 500/500\n",
            "92/92 [==============================] - 0s 3ms/step - loss: 78980344.0000 - root_mean_squared_error: 8887.0889 - val_loss: 83076952.0000 - val_root_mean_squared_error: 9114.6562\n"
          ]
        }
      ],
      "source": [
        "dropout = 0.1 # 0.2 best\n",
        "training = True\n",
        "\n",
        "# Define the architecture of the MLP with L2 regularization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(24,)))\n",
        "model.add(Dense(units=10, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(units=1, activation='linear'))  # Output layer with 1 neuron for regression\n",
        "\"\"\"\n",
        "model.add(Input(shape=(24,)))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=1, activation='linear'))  # Output layer with 1 neuron for regression\n",
        "\"\"\"\n",
        "#print(model.summary())\n",
        "\n",
        "# Compile the model with mean squared error (MSE) loss, and root mean square error (RMSE) as metric\n",
        "# Use Adam optimizer with learning rate\n",
        "optimizer = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "# Train the model and save the learning history, use x_dev and y_dev for validation\n",
        "history = model.fit(X_train_scaled, y_train, epochs=500, batch_size=32, validation_data=(X_dev_scaled, y_dev))\n",
        "#history = model.fit(batched_X_train, batched_y_train, epochs=50, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mit BatchNormalization:\n",
        "\n",
        "92/92 [==============================] - 0s 5ms/step - loss: 32794122.0000 - root_mean_squared_error: 5726.6152 - val_loss: 70737936.0000 - val_root_mean_squared_error: 8410.5850\n",
        "\n",
        "Ohne BatchNormalization:\n",
        "\n",
        "92/92 [==============================] - 0s 4ms/step - loss: 70121296.0000 - root_mean_squared_error: 8373.8457 - val_loss: 87356080.0000 - val_root_mean_squared_error: 9346.4473\n"
      ],
      "metadata": {
        "id": "WXmeLuSd__tD"
      },
      "id": "WXmeLuSd__tD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nH3EF2UCcYy6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH3EF2UCcYy6",
        "outputId": "6d4f5598-db08-4cbe-8e63-30b5c5caade6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "history_reg0 = history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gMEQCWywcatA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMEQCWywcatA",
        "outputId": "bcd64c94-b63b-4511-eea9-8b3b1c80a876"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "history_reg1000 = history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LurYAa8ue1at",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LurYAa8ue1at",
        "outputId": "7bec3e49-3d77-4780-efa1-56e882cd0621"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "history_reg0_not_scaled = history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ozrhdiYYFEAz",
      "metadata": {
        "id": "ozrhdiYYFEAz"
      },
      "outputs": [],
      "source": [
        "model.layers[0].get_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xWmUZ5O0Rvh6",
      "metadata": {
        "id": "xWmUZ5O0Rvh6"
      },
      "source": [
        "Epoch 100/100\n",
        "46/46 [==============================] - 1s 23ms/step - loss: 6617481.5000 - root_mean_squared_error: 2572.4465 - val_loss: 67260184.0000 - val_root_mean_squared_error: 8201.2305\n",
        "CPU times: user 2min 43s, sys: 6.67 s, total: 2min 50s\n",
        "Wall time: 2min 23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RhbEPgSPsXCy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "RhbEPgSPsXCy",
        "outputId": "5609e31d-6daf-4066-c720-45ece47bd0ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"a2cd6f39-d273-47ee-aaa0-732030972cc3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a2cd6f39-d273-47ee-aaa0-732030972cc3\")) {                    Plotly.newPlot(                        \"a2cd6f39-d273-47ee-aaa0-732030972cc3\",                        [{\"hovertemplate\":\"<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"mode\":\"lines+markers\",\"name\":\"Train L2=0\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[34203.95703125,34194.5703125,34167.9140625,34106.2734375,33989.36328125,33795.60546875,33502.08203125,33089.06640625,32539.818359375,31843.26953125,30999.00390625,30010.216796875,28893.541015625,27665.921875,26357.8984375,25007.380859375,23652.365234375,22333.181640625,21087.62890625,19935.958984375,18889.744140625,17947.833984375,17095.998046875,16315.564453125,15597.0126953125,14928.5146484375,14307.9345703125,13728.6943359375,13196.169921875,12709.8740234375,12271.701171875,11881.779296875,11545.8935546875,11252.1640625,11004.591796875,10793.578125,10616.4814453125,10466.888671875,10341.6083984375,10235.3740234375,10140.763671875,10059.3037109375,9986.50390625,9920.9189453125,9859.810546875,9804.5166015625,9753.3994140625,9703.63671875,9658.357421875,9615.724609375,9574.0693359375,9535.63671875,9499.3896484375,9464.08984375,9431.46484375,9399.2236328125,9368.23828125,9340.1953125,9313.3564453125,9285.5693359375,9261.244140625,9237.9033203125,9212.9716796875,9191.8974609375,9169.4814453125,9149.7470703125,9130.9365234375,9112.0986328125,9096.1181640625,9077.3525390625,9060.8837890625,9047.4248046875,9032.259765625,9016.099609375,9001.73046875,8987.724609375,8975.8515625,8961.1328125,8947.828125,8935.9755859375,8922.8544921875,8912.58984375,8900.625,8890.6708984375,8879.953125,8869.875,8859.466796875,8851.5244140625,8840.4560546875,8831.216796875,8823.0478515625,8813.1318359375,8807.607421875,8797.0107421875,8789.3740234375,8784.0732421875,8774.8828125,8767.484375,8760.0810546875,8753.1328125],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Test L2=0\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[33984.88671875,33968.65625,33926.77734375,33839.2890625,33683.91015625,33440.9765625,33087.7890625,32598.689453125,31966.603515625,31192.572265625,30268.619140625,29195.4140625,27998.26171875,26708.06640625,25359.349609375,23976.4453125,22613.41015625,21306.900390625,20092.2109375,18980.486328125,17971.103515625,17061.48828125,16235.048828125,15482.4208984375,14777.619140625,14135.2275390625,13524.8466796875,12959.6650390625,12446.9140625,11981.1748046875,11561.0380859375,11191.865234375,10868.71484375,10599.5078125,10362.61328125,10163.1083984375,9992.78515625,9851.5283203125,9726.7607421875,9618.1591796875,9526.1943359375,9442.478515625,9370.57421875,9303.0908203125,9241.607421875,9184.4873046875,9129.984375,9082.5361328125,9035.4482421875,8993.47265625,8951.66015625,8911.0146484375,8874.3310546875,8839.4384765625,8805.8369140625,8775.982421875,8747.2734375,8718.02734375,8689.0185546875,8665.05078125,8640.646484375,8618.7978515625,8593.9853515625,8572.0634765625,8554.8857421875,8535.5185546875,8517.26171875,8501.4697265625,8485.306640625,8469.630859375,8454.4755859375,8440.4072265625,8426.7900390625,8412.982421875,8399.818359375,8386.9892578125,8375.0107421875,8362.4150390625,8349.7265625,8341.5595703125,8330.91015625,8320.2998046875,8310.3203125,8301.724609375,8293.4755859375,8284.1728515625,8276.95703125,8268.33984375,8259.0009765625,8253.8212890625,8245.392578125,8237.4150390625,8227.6474609375,8222.8671875,8215.6572265625,8209.9345703125,8203.861328125,8199.6552734375,8193.296875,8187.68994140625],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\"},\"mode\":\"lines+markers\",\"name\":\"Train L2=0 not scaled\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[17865.48828125,11055.728515625,10567.78515625,10450.8486328125,10396.0400390625,10349.0380859375,10307.3720703125,10260.080078125,10230.7158203125,10219.41015625,10176.1728515625,10141.5693359375,10085.8232421875,10080.97265625,10059.3173828125,9971.294921875,10011.052734375,9933.5263671875,9901.8935546875,9938.8212890625,9867.5625,9870.4306640625,9825.486328125,9808.0625,9819.6748046875,9828.814453125,9787.275390625,9796.0810546875,9792.70703125,9753.1689453125,9770.2265625,9745.615234375,9783.912109375,9818.6142578125,9744.8369140625,9714.6533203125,9713.314453125,9706.5576171875,9713.8681640625,9731.3212890625,9743.8037109375,9699.357421875,9735.556640625,9731.4033203125,9696.1494140625,9740.9091796875,9712.5341796875,9691.2666015625,9693.8359375,9664.25390625,9659.9091796875,9685.564453125,9664.98046875,9649.7734375,9680.3515625,9677.044921875,9657.8984375,9661.7958984375,9684.740234375,9631.09375,9660.5419921875,9672.04296875,9700.64453125,9651.904296875,9654.681640625,9676.5576171875,9659.578125,9663.99609375,9651.994140625,9750.953125,9654.9541015625,9655.5537109375,9623.2666015625,9673.92578125,9630.5390625,9632.0830078125,9635.9052734375,9616.04296875,9661.3984375,9655.9033203125,9598.6572265625,9631.36328125,9619.8818359375,9623.3701171875,9600.173828125,9624.39453125,9616.724609375,9641.84375,9624.064453125,9598.0732421875,9621.953125,9655.947265625,9639.126953125,9656.37890625,9632.8798828125,9606.576171875,9611.6142578125,9595.775390625,9584.68359375,9625.189453125],\"type\":\"scatter\"},{\"line\":{\"color\":\"black\"},\"mode\":\"lines+markers\",\"name\":\"Test L2=0 not scaled\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[11312.970703125,10293.421875,10058.052734375,9971.5419921875,10038.4462890625,9863.0322265625,9823.078125,9799.4130859375,9757.2119140625,9748.9453125,9684.9111328125,9794.0576171875,9616.1181640625,9673.0517578125,9483.3330078125,9530.837890625,9433.4638671875,9401.0419921875,9425.1943359375,9489.37109375,9523.296875,9283.630859375,9247.1474609375,9218.515625,9291.8193359375,9196.951171875,9355.28125,9208.5166015625,9216.8896484375,9133.7724609375,9140.5244140625,9208.1640625,9124.138671875,9207.26171875,9088.6572265625,9300.5322265625,9091.0146484375,9101.4208984375,9115.0703125,9309.296875,9076.13671875,9053.0224609375,9038.583984375,9080.337890625,9048.0517578125,9048.791015625,9038.1728515625,9076.0810546875,9016.0234375,9018.3486328125,9211.322265625,8990.599609375,9035.439453125,9048.1279296875,9060.705078125,9027.0244140625,9003.1064453125,9015.0546875,9010.1826171875,9091.9970703125,9060.02734375,8993.580078125,9058.6904296875,9004.51953125,9018.9130859375,8997.6416015625,8971.5888671875,8971.384765625,9061.310546875,9335.5556640625,8968.9990234375,8993.2685546875,9001.2119140625,8957.638671875,8957.7890625,8980.27734375,8947.1953125,9127.990234375,9011.85546875,8998.021484375,8952.791015625,8965.1123046875,9025.8466796875,9060.291015625,8952.15234375,9028.71875,8981.2890625,9023.9951171875,8999.81640625,8939.1171875,8956.326171875,8964.736328125,9165.7998046875,8985.03515625,8938.3994140625,8966.759765625,8993.2255859375,9036.5400390625,8911.0771484375,8938.5263671875],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"RMSE\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"train RMSE vs test RMSE\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a2cd6f39-d273-47ee-aaa0-732030972cc3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hist_train_rmse_reg0 = np.array(history_reg0.history[\"root_mean_squared_error\"])\n",
        "hist_dev_rmse_reg0 = np.array(history_reg0.history[\"val_root_mean_squared_error\"])\n",
        "hist_train_rmse_reg0_not_scaled = np.array(history_reg0_not_scaled.history[\"root_mean_squared_error\"])\n",
        "hist_dev_rmse_reg0_not_scaled = np.array(history_reg0_not_scaled.history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "# Create the array for the x axis, starting from 1\n",
        "x = np.arange(1, len(history_reg0.history[\"root_mean_squared_error\"])+1)\n",
        "\n",
        "# Create a line chart with two lines using Plotly Express\n",
        "fig = px.line(title='train RMSE vs dev RMSE')\n",
        "fig.add_scatter(x=x, y=hist_train_rmse_reg0, mode='lines+markers', name='Train L2=0', line=dict(color='red'))\n",
        "fig.add_scatter(x=x, y=hist_dev_rmse_reg0, mode='lines+markers', name='Dev L2=0', line=dict(color='blue'))\n",
        "fig.add_scatter(x=x, y=hist_train_rmse_reg0_not_scaled, mode='lines+markers', name='Train L2=0 not scaled', line=dict(color='gray'))\n",
        "fig.add_scatter(x=x, y=hist_dev_rmse_reg0_not_scaled, mode='lines+markers', name='Dev L2=0 not scaled', line=dict(color='black'))\n",
        "\n",
        "# Set chart title and axis labels\n",
        "fig.update_layout(\n",
        "    xaxis_title='Epochs',\n",
        "    yaxis_title='RMSE'\n",
        ")\n",
        "\n",
        "# Show the chart\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ILDSZFdvZEq7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "ILDSZFdvZEq7",
        "outputId": "4c4c1ad1-8722-4ab4-ca9f-accbec3b6f27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"0c7d9cf9-a5c0-473c-9894-3899d8e2d005\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0c7d9cf9-a5c0-473c-9894-3899d8e2d005\")) {                    Plotly.newPlot(                        \"0c7d9cf9-a5c0-473c-9894-3899d8e2d005\",                        [{\"hovertemplate\":\"<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"mode\":\"lines+markers\",\"name\":\"Train\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[33403.5078125,21632.048828125,13360.060546875,10699.1767578125,9304.1875,8992.205078125,8736.7626953125,8650.6513671875,8547.34765625,8525.6875,8489.2900390625,8496.322265625,8386.265625,8380.6357421875,8356.849609375,8351.6328125,8333.6533203125,8290.552734375,8309.9912109375,8265.78125,8279.40234375,8268.462890625,8233.7646484375,8268.5361328125,8210.7294921875,8235.197265625,8211.1962890625,8203.6865234375,8188.8447265625,8196.802734375,8166.0322265625,8172.05859375,8150.9404296875,8218.9677734375,8162.806640625,8122.6357421875,8134.716796875,8144.95947265625,8133.35693359375,8148.35498046875,8106.783203125,8163.01416015625,8134.51220703125,8114.3671875,8085.60205078125,8088.9814453125,8090.03857421875,8100.54296875,8120.33154296875,8091.24951171875,8079.1494140625,8086.04150390625,8080.986328125,8076.275390625,8065.20166015625,8083.06396484375,8046.59423828125,8062.75439453125,8058.18798828125,8061.0498046875,8026.54296875,8066.84716796875,8055.60302734375,8041.287109375,8035.75341796875,8064.9443359375,8046.57763671875,8029.3935546875,8022.1748046875,8041.7158203125,8058.5595703125,8033.0859375,8025.13037109375,8036.8232421875,8056.369140625,8065.58349609375,8189.21435546875,8010.10986328125,8024.19189453125,8015.7001953125,7994.94140625,8000.38916015625,8018.458984375,7978.45556640625,7998.90966796875,8029.66455078125,8022.80224609375,8003.0576171875,7980.6982421875,7994.384765625,7966.71923828125,7980.5849609375,7980.7353515625,8020.21875,8041.6708984375,8025.1181640625,8117.63818359375,7998.970703125,8003.19189453125,8021.0234375,8040.0390625,7990.21044921875,8086.96728515625,8004.99609375,8008.02783203125,8004.12646484375,7966.81591796875,7984.60302734375,7971.74267578125,8004.53662109375,7997.72705078125,8025.0791015625,7995.8837890625,7970.5185546875,7976.39404296875,7970.31005859375,7962.8310546875,8068.7060546875,8017.60595703125,7987.26416015625,7987.953125,7991.8310546875,7978.5693359375,8037.8779296875,8040.90576171875,8047.833984375,7976.23388671875,7955.412109375,7974.08251953125,7944.19140625,7964.2890625,7997.056640625,7962.7470703125,7992.02734375,8019.6279296875,7971.169921875,7961.26025390625,7983.5712890625,8012.2255859375,7955.3701171875,7999.19775390625,8181.576171875,8052.89892578125,7970.515625,8032.88134765625,7936.21435546875,7957.59912109375,7995.49853515625,7976.21728515625,7956.41845703125,7957.68115234375,8012.62939453125,7984.84033203125,7971.03955078125,7956.947265625,7932.3349609375,7935.640625,8000.4921875,7972.2177734375,8033.0107421875,7933.5810546875,7972.3544921875,7939.689453125,7952.14794921875,7992.3828125,7945.60498046875,7955.48046875,8026.68896484375,7948.77783203125,7922.9970703125,7899.9560546875,7885.83154296875,7849.18994140625,7810.7333984375,7751.3740234375,7722.91455078125,7668.1259765625,7606.9794921875,7605.87353515625,7554.6337890625,7512.501953125,7539.55712890625,7485.71337890625,7434.56103515625,7457.29443359375,7415.9013671875,7433.2548828125,7408.0673828125,7417.728515625,7459.373046875,7397.40234375,7380.70849609375,7384.19287109375,7371.9130859375,7368.8720703125,7368.49609375,7338.681640625,7357.9775390625,7395.3564453125,7319.537109375,7380.92822265625,7420.73291015625,7388.55419921875,7352.8466796875,7323.8125,7348.06103515625,7354.7890625,7342.0078125,7376.71484375,7367.61279296875,7327.5537109375,7324.4052734375,7302.3623046875,7294.857421875,7300.8544921875,7297.9384765625,7308.1650390625,7290.16064453125,7310.4814453125,7289.390625,7262.22314453125,7301.4326171875,7259.30322265625,7250.095703125,7220.896484375,7248.373046875,7257.380859375,7282.615234375,7287.9462890625,7304.09375,7278.8466796875,7316.65576171875,7320.3515625,7262.78369140625,7258.380859375,7246.8212890625,7326.21875,7303.7841796875,7294.12451171875,7258.0458984375,7230.5,7245.75732421875,7216.12158203125,7211.87841796875,7238.6328125,7262.10302734375,7256.666015625,7260.52294921875,7299.08837890625,7205.875,7235.67626953125,7302.8798828125,7304.1533203125,7187.32958984375,7220.85986328125,7234.470703125,7217.00927734375,7157.38623046875,7184.990234375,7206.19482421875,7200.94287109375,7167.0693359375,7179.55908203125,7191.2412109375,7160.19970703125,7170.5537109375,7173.4755859375,7176.447265625,7201.69140625,7269.54248046875,7244.79443359375,7188.31396484375,7190.95166015625,7197.94140625,7123.32568359375,7136.83251953125,7119.7568359375,7131.32275390625,7126.5693359375,7067.39794921875,7083.92529296875,7085.068359375,7073.49072265625,7088.9912109375,7129.33251953125,7147.19482421875,7097.06689453125,7096.7509765625,7098.54638671875,7077.416015625,7121.8837890625,7196.2412109375,7168.63818359375,7087.9267578125,7164.4853515625,7113.763671875,7138.2451171875,7082.4482421875,7074.97900390625,7122.8154296875,7064.1904296875,7065.333984375,7087.08837890625,7212.39501953125,7046.8203125,7105.47509765625,7100.943359375,7029.2333984375,7048.904296875,7044.88037109375,7031.7333984375,7029.306640625,7062.1728515625,7078.93505859375,7030.7548828125,7047.46728515625,7162.06591796875,7173.21630859375,7032.44677734375,7041.64892578125,7011.41748046875,6966.14794921875,7054.26513671875,6993.271484375,6975.49072265625,6935.87646484375,6983.28515625,6969.2734375,6917.89404296875,6896.02294921875,6909.63623046875,6917.66259765625,7001.5615234375,6980.99072265625,6985.16357421875,6888.3505859375,6898.4951171875,6959.4853515625,6897.97021484375,6886.189453125,6905.88671875,6834.1572265625,6832.56640625,6838.36279296875,6866.25048828125,6825.10791015625,6781.83544921875,6762.22509765625,6725.40673828125,6755.18212890625,6730.53466796875,6704.64013671875,6703.7529296875,6797.5537109375,6764.2646484375,6622.07568359375,6579.298828125,6608.58984375,6578.31884765625,6541.9716796875,6569.69775390625,6536.7158203125,6517.39892578125,6454.7626953125,6430.7158203125,6470.99853515625,6443.671875,6485.08349609375,6460.869140625,6409.60986328125,6500.17236328125,6570.4873046875,6411.38232421875,6387.69677734375,6323.1015625,6319.2041015625,6329.1455078125,6393.95654296875,6318.19482421875,6266.0244140625,6265.2861328125,6222.23681640625,6331.703125,6273.22314453125,6106.41064453125,6150.8935546875,6102.74169921875,6154.85009765625,6063.9296875,6050.173828125,6034.46875,6013.33203125,6044.63330078125,6063.8544921875,6110.25830078125,6099.6904296875,6053.04150390625,6000.810546875,5935.54296875,5965.267578125,5911.25732421875,5967.39794921875,5886.81103515625,5882.16064453125,5879.69140625,5831.83740234375,5770.7490234375,5737.62255859375,5789.78369140625,5769.0078125,5736.88623046875,5729.93896484375,5740.95166015625,5656.14111328125,5671.4453125,5697.482421875,5665.6298828125,5732.83349609375,5664.4150390625,5807.51806640625,5779.208984375,5695.68359375,5707.111328125,5595.89111328125,5566.7099609375,5535.78271484375,5588.259765625,5645.3994140625,5528.76611328125,5559.19775390625,5533.013671875,5550.87646484375,5457.60888671875,5532.13427734375,5482.42431640625,5403.11865234375,5430.5166015625,5406.63427734375,5412.248046875,5482.51123046875,5574.46875,5445.34033203125,5442.3916015625,5544.8935546875,5392.14404296875,5435.79052734375,5456.13134765625,5477.9248046875,5369.19091796875,5283.9423828125,5302.10302734375,5298.89453125,5296.8916015625,5404.70703125,5435.62255859375,5341.9111328125,5407.9072265625,5327.1044921875,5260.70654296875,5292.572265625,5370.8388671875,5308.98291015625,5275.8798828125,5255.1953125,5339.9619140625,5301.6044921875,5311.0126953125,5152.43994140625,5189.5927734375,5175.7197265625,5143.90087890625,5239.1396484375,5264.38720703125,5267.55078125,5293.8828125,5181.96630859375,5207.64892578125,5123.1259765625,5130.76416015625,5122.64794921875,5109.22412109375,5190.70654296875,5130.16455078125,5099.50537109375,5148.841796875,5145.2001953125,5084.17138671875,5111.64453125,5120.00537109375,5089.412109375,5164.326171875,5163.30517578125,5094.82275390625,5018.4306640625,5076.6328125,4999.23779296875,5000.6806640625,5039.44580078125,5108.29736328125,5021.25],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Test\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500],\"y\":[29557.52734375,14912.8544921875,10971.693359375,9243.55078125,8639.3994140625,8412.4677734375,8214.091796875,8167.49853515625,8100.75390625,8108.9501953125,8025.1181640625,8066.08544921875,7988.9931640625,8018.4462890625,8006.720703125,7980.712890625,7977.4228515625,7984.54833984375,7974.708984375,7974.51513671875,7943.82275390625,8006.8310546875,7975.43701171875,7973.166015625,8050.99658203125,7944.01513671875,8022.65234375,7963.3876953125,7939.35400390625,7981.5859375,7917.80419921875,7975.98388671875,8047.99755859375,7953.18359375,8008.16259765625,7952.06201171875,7981.97216796875,7998.87890625,8018.5927734375,7962.5693359375,8085.88671875,7992.943359375,8086.3310546875,7984.08056640625,7998.21728515625,7979.0087890625,7990.1328125,7971.314453125,8041.92919921875,7953.9189453125,7937.44677734375,8044.2666015625,7996.5068359375,7955.576171875,8070.5146484375,7963.134765625,7953.8828125,7935.8994140625,7972.59423828125,7946.25439453125,7959.8994140625,7893.38134765625,7939.06201171875,7977.3837890625,8021.4384765625,7938.42919921875,7937.83251953125,7905.234375,7963.87646484375,7940.16748046875,7926.8251953125,7949.5283203125,7923.23291015625,7967.66748046875,7924.5166015625,7970.328125,7968.28125,8017.61181640625,7899.2060546875,7938.5517578125,7932.53125,7952.10107421875,7911.5693359375,7940.1923828125,7902.36181640625,7989.4716796875,7950.12646484375,7918.92724609375,7942.5185546875,7906.6669921875,7973.2880859375,7946.64501953125,7941.59521484375,7896.7431640625,7979.421875,8158.55322265625,7978.62939453125,7970.767578125,7937.07177734375,7930.35693359375,7935.5673828125,7963.1689453125,7952.64501953125,7908.58837890625,7970.44287109375,7908.8505859375,7935.4404296875,7910.623046875,8005.48583984375,8038.7626953125,7971.75830078125,7965.853515625,7937.87451171875,7920.20263671875,7962.50732421875,7928.69287109375,8059.0029296875,8103.25048828125,7939.83642578125,7983.46240234375,7916.326171875,7923.02978515625,8016.06494140625,8039.31494140625,8068.060546875,8079.673828125,7991.38671875,7985.9443359375,7950.94140625,7920.90625,8043.13525390625,8101.65576171875,8062.6728515625,8233.1875,7929.4990234375,7980.06884765625,7947.75390625,8055.86328125,8038.57861328125,7901.63671875,7996.4365234375,8487.4580078125,7938.046875,8130.98193359375,7925.921875,7957.6494140625,8090.70458984375,7939.60302734375,7961.474609375,7974.32275390625,7931.65771484375,7984.74072265625,7912.8466796875,8026.18359375,7978.46728515625,7971.0029296875,8110.53662109375,8102.94189453125,7950.33544921875,7950.9951171875,7963.224609375,8013.7744140625,8074.03076171875,8057.08154296875,7952.0087890625,7969.49609375,8032.01806640625,7984.00439453125,7930.50927734375,7952.43115234375,7924.51318359375,7967.7265625,7880.7431640625,7862.56884765625,7900.86083984375,7855.27197265625,7745.43505859375,7743.80859375,7671.95751953125,7663.0654296875,7702.8203125,7675.75439453125,7649.81982421875,7628.84912109375,7687.68212890625,7735.17822265625,7615.54541015625,7637.63037109375,7828.11083984375,7610.78369140625,7583.1884765625,7680.0908203125,7630.4111328125,7635.98486328125,7762.7939453125,7606.8515625,7614.46337890625,7598.60400390625,7608.40869140625,7643.37890625,7737.0166015625,7676.21533203125,7685.54150390625,7568.85107421875,7623.06982421875,7684.1513671875,7595.13232421875,7674.57763671875,7650.01708984375,7602.93994140625,7579.8173828125,7682.00732421875,7581.3994140625,7570.10888671875,7618.37548828125,7554.53466796875,7593.1416015625,7681.64501953125,7509.09814453125,7625.30078125,7555.357421875,7601.6513671875,7554.0537109375,7576.25439453125,7566.337890625,7621.3818359375,7594.35498046875,7678.12841796875,7610.9130859375,7704.4580078125,7585.416015625,7782.271484375,7630.51171875,7548.9091796875,7596.71142578125,7532.6455078125,7685.21533203125,7569.31396484375,7574.0234375,7539.75732421875,7576.39404296875,7613.24365234375,7551.37255859375,7603.94189453125,7596.34912109375,7577.97705078125,7692.060546875,7601.64794921875,7667.0078125,7550.046875,7636.30078125,7681.34716796875,7573.29052734375,7576.0048828125,7636.9130859375,7589.49072265625,7585.9755859375,7658.57861328125,7631.98779296875,7643.99853515625,7644.1171875,7682.15380859375,7608.7080078125,7608.72998046875,7625.17138671875,7619.29150390625,7608.67138671875,7705.50341796875,7710.7216796875,7768.68310546875,7589.18603515625,7664.904296875,7655.58837890625,7662.31591796875,7729.0439453125,7614.763671875,7671.33203125,7676.05908203125,7605.34521484375,7628.91845703125,7578.751953125,7701.146484375,7605.5712890625,7660.62646484375,7633.484375,7610.048828125,7651.03955078125,7655.13720703125,7620.59765625,7660.93798828125,7784.53271484375,7778.86474609375,7647.8046875,7775.74609375,7617.7734375,7628.638671875,7707.2041015625,7699.6669921875,7753.025390625,7598.74169921875,7760.28955078125,7706.01171875,7743.72265625,7667.873046875,7749.07470703125,7743.61328125,7787.728515625,7714.15478515625,7591.5546875,7680.28857421875,7658.572265625,7694.08837890625,7598.1943359375,7663.0830078125,7688.8720703125,7792.18017578125,7927.50732421875,7707.22607421875,7648.96240234375,7678.02392578125,7614.072265625,7621.71826171875,7648.34716796875,7635.30712890625,7651.55322265625,7760.24072265625,7665.11572265625,7674.2275390625,7641.69091796875,7710.8916015625,7665.3037109375,7734.1083984375,7663.6796875,7660.78955078125,7617.94189453125,7680.90869140625,7703.1259765625,7709.86865234375,7650.787109375,7780.9619140625,7642.70654296875,7699.54248046875,7657.14453125,7713.8818359375,7684.12158203125,7659.9033203125,7591.31494140625,7676.6982421875,7664.43505859375,7760.255859375,7673.62109375,7670.38525390625,7592.50634765625,7669.25,7581.8369140625,7566.48388671875,7620.59228515625,7563.6259765625,7585.05419921875,7574.453125,7618.203125,7616.62841796875,7600.38720703125,7527.68798828125,7649.3818359375,7554.57421875,7545.79150390625,7536.3935546875,7577.5908203125,7706.04833984375,8004.19384765625,7612.0791015625,7478.27490234375,7616.8525390625,7675.86181640625,7709.62744140625,7710.1767578125,7759.0849609375,7542.6953125,7694.2666015625,7557.14794921875,7706.96484375,7751.54248046875,7553.58349609375,7745.78955078125,7617.25439453125,7681.29541015625,7658.22119140625,7636.6474609375,7621.10546875,7678.2158203125,7644.7939453125,7725.8984375,7775.966796875,7763.388671875,7751.36572265625,8012.6884765625,7683.71044921875,7620.9638671875,7672.9931640625,7704.47509765625,7819.4951171875,7754.22509765625,7694.7353515625,7709.9150390625,7833.92724609375,7844.80517578125,7830.46044921875,7922.171875,7920.91943359375,7853.7998046875,7883.70556640625,7809.076171875,7836.76171875,7789.2314453125,7995.3369140625,7909.81884765625,7953.4208984375,8179.4765625,8175.51806640625,7793.814453125,7912.236328125,7931.513671875,7800.7265625,7862.14501953125,7841.15625,7939.23583984375,7794.3916015625,7970.20654296875,7797.81201171875,8141.74267578125,7934.43359375,7977.99365234375,8013.25341796875,7948.61962890625,7985.73974609375,7973.57421875,7982.48291015625,8079.6689453125,8262.7490234375,8057.4560546875,8133.91796875,7924.826171875,7978.7744140625,8068.93701171875,7969.11572265625,7940.08984375,7986.4013671875,7936.60400390625,7956.11669921875,7948.75830078125,7903.5546875,7961.19580078125,8237.0390625,8232.8876953125,8109.77783203125,7951.99365234375,7932.99658203125,8064.43212890625,7960.791015625,7957.28271484375,8025.9130859375,8123.34912109375,8187.5283203125,7981.04736328125,8075.83642578125,8049.455078125,8006.86181640625,8008.7958984375,8052.91650390625,7957.6962890625,8148.15234375,7983.0078125,7983.84765625,8254.2373046875,8078.39111328125,8194.9970703125,8038.607421875,8094.427734375,8000.20166015625,8355.8173828125,8035.24169921875,7989.447265625,8278.0625,8025.78564453125,7937.80029296875,8105.98876953125,8306.388671875,8182.6484375,8088.77099609375,8294.6416015625,8194.2861328125,8063.3515625,8125.25634765625,8206.921875,8292.720703125,8216.4912109375,8129.61328125,8357.2646484375,8138.34375],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"RMSE\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"train RMSE vs test RMSE\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0c7d9cf9-a5c0-473c-9894-3899d8e2d005');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hist_train_rmse = np.array(history.history[\"root_mean_squared_error\"])\n",
        "hist_dev_rmse = np.array(history.history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "# Create the array for the x axis, starting from 1\n",
        "x = np.arange(1, len(history.history[\"root_mean_squared_error\"])+1)\n",
        "\n",
        "# Create a line chart with two lines using Plotly Express\n",
        "fig = px.line(title='train RMSE vs dev RMSE')\n",
        "fig.add_scatter(x=x, y=hist_train_rmse, mode='lines+markers', name='Train', line=dict(color='red'))\n",
        "fig.add_scatter(x=x, y=hist_dev_rmse, mode='lines+markers', name='Dev', line=dict(color='blue'))\n",
        "\n",
        "# Set chart title and axis labels\n",
        "fig.update_layout(\n",
        "    xaxis_title='Epochs',\n",
        "    yaxis_title='RMSE'\n",
        ")\n",
        "\n",
        "# Show the chart\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qg2TMtxJUzVm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg2TMtxJUzVm",
        "outputId": "27112e65-201e-42f1-927e-bf8c20614373"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "92/92 [==============================] - 1s 10ms/step\n",
            "Trai RMSE: 2623.097985\n",
            "23/23 [==============================] - 0s 8ms/step\n",
            "Test RMSE: 8387.871121\n"
          ]
        }
      ],
      "source": [
        "preds_train = model.predict(X_train_scaled)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, preds_train))\n",
        "print(\"Trai RMSE: %f\" % (rmse_train))\n",
        "\n",
        "preds_dev = model.predict(x_dev_scaled)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "rmse_dev = np.sqrt(mean_squared_error(y_dev, preds_dev))\n",
        "print(\"Dev RMSE: %f\" % (rmse_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35YvxR1B1tcY",
      "metadata": {
        "id": "35YvxR1B1tcY"
      },
      "source": [
        "<a name=\"5.4.\"></a>\n",
        "## 5.4. Recurrent Neural Network\n",
        "[Content](#content)\n",
        "\n",
        "Lastly, we train an RNN to compare to the previous two models. A RNN can take in multiple timesteps, to make a prediction (Many-to-One). Specifically, we will feed in 4 timesteps at a time (current day and the 3 previous days) and output the prediction of the current day.\n",
        "\n",
        "Out input shape is therefore (none, 4, 21), where none represents a variable amount of training days (in our case the length of X_train)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "J7cPlQdTzEmQ",
      "metadata": {
        "id": "J7cPlQdTzEmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fadacc9-65e1-42ba-cccb-192826b04210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Load the data into a pandas dataframe\n",
        "data = df_transformed_date\n",
        "\n",
        "# Define the features and target\n",
        "# Higly correlated features have been removed (tavg, tmax, wpgt)\n",
        "features = ['year', 'month', 'day', 'weekday', 'tmax', 'prcp',\n",
        "            'snow', 'wspd', 'pres', 'tsun',\n",
        "            'holiday_1_weihnachtsfeiertag', 'holiday_2_weihnachtsfeiertag',\n",
        "            'holiday_christi_himmelfahrt', 'holiday_karfreitag', 'holiday_neujahr',\n",
        "            'holiday_ostermontag', 'holiday_pfingstmontag', 'holiday_reformationstag',\n",
        "            'holiday_tag_der_arbeit', 'holiday_tag_der_deutschen_einheit',\n",
        "            'vacation']\n",
        "\n",
        "target = 'total'\n",
        "\n",
        "# Split the data into training and dev sets\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(data[features], data[target],\n",
        "                                                    test_size=0.2, shuffle=False, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137fc8a6-b422-47ac-999e-2103b4c80b7c",
        "id": "lI1NinnLJ1tc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Standardize and fit to the training set only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the same standardization to the dev set\n",
        "X_dev_scaled = scaler.transform(X_dev)\n",
        "\n",
        "#X_train_scaled = X_train\n",
        "#X_dev_scaled = X_dev"
      ],
      "id": "lI1NinnLJ1tc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of timesteps\n",
        "timesteps = 4\n",
        "\n",
        "# Step 1: Create sequences of length 4\n",
        "X_train_scaled_3d, X_dev_scaled_3d = [], []\n",
        "y_train_3d, y_dev_3d = [], []\n",
        "\n",
        "for i in range(len(X_train_scaled) - timesteps + 1):\n",
        "    X_train_scaled_3d.append(X_train_scaled[i : i + timesteps])\n",
        "    y_train_3d.append(y_train[i : i + timesteps])\n",
        "\n",
        "X_train_scaled_3d = np.array(X_train_scaled_3d)\n",
        "#y_train = y_train [timesteps-1:]\n",
        "y_train_3d = np.array(y_train_3d)\n",
        "\n",
        "for i in range(len(X_dev_scaled) - timesteps + 1):\n",
        "    X_dev_scaled_3d.append(X_dev_scaled[i : i + timesteps])\n",
        "    y_dev_3d.append(y_dev[i : i + timesteps])\n",
        "\n",
        "X_dev_scaled_3d = np.array(X_dev_scaled_3d)\n",
        "#y_dev = y_dev [timesteps-1:]\n",
        "y_dev_3d = np.array(y_dev_3d)\n",
        "\n",
        "print(X_train_scaled_3d.shape)\n",
        "#print(y_train.shape)\n",
        "print(y_train_3d.shape)\n",
        "\n",
        "print(X_dev_scaled_3d.shape)\n",
        "#print(y_dev.shape)\n",
        "print(y_dev_3d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG3uW6OfVD4n",
        "outputId": "1396b197-b5a6-4d13-fa96-658c2e643a6e"
      },
      "id": "jG3uW6OfVD4n",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2918, 4, 21)\n",
            "(2918, 4)\n",
            "(728, 4, 21)\n",
            "(728, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled_3d[0])\n",
        "print(y_train_3d[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tfeCnmzdXW4",
        "outputId": "154ced9c-9d1c-4325-bc93-ea19b015e0f1"
      },
      "id": "2tfeCnmzdXW4",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.52769960e+00 -1.60132494e+00 -1.67378744e+00 -9.99614949e-01\n",
            "  -7.12590851e-01  1.45245197e+00 -1.31126690e-01  6.70967153e-01\n",
            "  -1.40081458e+00 -1.06115073e+00 -5.24052445e-02 -5.24052445e-02\n",
            "  -5.24052445e-02 -5.24052445e-02  1.90820596e+01 -5.24052445e-02\n",
            "  -5.24052445e-02 -3.70306880e-02 -5.24052445e-02 -5.24052445e-02\n",
            "   1.73086569e+00]\n",
            " [-1.52769960e+00 -1.60132494e+00 -1.56011310e+00 -4.99550680e-01\n",
            "  -9.64166965e-01  3.83403275e-02 -1.31126690e-01  7.95565131e-01\n",
            "   2.66395438e-01 -9.47283932e-01 -5.24052445e-02 -5.24052445e-02\n",
            "  -5.24052445e-02 -5.24052445e-02 -5.24052445e-02 -5.24052445e-02\n",
            "  -5.24052445e-02 -3.70306880e-02 -5.24052445e-02 -5.24052445e-02\n",
            "   1.73086569e+00]\n",
            " [-1.52769960e+00 -1.60132494e+00 -1.44643877e+00  5.13588773e-04\n",
            "  -5.23908765e-01 -2.11208786e-01 -1.31126690e-01  1.35625604e+00\n",
            "   1.00973749e+00 -1.06115073e+00 -5.24052445e-02 -5.24052445e-02\n",
            "  -5.24052445e-02 -5.24052445e-02 -5.24052445e-02 -5.24052445e-02\n",
            "  -5.24052445e-02 -3.70306880e-02 -5.24052445e-02 -5.24052445e-02\n",
            "   1.73086569e+00]\n",
            " [-1.52769960e+00 -1.60132494e+00 -1.33276444e+00  5.00577857e-01\n",
            "  -6.37118017e-01 -4.60757900e-01 -1.31126690e-01  1.57430250e+00\n",
            "   1.54069609e+00 -1.06115073e+00 -5.24052445e-02 -5.24052445e-02\n",
            "  -5.24052445e-02 -5.24052445e-02 -5.24052445e-02 -5.24052445e-02\n",
            "  -5.24052445e-02 -3.70306880e-02 -5.24052445e-02 -5.24052445e-02\n",
            "   1.73086569e+00]]\n",
            "[ 5795. 19494. 24851. 13475.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "sOTf5esj1181",
      "metadata": {
        "id": "sOTf5esj1181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d3ba89-e30d-481b-de5b-3fba03fdc893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_63 (InputLayer)       [(None, 4, 21)]           0         \n",
            "                                                                 \n",
            " lstm_66 (LSTM)              (None, 4, 32)             6912      \n",
            "                                                                 \n",
            " custom_output (Dense)       (None, 4, 1)              33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,945\n",
            "Trainable params: 6,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Assuming X_train, x_dev, y_train, y_dev are already defined and contain the appropriate data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_samples = len(X_train_scaled_3d)\n",
        "num_sequence = 4\n",
        "# Build the LSTM model\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=256, input_shape=(1, X_train.shape[1]), activation='relu'))\n",
        "# Add a dense output layer with a single unit (for regression) and no activation function\n",
        "model.add(Dense(units=1))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\"\"\"\n",
        "# Build the LSTM model\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(num_sequence, 21)))\n",
        "model.add(LSTM(units=32, activation='relu', dropout=0.1))\n",
        "model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "model = Sequential([\n",
        "    #Input(shape=(num_sequence, 21)),\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    LSTM(32, activation='relu', dropout=0.1, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    Dense(units=1, activation='linear')\n",
        "])\"\"\"\n",
        "\n",
        "inputs = Input(shape=(num_sequence, 21))\n",
        "x = LSTM(32, activation='relu', dropout=0.1, return_sequences=True)(inputs)\n",
        "outputs = Dense(1, activation='linear', name=\"custom_output\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.1)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_train_scaled_3d = np.reshape(X_train_scaled, (num_samples, num_sequence, X_train_scaled.shape[1]))  # Fix variable name\n",
        "\n",
        "#num_samples = X_dev_scaled.shape[0]\n",
        "#X_dev_scaled_3d = np.reshape(X_dev_scaled, (num_samples, num_sequence, X_dev_scaled.shape[1]))\n",
        "\n",
        "# Train the model\n",
        "#X_train_scaled_3d = np.expand_dims(X_train_scaled_3d[0], axis=0)\n",
        "#y_train_3d = np.expand_dims(y_train_3d[0], axis=0)\n",
        "#print(X_train_scaled_3d)\n",
        "#print(y_train_3d)\n",
        "#history = model.fit(X_train_scaled_3d, y_train_3d, epochs=50, batch_size=32, verbose=2, validation_data=(X_dev_scaled_3d, y_dev_3d))\n",
        "\n",
        "#validation_data=(X_dev_scaled, y_dev)\n",
        "\n",
        "#output = model.predict(X_train_scaled_3d)\n",
        "\n",
        "#intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(\"custom_output\").output)\n",
        "#intermediate_model.predict(X_train_scaled_3d)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "9ukpsLCDTJsP",
        "outputId": "3ea3ca3e-4ac6-496a-863f-0c7af0aba913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9ukpsLCDTJsP",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 3530.1956 ],\n",
              "        [21039.594  ],\n",
              "        [18744.39   ],\n",
              "        [18744.39   ]],\n",
              "\n",
              "       [[25455.633  ],\n",
              "        [30297.64   ],\n",
              "        [30297.64   ],\n",
              "        [30297.64   ]],\n",
              "\n",
              "       [[26324.275  ],\n",
              "        [31157.262  ],\n",
              "        [31157.262  ],\n",
              "        [31157.262  ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[   66.67899],\n",
              "        [ 3320.174  ],\n",
              "        [10063.755  ],\n",
              "        [10063.755  ]],\n",
              "\n",
              "       [[ 3320.174  ],\n",
              "        [10063.755  ],\n",
              "        [10063.755  ],\n",
              "        [10063.755  ]],\n",
              "\n",
              "       [[13288.419  ],\n",
              "        [20993.754  ],\n",
              "        [20993.754  ],\n",
              "        [20993.754  ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "UhgpRcfljzy8",
        "outputId": "881a7d47-0787-4b58-bf20-c32187e74d87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UhgpRcfljzy8",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2918, 4, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}