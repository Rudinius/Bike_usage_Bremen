{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook"
      ],
      "metadata": {
        "id": "CBLnLwZIZpWJ"
      },
      "id": "CBLnLwZIZpWJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Model learning step, the prepared dataset from [2_EDA](https://github.com/Rudinius/Bike_usage_Bremen/blob/57e21c8dd687aadc1498f82241cf662840c8b871/2_EDA.ipynb) is loaded. Then different machine learning algorithms are trained and compared to each other."
      ],
      "metadata": {
        "id": "lZXvJFJqZuRE"
      },
      "id": "lZXvJFJqZuRE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c910711"
      },
      "source": [
        "<a name=\"content\"></a>\n",
        "# Content \n",
        "\n",
        "* [1. Import libraries and mount drive](#1)\n",
        "* [2. Import datasets](#2)\n",
        "* [3. Transform columns](#3)\n",
        "* [4. Establish baseline benchmark](#4)\n",
        "* [5. Training machine learning algorithms](#5)\n",
        "    * [5.2. XGBoost](#5.2.)\n",
        "    * [5.3. Multilayer perceptron](#5.3.)\n",
        "    * [5.4. Recurrent Neural Network](#5.4.)"
      ],
      "id": "0c910711"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85f76996"
      },
      "source": [
        "<a name=\"1\"></a>\n",
        "# 1.&nbsp;Import libraries\n",
        "[Content](#content)"
      ],
      "id": "85f76996"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "3731ea33"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import random\n",
        "#from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, TimeSeriesSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import xgboost as xgb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError"
      ],
      "id": "3731ea33"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2516jhMiVxrJ"
      },
      "source": [
        "<a name=\"2\"></a>\n",
        "#2.&nbsp;Import dataset\n",
        "[Content](#content)"
      ],
      "id": "2516jhMiVxrJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will import the processed dataset from [2_EDA](../Bike_usage_Bremen/2_EDA.ipynb)."
      ],
      "metadata": {
        "id": "IF9lS_3ok1tO"
      },
      "id": "IF9lS_3ok1tO"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xu3OXfHqVxfa"
      },
      "outputs": [],
      "source": [
        "# Set base url\n",
        "url = \"https://raw.githubusercontent.com/Rudinius/Bike_usage_Bremen/main/data/\""
      ],
      "id": "Xu3OXfHqVxfa"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "2etHV6ODVsUV",
        "outputId": "a7145027-0f07-42c0-a124-2514a2bc8ba1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Weekday  GrafMoltkeStrEast  GrafMoltkeStrWest  HastedterBrStr  \\\n",
              "date                                                                        \n",
              "2013-01-01        1              261.0              290.0           381.0   \n",
              "2013-01-02        2              750.0              876.0          1109.0   \n",
              "2013-01-03        3              931.0             1015.0          1603.0   \n",
              "2013-01-04        4              500.0              587.0          1284.0   \n",
              "2013-01-05        5             1013.0             1011.0          1284.0   \n",
              "\n",
              "            LangemarckStrEast  LangemarckStrWest  Osterdeich  \\\n",
              "date                                                           \n",
              "2013-01-01              312.0              308.0       870.0   \n",
              "2013-01-02             1258.0             1120.0      2169.0   \n",
              "2013-01-03             1556.0             1480.0      2295.0   \n",
              "2013-01-04              703.0              626.0      1640.0   \n",
              "2013-01-05             1856.0             1621.0      4128.0   \n",
              "\n",
              "            RadwegKleineWeser  SchwachhauserRing  WachmannStrAusSouth  ...  \\\n",
              "date                                                                   ...   \n",
              "2013-01-01              410.0              391.0                514.0  ...   \n",
              "2013-01-02             1762.0              829.0               1786.0  ...   \n",
              "2013-01-03             2287.0             1196.0               2412.0  ...   \n",
              "2013-01-04             1548.0             1418.0                964.0  ...   \n",
              "2013-01-05             4256.0             3075.0               2065.0  ...   \n",
              "\n",
              "            tmax  prcp  snow   wdir  wspd  wpgt    pres  tsun  Holiday  \\\n",
              "date                                                                     \n",
              "2013-01-01   9.1   6.9   0.0  233.0  19.4  50.4  1001.8     0  Neujahr   \n",
              "2013-01-02   7.1   1.8   0.0  246.0  20.2  40.0  1017.5    30      NaN   \n",
              "2013-01-03  10.6   0.9   0.0  257.0  23.8  45.7  1024.5     0      NaN   \n",
              "2013-01-04   9.7   0.0   0.0  276.0  25.2  48.2  1029.5     0      NaN   \n",
              "2013-01-05   8.6   0.1   0.0  293.0  20.2  41.0  1029.9     0      NaN   \n",
              "\n",
              "                    Vacation  \n",
              "date                          \n",
              "2013-01-01  Weihnachtsferien  \n",
              "2013-01-02  Weihnachtsferien  \n",
              "2013-01-03  Weihnachtsferien  \n",
              "2013-01-04  Weihnachtsferien  \n",
              "2013-01-05  Weihnachtsferien  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d5fa228-7a3e-4cee-8f63-5a0b9af5054f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weekday</th>\n",
              "      <th>GrafMoltkeStrEast</th>\n",
              "      <th>GrafMoltkeStrWest</th>\n",
              "      <th>HastedterBrStr</th>\n",
              "      <th>LangemarckStrEast</th>\n",
              "      <th>LangemarckStrWest</th>\n",
              "      <th>Osterdeich</th>\n",
              "      <th>RadwegKleineWeser</th>\n",
              "      <th>SchwachhauserRing</th>\n",
              "      <th>WachmannStrAusSouth</th>\n",
              "      <th>...</th>\n",
              "      <th>tmax</th>\n",
              "      <th>prcp</th>\n",
              "      <th>snow</th>\n",
              "      <th>wdir</th>\n",
              "      <th>wspd</th>\n",
              "      <th>wpgt</th>\n",
              "      <th>pres</th>\n",
              "      <th>tsun</th>\n",
              "      <th>Holiday</th>\n",
              "      <th>Vacation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>1</td>\n",
              "      <td>261.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>870.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.1</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>50.4</td>\n",
              "      <td>1001.8</td>\n",
              "      <td>0</td>\n",
              "      <td>Neujahr</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>2</td>\n",
              "      <td>750.0</td>\n",
              "      <td>876.0</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>2169.0</td>\n",
              "      <td>1762.0</td>\n",
              "      <td>829.0</td>\n",
              "      <td>1786.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1017.5</td>\n",
              "      <td>30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>3</td>\n",
              "      <td>931.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>1603.0</td>\n",
              "      <td>1556.0</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>2287.0</td>\n",
              "      <td>1196.0</td>\n",
              "      <td>2412.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>257.0</td>\n",
              "      <td>23.8</td>\n",
              "      <td>45.7</td>\n",
              "      <td>1024.5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>4</td>\n",
              "      <td>500.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>703.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>1640.0</td>\n",
              "      <td>1548.0</td>\n",
              "      <td>1418.0</td>\n",
              "      <td>964.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>25.2</td>\n",
              "      <td>48.2</td>\n",
              "      <td>1029.5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>5</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>1856.0</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>4128.0</td>\n",
              "      <td>4256.0</td>\n",
              "      <td>3075.0</td>\n",
              "      <td>2065.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1029.9</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Weihnachtsferien</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d5fa228-7a3e-4cee-8f63-5a0b9af5054f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d5fa228-7a3e-4cee-8f63-5a0b9af5054f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d5fa228-7a3e-4cee-8f63-5a0b9af5054f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Import dataset\n",
        "\n",
        "# We will also parse the date column as datetime64 and set it to the index column\n",
        "df = pd.read_csv(url + \"03_training_data/\" + \"2023-04-02_df_full.csv\", \n",
        "                         parse_dates=[0], index_col=[0])\n",
        "\n",
        "# Check the correct loading of dataset\n",
        "df.head()"
      ],
      "id": "2etHV6ODVsUV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"3\"></a>\n",
        "# 3. Transform columns\n",
        "[Content](#content)"
      ],
      "metadata": {
        "id": "LIog4gAun3Gh"
      },
      "id": "LIog4gAun3Gh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to transform the columns `Holiday` and `Vacation` using `One-Hot-Encoding` to change the categorical columns to numerical columns. Then we need to drop the original columns."
      ],
      "metadata": {
        "id": "1KinSwc3oDMj"
      },
      "id": "1KinSwc3oDMj"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zZnhFuQN-QT2"
      },
      "outputs": [],
      "source": [
        "# Use One Hot Encoder\n",
        "OH_encoder = OneHotEncoder()\n",
        "transformed_array = OH_encoder.fit_transform(df.loc[:,\"Holiday\": \"Vacation\"]).toarray()\n",
        "df_holiday_vacation_transformed = pd.DataFrame(transformed_array, \n",
        "                              columns=OH_encoder.get_feature_names_out(), \n",
        "                              index = df.index)              \n",
        "# Drop the columns with Holiday_nan and Vacation_nan as those hold no additional value          \n",
        "df_holiday_vacation_transformed = df_holiday_vacation_transformed.drop([\"Holiday_nan\", \"Vacation_nan\"], axis=1)\n",
        "\n",
        "# Drop the old categorical columns Holiday and Vacation\n",
        "df_transformed = df.drop([\"Holiday\", \"Vacation\"], axis=1)\n",
        "\n",
        "# Add the new columns from OHE\n",
        "df_transformed = pd.concat([df_transformed, df_holiday_vacation_transformed], axis=1)"
      ],
      "id": "zZnhFuQN-QT2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will add the year, month and day as seperate columns to give the algorithm the chance to pick up more granular and seasonal patterns."
      ],
      "metadata": {
        "id": "Ex0TAxa6xPK6"
      },
      "id": "Ex0TAxa6xPK6"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZFMh5fPazIDm"
      },
      "outputs": [],
      "source": [
        "df_date = pd.DataFrame(data = {\n",
        "    \"Year\": df.index.year,\n",
        "    \"Month\": df.index.month,\n",
        "    \"Day\": df.index.day\n",
        "}, index=pd.to_datetime(df.index.values))\n",
        "    \n",
        "df_transformed_date = pd.concat([df_date, df_transformed], axis=1)\n",
        "\n",
        "# Check dataframe\n",
        "#df_transformed_date.head()"
      ],
      "id": "ZFMh5fPazIDm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, after all those transformations, we have out final dataset, to train our machine learning algorithms on."
      ],
      "metadata": {
        "id": "cYhxv0nmxmEp"
      },
      "id": "cYhxv0nmxmEp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBM3I6LFOHL9"
      },
      "source": [
        "<a name=\"4\"></a>\n",
        "# 4. Establish baseline benchmark\n",
        "[Content](#content)\n"
      ],
      "id": "gBM3I6LFOHL9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our current task of creating model to predict the amount of cyclers for a given day, we do not have any baseline accuracy to predict the value that we could use, to measure our model against. \n",
        "For this reason, we will create a naive baseline model. For this, we will simply predict the amount of a day based on the value of previous day."
      ],
      "metadata": {
        "id": "VgkVXhdAx6zB"
      },
      "id": "VgkVXhdAx6zB"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mu5aaMpO42j",
        "outputId": "7ad2ac0d-10fa-48b9-9d69-887e23a24543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 9083.225418\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model's performance using RMSE\n",
        "\n",
        "# Select the `Total` column as our y_test and preds arrays\n",
        "y_test = preds = df.loc[:,\"Total\"]\n",
        "\n",
        "rmse = 0\n",
        "length = y_test.shape[0]\n",
        "\n",
        "# Loop from 0 to second last entry, as we can only use seconds last entry to\n",
        "# predict the last entry of series\n",
        "for i in range(length-1):\n",
        "    # The mean_sqared_error function expects an array as input, therfore we \n",
        "    # concatenate the range from current value to current value + 1 (excluding)\n",
        "    rmse += np.sqrt(mean_squared_error(y_test[i+1:i+2], preds[i:i+1]))\n",
        "\n",
        "# Divide rmse value by number of pairs\n",
        "rmse = rmse / (length-1)\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "id": "6mu5aaMpO42j"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6O5OFAwW9Pm"
      },
      "source": [
        "If we were naivly predicting the current value with the last value, we get an error over the entire dataset of approximately $9,111$. \n",
        "\n",
        "This is our naive benchmark to compare our model against. "
      ],
      "id": "f6O5OFAwW9Pm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HqwjOgkxauH"
      },
      "source": [
        "<a name=\"5\"></a>\n",
        "# 5. Training machine learning algorithms\n",
        "[Content](#content)"
      ],
      "id": "5HqwjOgkxauH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5.2.\"></a>\n",
        "## 5.2. XGBoost\n",
        "[Content](#content)"
      ],
      "metadata": {
        "id": "mO2Xt87cykEf"
      },
      "id": "mO2Xt87cykEf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifically for XGBoost algorithm, we will add the data points of the previous time steps as features to feature vector. For RNNs, this will probably not be necessary, as RNNs have built-in memory units that allow them to store information from previous steps.\n",
        "\n",
        "In this case, we will only add the last 3 values, as the observed improvement of accuracy (RMSE score) is drastically decressing with each further time step added after 3 steps.\n",
        "\n",
        "Improvements:\n",
        "* 1 day 6291 2,8%\n",
        "* 2 day 6157 2,1%\n",
        "* 3 day 6120 0,6%"
      ],
      "metadata": {
        "id": "ZgSdeq3fOxaQ"
      },
      "id": "ZgSdeq3fOxaQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty new dataframe\n",
        "df_lagged_days = pd.DataFrame({})\n",
        "\n",
        "# Select the number of lagged days\n",
        "go_back_x_days = 3\n",
        "\n",
        "for i in range(go_back_x_days):\n",
        "    # Shift the values in \"Total\" by i and assign to new column prev_Total_i+1\n",
        "    df_lagged_days[f'prev_Total_{i+1}'] = df_transformed_date['Total'].shift(i+1)\n",
        "\n",
        "# Concat new dataframe with old dataframe\n",
        "df_transformed_date_lagged = pd.concat([df_transformed_date, df_lagged_days], axis=1)\n",
        "\n",
        "# Check output\n",
        "#df_transformed_date_lagged.loc[:,[\"prev_Total_1\", \"prev_Total_2\", \"prev_Total_3\",\"Total\"]]"
      ],
      "metadata": {
        "id": "MwRs_MUJdcTj"
      },
      "id": "MwRs_MUJdcTj",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into a pandas dataframe\n",
        "data = df_transformed_date_lagged\n",
        "\n",
        "# Define the features and target\n",
        "# Higly correlated features have been removed (tavg, tmax, wpgt)\n",
        "\n",
        "features = ['Year', 'Month', 'Day', 'Weekday',\n",
        "       'tmax', 'prcp', 'snow', 'wspd', 'pres', 'tsun',\n",
        "       'Holiday_1. Weihnachtsfeiertag', 'Holiday_2. Weihnachtsfeiertag',\n",
        "       'Holiday_Christi Himmelfahrt', 'Holiday_Karfreitag', 'Holiday_Neujahr',\n",
        "       'Holiday_Ostermontag', 'Holiday_Pfingstmontag',\n",
        "       'Holiday_Reformationstag', 'Holiday_Tag der Arbeit',\n",
        "       'Holiday_Tag der Deutschen Einheit', 'Vacation_Herbstferien',\n",
        "       'Vacation_Osterferien', 'Vacation_Pfingstferien',\n",
        "       'Vacation_Sommerferien', 'Vacation_Weihnachtsferien',\n",
        "       'Vacation_Winterferien', \"prev_Total_1\", \"prev_Total_2\", \"prev_Total_3\"]\n",
        "\n",
        "# Have features without NaN values for NN\n",
        "features_MLP = ['Year', 'Month', 'Day', 'Weekday',\n",
        "       'tmax', 'prcp', 'snow', 'wspd', 'pres', 'tsun',\n",
        "       'Holiday_1. Weihnachtsfeiertag', 'Holiday_2. Weihnachtsfeiertag',\n",
        "       'Holiday_Christi Himmelfahrt', 'Holiday_Karfreitag', 'Holiday_Neujahr',\n",
        "       'Holiday_Ostermontag', 'Holiday_Pfingstmontag',\n",
        "       'Holiday_Reformationstag', 'Holiday_Tag der Arbeit',\n",
        "       'Holiday_Tag der Deutschen Einheit', 'Vacation_Herbstferien',\n",
        "       'Vacation_Osterferien', 'Vacation_Pfingstferien',\n",
        "       'Vacation_Sommerferien', 'Vacation_Weihnachtsferien',\n",
        "       'Vacation_Winterferien']\n",
        "\n",
        "target = 'Total'\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features_MLP], data[target], \n",
        "                                                    test_size=0.2, shuffle=True, random_state=0)"
      ],
      "metadata": {
        "id": "nxeQ39ojh2Y-"
      },
      "id": "nxeQ39ojh2Y-",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `GridSearchCV` to select optimal parameters."
      ],
      "metadata": {
        "id": "amR72D-bg9Ea"
      },
      "id": "amR72D-bg9Ea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaSMrh3bLqsm"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [700, 1000, 1200],\n",
        "    'subsample': [0.5, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.5, 0.8, 1.0],\n",
        "    'reg_alpha': [0.1, 0.5, 1.0],\n",
        "    'reg_lambda': [0.1, 0.5, 1.0],\n",
        "    'min_child_weight': [1, 5, 10]\n",
        "}\n",
        "\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "\n",
        "grid_search = GridSearchCV(xg_reg, param_grid=params, cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search.best_params_)"
      ],
      "id": "AaSMrh3bLqsm"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "RwfBOBjpXNfw",
        "outputId": "21636504-260c-4467-d284-bb997a523faa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 1128.649456\n",
            "Test RMSE: 6468.643608\n"
          ]
        }
      ],
      "source": [
        "# Build the XGBoost regressor model with selected hyper parameters\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 1.0, learning_rate = 0.01, \n",
        "                          max_depth = 12, n_estimators = 1000, reg_alpha = 0.1, reg_lambda = 1.0, \n",
        "                          subsample = 0.8, min_child_weight=5)\n",
        "\n",
        "xg_reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "# Predict on the test set\n",
        "preds_train = xg_reg.predict(X_train)\n",
        "\n",
        "# Training set\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, preds_train))\n",
        "print(\"Train RMSE: %f\" % (rmse_train))\n",
        "\n",
        "# Predict on the test set\n",
        "preds_test = xg_reg.predict(X_test)\n",
        "\n",
        "# Test set\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, preds_test))\n",
        "print(\"Test RMSE: %f\" % (rmse_test))"
      ],
      "id": "RwfBOBjpXNfw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKSA0rEBGRNB"
      },
      "source": [
        "* 02.04.23: 6468\n",
        "* 10.04.23: 6120"
      ],
      "id": "RKSA0rEBGRNB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an alternative, instead of `train_test_split`, we try `TimeSeriesSplit` and compare the performance."
      ],
      "metadata": {
        "id": "Y9ZfwhxDkTUL"
      },
      "id": "Y9ZfwhxDkTUL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "for train_index, test_index in tscv.split(data):\n",
        "    X_train, X_test = data.iloc[train_index][features], data.iloc[test_index][features]\n",
        "    y_train, y_test = data.iloc[train_index][target], data.iloc[test_index][target]\n",
        "\n",
        "    xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=1.0, learning_rate=0.01,\n",
        "                              max_depth=12, n_estimators=1000, reg_alpha=0.1, reg_lambda=1.0,\n",
        "                              subsample=0.8, min_child_weight=5)\n",
        "\n",
        "    xg_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    preds = xg_reg.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance using RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    print(\"RMSE: %f\" % (rmse))\n"
      ],
      "metadata": {
        "id": "qvsBo8m7cZXf"
      },
      "id": "qvsBo8m7cZXf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`train_test_split` has a better performance on the accuracy of the model than `TimeSeriesSplit`."
      ],
      "metadata": {
        "id": "A0-dFnLfnHkG"
      },
      "id": "A0-dFnLfnHkG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot random different data points to analyze big differences between prediction and actual value in more detail."
      ],
      "metadata": {
        "id": "2BZuW_UOgc1Q"
      },
      "id": "2BZuW_UOgc1Q"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 100 random datapoints from y_test\n",
        "random_indices = random.sample(range(len(y_test)), 100)\n",
        "y_test_sample = y_test[random_indices]\n",
        "preds_sample = preds[random_indices]\n",
        "\n",
        "# Create plot using plotly express\n",
        "fig = px.scatter()\n",
        "fig.add_scatter(x=y_test_sample.index, y=y_test_sample, mode='markers', name='y_test', marker=dict(color='blue'))\n",
        "fig.add_scatter(x=y_test_sample.index, y=preds_sample, mode='markers', name='preds', marker=dict(color='red'))\n",
        "fig.update_layout(title='y_test vs. preds, random values', xaxis_title='Date', yaxis_title='Values')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "pXPOd1x_ufBG",
        "outputId": "0ec24e4c-0b46-4442-a2fd-defcc68e6e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "id": "pXPOd1x_ufBG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"72946cab-2750-4189-9586-af116db80ed0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"72946cab-2750-4189-9586-af116db80ed0\")) {                    Plotly.newPlot(                        \"72946cab-2750-4189-9586-af116db80ed0\",                        [{\"hovertemplate\":\"<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\"},\"mode\":\"markers\",\"name\":\"y_test\",\"x\":[\"2013-01-05T00:00:00\",\"2015-06-02T00:00:00\",\"2018-11-22T00:00:00\",\"2013-06-06T00:00:00\",\"2021-09-28T00:00:00\",\"2018-04-16T00:00:00\",\"2021-06-29T00:00:00\",\"2017-11-29T00:00:00\",\"2022-10-15T00:00:00\",\"2014-12-14T00:00:00\",\"2018-05-17T00:00:00\",\"2015-08-30T00:00:00\",\"2021-01-10T00:00:00\",\"2020-08-09T00:00:00\",\"2016-02-15T00:00:00\",\"2013-12-13T00:00:00\",\"2017-02-05T00:00:00\",\"2016-12-03T00:00:00\",\"2022-06-03T00:00:00\",\"2016-11-24T00:00:00\",\"2022-04-10T00:00:00\",\"2020-04-24T00:00:00\",\"2020-11-17T00:00:00\",\"2019-04-07T00:00:00\",\"2014-07-03T00:00:00\",\"2019-08-27T00:00:00\",\"2021-10-03T00:00:00\",\"2015-04-06T00:00:00\",\"2014-02-07T00:00:00\",\"2019-04-14T00:00:00\",\"2021-05-18T00:00:00\",\"2022-01-27T00:00:00\",\"2016-03-20T00:00:00\",\"2017-05-03T00:00:00\",\"2015-11-04T00:00:00\",\"2022-11-28T00:00:00\",\"2017-10-31T00:00:00\",\"2022-01-16T00:00:00\",\"2018-02-11T00:00:00\",\"2013-02-09T00:00:00\",\"2019-06-01T00:00:00\",\"2019-05-06T00:00:00\",\"2019-06-07T00:00:00\",\"2016-08-29T00:00:00\",\"2016-02-14T00:00:00\",\"2020-05-01T00:00:00\",\"2017-03-11T00:00:00\",\"2021-12-05T00:00:00\",\"2022-07-21T00:00:00\",\"2017-12-17T00:00:00\",\"2017-04-09T00:00:00\",\"2015-08-10T00:00:00\",\"2016-10-09T00:00:00\",\"2022-12-06T00:00:00\",\"2016-01-26T00:00:00\",\"2014-12-21T00:00:00\",\"2013-02-27T00:00:00\",\"2018-10-26T00:00:00\",\"2017-04-04T00:00:00\",\"2017-10-29T00:00:00\",\"2017-07-29T00:00:00\",\"2014-06-02T00:00:00\",\"2017-05-06T00:00:00\",\"2019-10-22T00:00:00\",\"2015-07-08T00:00:00\",\"2013-04-15T00:00:00\",\"2016-09-30T00:00:00\",\"2017-10-16T00:00:00\",\"2022-02-04T00:00:00\",\"2022-08-17T00:00:00\",\"2021-01-29T00:00:00\",\"2021-11-21T00:00:00\",\"2018-03-11T00:00:00\",\"2014-07-17T00:00:00\",\"2020-12-05T00:00:00\",\"2014-03-04T00:00:00\",\"2015-04-07T00:00:00\",\"2013-08-23T00:00:00\",\"2016-08-10T00:00:00\",\"2017-05-23T00:00:00\",\"2020-06-22T00:00:00\",\"2017-05-12T00:00:00\",\"2014-04-11T00:00:00\",\"2015-03-05T00:00:00\",\"2014-03-20T00:00:00\",\"2014-07-01T00:00:00\",\"2018-08-21T00:00:00\",\"2015-10-30T00:00:00\",\"2013-11-08T00:00:00\",\"2015-11-19T00:00:00\",\"2022-03-06T00:00:00\",\"2019-12-25T00:00:00\",\"2019-10-07T00:00:00\",\"2016-02-23T00:00:00\",\"2013-10-17T00:00:00\",\"2015-06-25T00:00:00\",\"2022-05-08T00:00:00\",\"2013-09-11T00:00:00\",\"2020-08-08T00:00:00\",\"2015-06-20T00:00:00\"],\"y\":[30643.0,26553.0,33426.0,50191.0,46770.0,43364.0,33378.0,33537.0,26313.0,15074.0,45200.0,25169.0,45148.0,47796.0,23435.0,30203.0,35463.0,22081.0,21103.0,37972.0,43057.0,38306.0,34197.0,53584.0,36592.0,55075.0,29903.0,51798.0,46398.0,17280.0,36491.0,28465.0,16106.0,17235.0,23190.0,27446.0,15780.0,12165.0,40225.0,32885.0,11880.0,50738.0,25250.0,40038.0,6729.0,13332.0,38856.0,36675.0,27391.0,12359.0,48946.0,40092.0,41406.0,33205.0,32915.0,11003.0,26363.0,34764.0,53618.0,15248.0,20074.0,29996.0,31355.0,45471.0,27901.0,36195.0,39593.0,50244.0,19915.0,39278.0,15473.0,18462.0,26957.0,55546.0,31045.0,46002.0,44020.0,48086.0,21765.0,47145.0,53078.0,34708.0,32329.0,19083.0,46482.0,32943.0,52242.0,34043.0,27447.0,30816.0,46220.0,7443.0,40401.0,29748.0,28164.0,46478.0,26516.0,17215.0,37929.0,24926.0],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"markers\",\"name\":\"preds\",\"x\":[\"2013-01-05T00:00:00\",\"2015-06-02T00:00:00\",\"2018-11-22T00:00:00\",\"2013-06-06T00:00:00\",\"2021-09-28T00:00:00\",\"2018-04-16T00:00:00\",\"2021-06-29T00:00:00\",\"2017-11-29T00:00:00\",\"2022-10-15T00:00:00\",\"2014-12-14T00:00:00\",\"2018-05-17T00:00:00\",\"2015-08-30T00:00:00\",\"2021-01-10T00:00:00\",\"2020-08-09T00:00:00\",\"2016-02-15T00:00:00\",\"2013-12-13T00:00:00\",\"2017-02-05T00:00:00\",\"2016-12-03T00:00:00\",\"2022-06-03T00:00:00\",\"2016-11-24T00:00:00\",\"2022-04-10T00:00:00\",\"2020-04-24T00:00:00\",\"2020-11-17T00:00:00\",\"2019-04-07T00:00:00\",\"2014-07-03T00:00:00\",\"2019-08-27T00:00:00\",\"2021-10-03T00:00:00\",\"2015-04-06T00:00:00\",\"2014-02-07T00:00:00\",\"2019-04-14T00:00:00\",\"2021-05-18T00:00:00\",\"2022-01-27T00:00:00\",\"2016-03-20T00:00:00\",\"2017-05-03T00:00:00\",\"2015-11-04T00:00:00\",\"2022-11-28T00:00:00\",\"2017-10-31T00:00:00\",\"2022-01-16T00:00:00\",\"2018-02-11T00:00:00\",\"2013-02-09T00:00:00\",\"2019-06-01T00:00:00\",\"2019-05-06T00:00:00\",\"2019-06-07T00:00:00\",\"2016-08-29T00:00:00\",\"2016-02-14T00:00:00\",\"2020-05-01T00:00:00\",\"2017-03-11T00:00:00\",\"2021-12-05T00:00:00\",\"2022-07-21T00:00:00\",\"2017-12-17T00:00:00\",\"2017-04-09T00:00:00\",\"2015-08-10T00:00:00\",\"2016-10-09T00:00:00\",\"2022-12-06T00:00:00\",\"2016-01-26T00:00:00\",\"2014-12-21T00:00:00\",\"2013-02-27T00:00:00\",\"2018-10-26T00:00:00\",\"2017-04-04T00:00:00\",\"2017-10-29T00:00:00\",\"2017-07-29T00:00:00\",\"2014-06-02T00:00:00\",\"2017-05-06T00:00:00\",\"2019-10-22T00:00:00\",\"2015-07-08T00:00:00\",\"2013-04-15T00:00:00\",\"2016-09-30T00:00:00\",\"2017-10-16T00:00:00\",\"2022-02-04T00:00:00\",\"2022-08-17T00:00:00\",\"2021-01-29T00:00:00\",\"2021-11-21T00:00:00\",\"2018-03-11T00:00:00\",\"2014-07-17T00:00:00\",\"2020-12-05T00:00:00\",\"2014-03-04T00:00:00\",\"2015-04-07T00:00:00\",\"2013-08-23T00:00:00\",\"2016-08-10T00:00:00\",\"2017-05-23T00:00:00\",\"2020-06-22T00:00:00\",\"2017-05-12T00:00:00\",\"2014-04-11T00:00:00\",\"2015-03-05T00:00:00\",\"2014-03-20T00:00:00\",\"2014-07-01T00:00:00\",\"2018-08-21T00:00:00\",\"2015-10-30T00:00:00\",\"2013-11-08T00:00:00\",\"2015-11-19T00:00:00\",\"2022-03-06T00:00:00\",\"2019-12-25T00:00:00\",\"2019-10-07T00:00:00\",\"2016-02-23T00:00:00\",\"2013-10-17T00:00:00\",\"2015-06-25T00:00:00\",\"2022-05-08T00:00:00\",\"2013-09-11T00:00:00\",\"2020-08-08T00:00:00\",\"2015-06-20T00:00:00\"],\"y\":[29531.0,30443.0,28509.0,30013.0,29507.0,46826.0,44027.0,46368.0,7750.0,41606.0,53533.0,25863.0,38786.0,28164.0,21577.0,37801.0,34848.0,39739.0,14591.0,30338.0,40132.0,30761.0,37368.0,30954.0,22359.0,28032.0,33224.0,17959.0,28505.0,47177.0,12411.0,14712.0,50977.0,19973.0,31003.0,46398.0,44800.0,8660.0,5832.0,48810.0,22765.0,39728.0,10898.0,31042.0,33981.0,42660.0,30044.0,30061.0,36195.0,44389.0,5188.0,38534.0,38204.0,32972.0,32717.0,37629.0,24112.0,38673.0,36592.0,20094.0,36711.0,45966.0,24222.0,27914.0,25641.0,28551.0,24851.0,14844.0,43663.0,11935.0,42673.0,21206.0,5795.0,42954.0,34174.0,11003.0,46399.0,28881.0,35357.0,31785.0,28676.0,27149.0,42575.0,27195.0,20926.0,56823.0,19700.0,30670.0,39399.0,26168.0,32624.0,19004.0,17313.0,34151.0,37849.0,30972.0,37703.0,47208.0,34033.0,20438.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Date\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Values\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"y_test vs. preds, random values\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('72946cab-2750-4189-9586-af116db80ed0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5.3.\"></a>\n",
        "## 5.3. Multilayer Perceptron\n",
        "[Content](#content)"
      ],
      "metadata": {
        "id": "fOFZ5oXgTT7V"
      },
      "id": "fOFZ5oXgTT7V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO CHECK: Performance when standardizing/normalizing dataset"
      ],
      "metadata": {
        "id": "pWGJlB8pNl7m"
      },
      "id": "pWGJlB8pNl7m"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture of the MLP\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(26,)))\n",
        "model.add(Dense(units=1024, activation='relu'))  # Input layer with 20 features\n",
        "model.add(Dense(units=512, activation='relu'))  # Hidden layer with 32 neurons\n",
        "model.add(Dense(units=256, activation='relu'))  # Hidden layer with 32 neurons\n",
        "model.add(Dense(units=128, activation='relu'))  # Hidden layer with 32 neurons\n",
        "model.add(Dense(units=32, activation='relu'))  # Hidden layer with 32 neurons\n",
        "model.add(Dense(units=16, activation='relu'))  # Hidden layer with 32 neurons\n",
        "model.add(Dense(units=8, activation='relu'))  # Hidden layer with 32 neurons\n",
        "model.add(Dense(units=1, activation='linear'))  # Output layer with 1 neuron for regression\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])  # Use Adam optimizer, mean squared error (MSE) loss, and root mean square error (RMSE) as metric\n",
        "\n",
        "# Train the model\n",
        "#model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))  # Use X_train and y_train for training, X_test and y_test for validation, train for 100 epochs with batch size of 32\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=64, validation_data=(X_test, y_test))  # Use X_train and y_train for training, X_test and y_test for validation, train for 100 epochs with batch size of 32\n"
      ],
      "metadata": {
        "id": "CFbCaX6sKhZF",
        "outputId": "4fd77f50-51ed-40af-d7a7-8f73071a3c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CFbCaX6sKhZF",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "46/46 [==============================] - 4s 16ms/step - loss: 476962656.0000 - root_mean_squared_error: 21839.4746 - val_loss: 131006792.0000 - val_root_mean_squared_error: 11445.8203\n",
            "Epoch 2/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 127741568.0000 - root_mean_squared_error: 11302.2812 - val_loss: 111768264.0000 - val_root_mean_squared_error: 10572.0508\n",
            "Epoch 3/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 124502792.0000 - root_mean_squared_error: 11158.0820 - val_loss: 109943776.0000 - val_root_mean_squared_error: 10485.4082\n",
            "Epoch 4/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 126028072.0000 - root_mean_squared_error: 11226.2227 - val_loss: 110266184.0000 - val_root_mean_squared_error: 10500.7705\n",
            "Epoch 5/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 123097888.0000 - root_mean_squared_error: 11094.9492 - val_loss: 108894280.0000 - val_root_mean_squared_error: 10435.2422\n",
            "Epoch 6/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 122979344.0000 - root_mean_squared_error: 11089.6055 - val_loss: 110763248.0000 - val_root_mean_squared_error: 10524.4121\n",
            "Epoch 7/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 122442088.0000 - root_mean_squared_error: 11065.3555 - val_loss: 107666808.0000 - val_root_mean_squared_error: 10376.2617\n",
            "Epoch 8/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 122927408.0000 - root_mean_squared_error: 11087.2637 - val_loss: 106808752.0000 - val_root_mean_squared_error: 10334.8320\n",
            "Epoch 9/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 121514480.0000 - root_mean_squared_error: 11023.3604 - val_loss: 106826832.0000 - val_root_mean_squared_error: 10335.7070\n",
            "Epoch 10/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 122269920.0000 - root_mean_squared_error: 11057.5732 - val_loss: 110002760.0000 - val_root_mean_squared_error: 10488.2197\n",
            "Epoch 11/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 121695360.0000 - root_mean_squared_error: 11031.5615 - val_loss: 105236776.0000 - val_root_mean_squared_error: 10258.4980\n",
            "Epoch 12/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 120601560.0000 - root_mean_squared_error: 10981.8740 - val_loss: 105266504.0000 - val_root_mean_squared_error: 10259.9463\n",
            "Epoch 13/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 119105176.0000 - root_mean_squared_error: 10913.5322 - val_loss: 103474152.0000 - val_root_mean_squared_error: 10172.2246\n",
            "Epoch 14/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 117375136.0000 - root_mean_squared_error: 10833.9805 - val_loss: 102470032.0000 - val_root_mean_squared_error: 10122.7480\n",
            "Epoch 15/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 116221424.0000 - root_mean_squared_error: 10780.6045 - val_loss: 101363808.0000 - val_root_mean_squared_error: 10067.9600\n",
            "Epoch 16/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 116979760.0000 - root_mean_squared_error: 10815.7178 - val_loss: 104199352.0000 - val_root_mean_squared_error: 10207.8086\n",
            "Epoch 17/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 114095608.0000 - root_mean_squared_error: 10681.5547 - val_loss: 98234464.0000 - val_root_mean_squared_error: 9911.3301\n",
            "Epoch 18/300\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 118964408.0000 - root_mean_squared_error: 10907.0811 - val_loss: 106445760.0000 - val_root_mean_squared_error: 10317.2559\n",
            "Epoch 19/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 113132536.0000 - root_mean_squared_error: 10636.3779 - val_loss: 95991472.0000 - val_root_mean_squared_error: 9797.5234\n",
            "Epoch 20/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 110499088.0000 - root_mean_squared_error: 10511.8545 - val_loss: 93892352.0000 - val_root_mean_squared_error: 9689.8066\n",
            "Epoch 21/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 108237776.0000 - root_mean_squared_error: 10403.7383 - val_loss: 95057120.0000 - val_root_mean_squared_error: 9749.7236\n",
            "Epoch 22/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 108100848.0000 - root_mean_squared_error: 10397.1562 - val_loss: 113643208.0000 - val_root_mean_squared_error: 10660.3564\n",
            "Epoch 23/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 111765424.0000 - root_mean_squared_error: 10571.9170 - val_loss: 91025072.0000 - val_root_mean_squared_error: 9540.7061\n",
            "Epoch 24/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 111165704.0000 - root_mean_squared_error: 10543.5146 - val_loss: 108077680.0000 - val_root_mean_squared_error: 10396.0420\n",
            "Epoch 25/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 108549400.0000 - root_mean_squared_error: 10418.7041 - val_loss: 101504896.0000 - val_root_mean_squared_error: 10074.9639\n",
            "Epoch 26/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 106307728.0000 - root_mean_squared_error: 10310.5635 - val_loss: 89732096.0000 - val_root_mean_squared_error: 9472.7031\n",
            "Epoch 27/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 102621224.0000 - root_mean_squared_error: 10130.2139 - val_loss: 92296488.0000 - val_root_mean_squared_error: 9607.1064\n",
            "Epoch 28/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 102696368.0000 - root_mean_squared_error: 10133.9219 - val_loss: 87455400.0000 - val_root_mean_squared_error: 9351.7588\n",
            "Epoch 29/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 101583248.0000 - root_mean_squared_error: 10078.8516 - val_loss: 86966808.0000 - val_root_mean_squared_error: 9325.5996\n",
            "Epoch 30/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 100852176.0000 - root_mean_squared_error: 10042.5186 - val_loss: 91957832.0000 - val_root_mean_squared_error: 9589.4648\n",
            "Epoch 31/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 103931832.0000 - root_mean_squared_error: 10194.6963 - val_loss: 91964560.0000 - val_root_mean_squared_error: 9589.8154\n",
            "Epoch 32/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 98039048.0000 - root_mean_squared_error: 9901.4668 - val_loss: 84215152.0000 - val_root_mean_squared_error: 9176.8818\n",
            "Epoch 33/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 97117072.0000 - root_mean_squared_error: 9854.7998 - val_loss: 82899056.0000 - val_root_mean_squared_error: 9104.8916\n",
            "Epoch 34/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 96496040.0000 - root_mean_squared_error: 9823.2402 - val_loss: 82483232.0000 - val_root_mean_squared_error: 9082.0283\n",
            "Epoch 35/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 98887808.0000 - root_mean_squared_error: 9944.2354 - val_loss: 82385648.0000 - val_root_mean_squared_error: 9076.6543\n",
            "Epoch 36/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 95952616.0000 - root_mean_squared_error: 9795.5410 - val_loss: 86273896.0000 - val_root_mean_squared_error: 9288.3740\n",
            "Epoch 37/300\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 95942352.0000 - root_mean_squared_error: 9795.0166 - val_loss: 81631304.0000 - val_root_mean_squared_error: 9035.0039\n",
            "Epoch 38/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 95398864.0000 - root_mean_squared_error: 9767.2344 - val_loss: 80081616.0000 - val_root_mean_squared_error: 8948.8330\n",
            "Epoch 39/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 92805384.0000 - root_mean_squared_error: 9633.5547 - val_loss: 81044632.0000 - val_root_mean_squared_error: 9002.4795\n",
            "Epoch 40/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 96350016.0000 - root_mean_squared_error: 9815.8047 - val_loss: 83574488.0000 - val_root_mean_squared_error: 9141.9082\n",
            "Epoch 41/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 94325928.0000 - root_mean_squared_error: 9712.1533 - val_loss: 78922992.0000 - val_root_mean_squared_error: 8883.8613\n",
            "Epoch 42/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 89817704.0000 - root_mean_squared_error: 9477.2207 - val_loss: 80501840.0000 - val_root_mean_squared_error: 8972.2822\n",
            "Epoch 43/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 96805800.0000 - root_mean_squared_error: 9838.9941 - val_loss: 81230368.0000 - val_root_mean_squared_error: 9012.7891\n",
            "Epoch 44/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 91274440.0000 - root_mean_squared_error: 9553.7656 - val_loss: 77124544.0000 - val_root_mean_squared_error: 8782.0576\n",
            "Epoch 45/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 89207576.0000 - root_mean_squared_error: 9444.9766 - val_loss: 77901248.0000 - val_root_mean_squared_error: 8826.1680\n",
            "Epoch 46/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 89179728.0000 - root_mean_squared_error: 9443.5020 - val_loss: 80245880.0000 - val_root_mean_squared_error: 8958.0068\n",
            "Epoch 47/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 87245344.0000 - root_mean_squared_error: 9340.5215 - val_loss: 76141944.0000 - val_root_mean_squared_error: 8725.9355\n",
            "Epoch 48/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 86963008.0000 - root_mean_squared_error: 9325.3955 - val_loss: 86736504.0000 - val_root_mean_squared_error: 9313.2432\n",
            "Epoch 49/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 86602160.0000 - root_mean_squared_error: 9306.0283 - val_loss: 75568392.0000 - val_root_mean_squared_error: 8693.0078\n",
            "Epoch 50/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 88183312.0000 - root_mean_squared_error: 9390.5967 - val_loss: 75982120.0000 - val_root_mean_squared_error: 8716.7725\n",
            "Epoch 51/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 88471728.0000 - root_mean_squared_error: 9405.9414 - val_loss: 77807048.0000 - val_root_mean_squared_error: 8820.8301\n",
            "Epoch 52/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 85594048.0000 - root_mean_squared_error: 9251.7051 - val_loss: 86161984.0000 - val_root_mean_squared_error: 9282.3477\n",
            "Epoch 53/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 86149416.0000 - root_mean_squared_error: 9281.6709 - val_loss: 74459232.0000 - val_root_mean_squared_error: 8628.9766\n",
            "Epoch 54/300\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 83891984.0000 - root_mean_squared_error: 9159.2568 - val_loss: 73574808.0000 - val_root_mean_squared_error: 8577.5762\n",
            "Epoch 55/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 84131928.0000 - root_mean_squared_error: 9172.3457 - val_loss: 73668072.0000 - val_root_mean_squared_error: 8583.0107\n",
            "Epoch 56/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 84325480.0000 - root_mean_squared_error: 9182.8906 - val_loss: 72582448.0000 - val_root_mean_squared_error: 8519.5332\n",
            "Epoch 57/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 82474248.0000 - root_mean_squared_error: 9081.5332 - val_loss: 71807040.0000 - val_root_mean_squared_error: 8473.9033\n",
            "Epoch 58/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 81837744.0000 - root_mean_squared_error: 9046.4219 - val_loss: 72135376.0000 - val_root_mean_squared_error: 8493.2549\n",
            "Epoch 59/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 81705288.0000 - root_mean_squared_error: 9039.0977 - val_loss: 71520616.0000 - val_root_mean_squared_error: 8456.9863\n",
            "Epoch 60/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 84544096.0000 - root_mean_squared_error: 9194.7861 - val_loss: 74744792.0000 - val_root_mean_squared_error: 8645.5068\n",
            "Epoch 61/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 81857120.0000 - root_mean_squared_error: 9047.4922 - val_loss: 73887840.0000 - val_root_mean_squared_error: 8595.8037\n",
            "Epoch 62/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 86156656.0000 - root_mean_squared_error: 9282.0605 - val_loss: 75081224.0000 - val_root_mean_squared_error: 8664.9424\n",
            "Epoch 63/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 83392184.0000 - root_mean_squared_error: 9131.9316 - val_loss: 71767072.0000 - val_root_mean_squared_error: 8471.5449\n",
            "Epoch 64/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 80171048.0000 - root_mean_squared_error: 8953.8291 - val_loss: 71374192.0000 - val_root_mean_squared_error: 8448.3252\n",
            "Epoch 65/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 78960544.0000 - root_mean_squared_error: 8885.9746 - val_loss: 75756008.0000 - val_root_mean_squared_error: 8703.7930\n",
            "Epoch 66/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 78576640.0000 - root_mean_squared_error: 8864.3467 - val_loss: 74135344.0000 - val_root_mean_squared_error: 8610.1885\n",
            "Epoch 67/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 81803480.0000 - root_mean_squared_error: 9044.5273 - val_loss: 72532760.0000 - val_root_mean_squared_error: 8516.6162\n",
            "Epoch 68/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 82562648.0000 - root_mean_squared_error: 9086.3994 - val_loss: 68626256.0000 - val_root_mean_squared_error: 8284.0967\n",
            "Epoch 69/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 78111728.0000 - root_mean_squared_error: 8838.0840 - val_loss: 68371784.0000 - val_root_mean_squared_error: 8268.7236\n",
            "Epoch 70/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 78329928.0000 - root_mean_squared_error: 8850.4199 - val_loss: 70139008.0000 - val_root_mean_squared_error: 8374.9033\n",
            "Epoch 71/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 78255320.0000 - root_mean_squared_error: 8846.2041 - val_loss: 76998712.0000 - val_root_mean_squared_error: 8774.8906\n",
            "Epoch 72/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 80302120.0000 - root_mean_squared_error: 8961.1445 - val_loss: 69719656.0000 - val_root_mean_squared_error: 8349.8301\n",
            "Epoch 73/300\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 77245448.0000 - root_mean_squared_error: 8788.9385 - val_loss: 67927904.0000 - val_root_mean_squared_error: 8241.8389\n",
            "Epoch 74/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 77720920.0000 - root_mean_squared_error: 8815.9473 - val_loss: 69474416.0000 - val_root_mean_squared_error: 8335.1318\n",
            "Epoch 75/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 83722856.0000 - root_mean_squared_error: 9150.0195 - val_loss: 68635296.0000 - val_root_mean_squared_error: 8284.6426\n",
            "Epoch 76/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 78121504.0000 - root_mean_squared_error: 8838.6367 - val_loss: 75131680.0000 - val_root_mean_squared_error: 8667.8535\n",
            "Epoch 77/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 76022448.0000 - root_mean_squared_error: 8719.0850 - val_loss: 74678768.0000 - val_root_mean_squared_error: 8641.6875\n",
            "Epoch 78/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 78782280.0000 - root_mean_squared_error: 8875.9385 - val_loss: 68501320.0000 - val_root_mean_squared_error: 8276.5527\n",
            "Epoch 79/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 75555120.0000 - root_mean_squared_error: 8692.2451 - val_loss: 67452976.0000 - val_root_mean_squared_error: 8212.9766\n",
            "Epoch 80/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 76083080.0000 - root_mean_squared_error: 8722.5615 - val_loss: 67352640.0000 - val_root_mean_squared_error: 8206.8652\n",
            "Epoch 81/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 74151952.0000 - root_mean_squared_error: 8611.1523 - val_loss: 70390696.0000 - val_root_mean_squared_error: 8389.9160\n",
            "Epoch 82/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 75411144.0000 - root_mean_squared_error: 8683.9590 - val_loss: 67718600.0000 - val_root_mean_squared_error: 8229.1309\n",
            "Epoch 83/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 76003632.0000 - root_mean_squared_error: 8718.0059 - val_loss: 67003392.0000 - val_root_mean_squared_error: 8185.5601\n",
            "Epoch 84/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 75518480.0000 - root_mean_squared_error: 8690.1367 - val_loss: 66357516.0000 - val_root_mean_squared_error: 8146.0122\n",
            "Epoch 85/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 75427648.0000 - root_mean_squared_error: 8684.9092 - val_loss: 77219296.0000 - val_root_mean_squared_error: 8787.4512\n",
            "Epoch 86/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 74881296.0000 - root_mean_squared_error: 8653.3975 - val_loss: 65563272.0000 - val_root_mean_squared_error: 8097.1152\n",
            "Epoch 87/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 73822504.0000 - root_mean_squared_error: 8592.0020 - val_loss: 67348608.0000 - val_root_mean_squared_error: 8206.6201\n",
            "Epoch 88/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 76264040.0000 - root_mean_squared_error: 8732.9287 - val_loss: 70003208.0000 - val_root_mean_squared_error: 8366.7920\n",
            "Epoch 89/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 73026480.0000 - root_mean_squared_error: 8545.5537 - val_loss: 70645008.0000 - val_root_mean_squared_error: 8405.0586\n",
            "Epoch 90/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 73870432.0000 - root_mean_squared_error: 8594.7910 - val_loss: 65908836.0000 - val_root_mean_squared_error: 8118.4258\n",
            "Epoch 91/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 76629384.0000 - root_mean_squared_error: 8753.8213 - val_loss: 69983216.0000 - val_root_mean_squared_error: 8365.5977\n",
            "Epoch 92/300\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 76282168.0000 - root_mean_squared_error: 8733.9668 - val_loss: 69397680.0000 - val_root_mean_squared_error: 8330.5273\n",
            "Epoch 93/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 73525544.0000 - root_mean_squared_error: 8574.7041 - val_loss: 64992968.0000 - val_root_mean_squared_error: 8061.8218\n",
            "Epoch 94/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 75032672.0000 - root_mean_squared_error: 8662.1406 - val_loss: 71999224.0000 - val_root_mean_squared_error: 8485.2354\n",
            "Epoch 95/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72489592.0000 - root_mean_squared_error: 8514.0820 - val_loss: 65806032.0000 - val_root_mean_squared_error: 8112.0918\n",
            "Epoch 96/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 73543184.0000 - root_mean_squared_error: 8575.7324 - val_loss: 65795680.0000 - val_root_mean_squared_error: 8111.4536\n",
            "Epoch 97/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 72326320.0000 - root_mean_squared_error: 8504.4883 - val_loss: 67114024.0000 - val_root_mean_squared_error: 8192.3145\n",
            "Epoch 98/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 74266824.0000 - root_mean_squared_error: 8617.8203 - val_loss: 65735828.0000 - val_root_mean_squared_error: 8107.7637\n",
            "Epoch 99/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72648536.0000 - root_mean_squared_error: 8523.4111 - val_loss: 68128000.0000 - val_root_mean_squared_error: 8253.9688\n",
            "Epoch 100/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 73392296.0000 - root_mean_squared_error: 8566.9307 - val_loss: 66770632.0000 - val_root_mean_squared_error: 8171.3301\n",
            "Epoch 101/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 73145784.0000 - root_mean_squared_error: 8552.5312 - val_loss: 64032540.0000 - val_root_mean_squared_error: 8002.0337\n",
            "Epoch 102/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 75045992.0000 - root_mean_squared_error: 8662.9092 - val_loss: 67756528.0000 - val_root_mean_squared_error: 8231.4355\n",
            "Epoch 103/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 73107504.0000 - root_mean_squared_error: 8550.2930 - val_loss: 75990768.0000 - val_root_mean_squared_error: 8717.2686\n",
            "Epoch 104/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72615216.0000 - root_mean_squared_error: 8521.4561 - val_loss: 64713876.0000 - val_root_mean_squared_error: 8044.4937\n",
            "Epoch 105/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72522144.0000 - root_mean_squared_error: 8515.9932 - val_loss: 63967780.0000 - val_root_mean_squared_error: 7997.9858\n",
            "Epoch 106/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 71803696.0000 - root_mean_squared_error: 8473.7061 - val_loss: 63850724.0000 - val_root_mean_squared_error: 7990.6650\n",
            "Epoch 107/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72422920.0000 - root_mean_squared_error: 8510.1660 - val_loss: 84540856.0000 - val_root_mean_squared_error: 9194.6104\n",
            "Epoch 108/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 73251464.0000 - root_mean_squared_error: 8558.7070 - val_loss: 64854836.0000 - val_root_mean_squared_error: 8053.2500\n",
            "Epoch 109/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 70813904.0000 - root_mean_squared_error: 8415.1006 - val_loss: 65553156.0000 - val_root_mean_squared_error: 8096.4902\n",
            "Epoch 110/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72015240.0000 - root_mean_squared_error: 8486.1797 - val_loss: 63266608.0000 - val_root_mean_squared_error: 7954.0308\n",
            "Epoch 111/300\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 76021640.0000 - root_mean_squared_error: 8719.0391 - val_loss: 75514024.0000 - val_root_mean_squared_error: 8689.8809\n",
            "Epoch 112/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 74050144.0000 - root_mean_squared_error: 8605.2393 - val_loss: 64347864.0000 - val_root_mean_squared_error: 8021.7119\n",
            "Epoch 113/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 70222920.0000 - root_mean_squared_error: 8379.9121 - val_loss: 63044012.0000 - val_root_mean_squared_error: 7940.0259\n",
            "Epoch 114/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 71419968.0000 - root_mean_squared_error: 8451.0332 - val_loss: 62808996.0000 - val_root_mean_squared_error: 7925.2129\n",
            "Epoch 115/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 70118736.0000 - root_mean_squared_error: 8373.6934 - val_loss: 64097272.0000 - val_root_mean_squared_error: 8006.0771\n",
            "Epoch 116/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 70901664.0000 - root_mean_squared_error: 8420.3125 - val_loss: 65517004.0000 - val_root_mean_squared_error: 8094.2573\n",
            "Epoch 117/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 69665232.0000 - root_mean_squared_error: 8346.5703 - val_loss: 67953584.0000 - val_root_mean_squared_error: 8243.3965\n",
            "Epoch 118/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72657048.0000 - root_mean_squared_error: 8523.9102 - val_loss: 62392756.0000 - val_root_mean_squared_error: 7898.9087\n",
            "Epoch 119/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 74939776.0000 - root_mean_squared_error: 8656.7764 - val_loss: 70975504.0000 - val_root_mean_squared_error: 8424.6963\n",
            "Epoch 120/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 70084168.0000 - root_mean_squared_error: 8371.6289 - val_loss: 64039560.0000 - val_root_mean_squared_error: 8002.4722\n",
            "Epoch 121/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 70234592.0000 - root_mean_squared_error: 8380.6084 - val_loss: 73737512.0000 - val_root_mean_squared_error: 8587.0547\n",
            "Epoch 122/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 70914616.0000 - root_mean_squared_error: 8421.0820 - val_loss: 78736272.0000 - val_root_mean_squared_error: 8873.3457\n",
            "Epoch 123/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 73686912.0000 - root_mean_squared_error: 8584.1084 - val_loss: 63718672.0000 - val_root_mean_squared_error: 7982.3975\n",
            "Epoch 124/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 68469872.0000 - root_mean_squared_error: 8274.6523 - val_loss: 63996208.0000 - val_root_mean_squared_error: 7999.7632\n",
            "Epoch 125/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 70255752.0000 - root_mean_squared_error: 8381.8701 - val_loss: 81314192.0000 - val_root_mean_squared_error: 9017.4385\n",
            "Epoch 126/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 71006584.0000 - root_mean_squared_error: 8426.5400 - val_loss: 65062080.0000 - val_root_mean_squared_error: 8066.1069\n",
            "Epoch 127/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 69710392.0000 - root_mean_squared_error: 8349.2754 - val_loss: 68052552.0000 - val_root_mean_squared_error: 8249.3975\n",
            "Epoch 128/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72895480.0000 - root_mean_squared_error: 8537.8848 - val_loss: 65943992.0000 - val_root_mean_squared_error: 8120.5908\n",
            "Epoch 129/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 72203936.0000 - root_mean_squared_error: 8497.2900 - val_loss: 62271296.0000 - val_root_mean_squared_error: 7891.2163\n",
            "Epoch 130/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 68926656.0000 - root_mean_squared_error: 8302.2080 - val_loss: 62683712.0000 - val_root_mean_squared_error: 7917.3047\n",
            "Epoch 131/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 70843512.0000 - root_mean_squared_error: 8416.8584 - val_loss: 62032288.0000 - val_root_mean_squared_error: 7876.0581\n",
            "Epoch 132/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 68835840.0000 - root_mean_squared_error: 8296.7363 - val_loss: 61824260.0000 - val_root_mean_squared_error: 7862.8403\n",
            "Epoch 133/300\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 68521208.0000 - root_mean_squared_error: 8277.7539 - val_loss: 63207652.0000 - val_root_mean_squared_error: 7950.3242\n",
            "Epoch 134/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 69769728.0000 - root_mean_squared_error: 8352.8271 - val_loss: 63835556.0000 - val_root_mean_squared_error: 7989.7158\n",
            "Epoch 135/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 70857672.0000 - root_mean_squared_error: 8417.7002 - val_loss: 60846848.0000 - val_root_mean_squared_error: 7800.4390\n",
            "Epoch 136/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 67486408.0000 - root_mean_squared_error: 8215.0107 - val_loss: 69722792.0000 - val_root_mean_squared_error: 8350.0176\n",
            "Epoch 137/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 67795496.0000 - root_mean_squared_error: 8233.8018 - val_loss: 65226100.0000 - val_root_mean_squared_error: 8076.2676\n",
            "Epoch 138/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 68624952.0000 - root_mean_squared_error: 8284.0176 - val_loss: 65230648.0000 - val_root_mean_squared_error: 8076.5493\n",
            "Epoch 139/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 69261416.0000 - root_mean_squared_error: 8322.3447 - val_loss: 78242592.0000 - val_root_mean_squared_error: 8845.4844\n",
            "Epoch 140/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 71485504.0000 - root_mean_squared_error: 8454.9102 - val_loss: 61835596.0000 - val_root_mean_squared_error: 7863.5615\n",
            "Epoch 141/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 69517568.0000 - root_mean_squared_error: 8337.7197 - val_loss: 61558880.0000 - val_root_mean_squared_error: 7845.9468\n",
            "Epoch 142/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 67204680.0000 - root_mean_squared_error: 8197.8457 - val_loss: 62623776.0000 - val_root_mean_squared_error: 7913.5186\n",
            "Epoch 143/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 71236608.0000 - root_mean_squared_error: 8440.1777 - val_loss: 63674692.0000 - val_root_mean_squared_error: 7979.6426\n",
            "Epoch 144/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 68542160.0000 - root_mean_squared_error: 8279.0195 - val_loss: 62604736.0000 - val_root_mean_squared_error: 7912.3154\n",
            "Epoch 145/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 69703848.0000 - root_mean_squared_error: 8348.8828 - val_loss: 60577816.0000 - val_root_mean_squared_error: 7783.1753\n",
            "Epoch 146/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 67995856.0000 - root_mean_squared_error: 8245.9600 - val_loss: 63961684.0000 - val_root_mean_squared_error: 7997.6050\n",
            "Epoch 147/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 68462760.0000 - root_mean_squared_error: 8274.2227 - val_loss: 61799596.0000 - val_root_mean_squared_error: 7861.2720\n",
            "Epoch 148/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 66884476.0000 - root_mean_squared_error: 8178.2930 - val_loss: 63126908.0000 - val_root_mean_squared_error: 7945.2441\n",
            "Epoch 149/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 66505792.0000 - root_mean_squared_error: 8155.1084 - val_loss: 61213584.0000 - val_root_mean_squared_error: 7823.9111\n",
            "Epoch 150/300\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 67748912.0000 - root_mean_squared_error: 8230.9727 - val_loss: 66426372.0000 - val_root_mean_squared_error: 8150.2373\n",
            "Epoch 151/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 66535508.0000 - root_mean_squared_error: 8156.9302 - val_loss: 59372956.0000 - val_root_mean_squared_error: 7705.3848\n",
            "Epoch 152/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 70281616.0000 - root_mean_squared_error: 8383.4131 - val_loss: 85624776.0000 - val_root_mean_squared_error: 9253.3652\n",
            "Epoch 153/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 69495376.0000 - root_mean_squared_error: 8336.3887 - val_loss: 69077144.0000 - val_root_mean_squared_error: 8311.2656\n",
            "Epoch 154/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 68152096.0000 - root_mean_squared_error: 8255.4287 - val_loss: 59760132.0000 - val_root_mean_squared_error: 7730.4678\n",
            "Epoch 155/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 66863616.0000 - root_mean_squared_error: 8177.0176 - val_loss: 71091056.0000 - val_root_mean_squared_error: 8431.5508\n",
            "Epoch 156/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 66162472.0000 - root_mean_squared_error: 8134.0317 - val_loss: 59073068.0000 - val_root_mean_squared_error: 7685.9004\n",
            "Epoch 157/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 68285448.0000 - root_mean_squared_error: 8263.5010 - val_loss: 62374660.0000 - val_root_mean_squared_error: 7897.7632\n",
            "Epoch 158/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 66737860.0000 - root_mean_squared_error: 8169.3242 - val_loss: 60245056.0000 - val_root_mean_squared_error: 7761.7690\n",
            "Epoch 159/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 66205096.0000 - root_mean_squared_error: 8136.6514 - val_loss: 58569680.0000 - val_root_mean_squared_error: 7653.0830\n",
            "Epoch 160/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 68294032.0000 - root_mean_squared_error: 8264.0205 - val_loss: 76051136.0000 - val_root_mean_squared_error: 8720.7305\n",
            "Epoch 161/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 67667824.0000 - root_mean_squared_error: 8226.0459 - val_loss: 58896468.0000 - val_root_mean_squared_error: 7674.4033\n",
            "Epoch 162/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 64997172.0000 - root_mean_squared_error: 8062.0825 - val_loss: 59122784.0000 - val_root_mean_squared_error: 7689.1343\n",
            "Epoch 163/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 65387332.0000 - root_mean_squared_error: 8086.2432 - val_loss: 59113972.0000 - val_root_mean_squared_error: 7688.5610\n",
            "Epoch 164/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 65312592.0000 - root_mean_squared_error: 8081.6206 - val_loss: 60605336.0000 - val_root_mean_squared_error: 7784.9429\n",
            "Epoch 165/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 64797480.0000 - root_mean_squared_error: 8049.6880 - val_loss: 65212384.0000 - val_root_mean_squared_error: 8075.4185\n",
            "Epoch 166/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 65455696.0000 - root_mean_squared_error: 8090.4692 - val_loss: 60358420.0000 - val_root_mean_squared_error: 7769.0684\n",
            "Epoch 167/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 65758204.0000 - root_mean_squared_error: 8109.1431 - val_loss: 73711512.0000 - val_root_mean_squared_error: 8585.5410\n",
            "Epoch 168/300\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 67175440.0000 - root_mean_squared_error: 8196.0625 - val_loss: 58713688.0000 - val_root_mean_squared_error: 7662.4858\n",
            "Epoch 169/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 64923864.0000 - root_mean_squared_error: 8057.5347 - val_loss: 58878840.0000 - val_root_mean_squared_error: 7673.2549\n",
            "Epoch 170/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 65242996.0000 - root_mean_squared_error: 8077.3135 - val_loss: 66746708.0000 - val_root_mean_squared_error: 8169.8657\n",
            "Epoch 171/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 68881704.0000 - root_mean_squared_error: 8299.5000 - val_loss: 70737720.0000 - val_root_mean_squared_error: 8410.5723\n",
            "Epoch 172/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 65316536.0000 - root_mean_squared_error: 8081.8647 - val_loss: 64611872.0000 - val_root_mean_squared_error: 8038.1509\n",
            "Epoch 173/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 64097372.0000 - root_mean_squared_error: 8006.0835 - val_loss: 61710492.0000 - val_root_mean_squared_error: 7855.6025\n",
            "Epoch 174/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 68010296.0000 - root_mean_squared_error: 8246.8359 - val_loss: 58986620.0000 - val_root_mean_squared_error: 7680.2749\n",
            "Epoch 175/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 67467152.0000 - root_mean_squared_error: 8213.8389 - val_loss: 57984864.0000 - val_root_mean_squared_error: 7614.7793\n",
            "Epoch 176/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 62341876.0000 - root_mean_squared_error: 7895.6870 - val_loss: 59748700.0000 - val_root_mean_squared_error: 7729.7285\n",
            "Epoch 177/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 63841704.0000 - root_mean_squared_error: 7990.1006 - val_loss: 67813968.0000 - val_root_mean_squared_error: 8234.9238\n",
            "Epoch 178/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 67487192.0000 - root_mean_squared_error: 8215.0586 - val_loss: 56855988.0000 - val_root_mean_squared_error: 7540.2910\n",
            "Epoch 179/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 63590124.0000 - root_mean_squared_error: 7974.3418 - val_loss: 62434336.0000 - val_root_mean_squared_error: 7901.5400\n",
            "Epoch 180/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 64540200.0000 - root_mean_squared_error: 8033.6914 - val_loss: 57565172.0000 - val_root_mean_squared_error: 7587.1714\n",
            "Epoch 181/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 71326528.0000 - root_mean_squared_error: 8445.5039 - val_loss: 58777560.0000 - val_root_mean_squared_error: 7666.6523\n",
            "Epoch 182/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 62840028.0000 - root_mean_squared_error: 7927.1704 - val_loss: 58698948.0000 - val_root_mean_squared_error: 7661.5239\n",
            "Epoch 183/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 64654196.0000 - root_mean_squared_error: 8040.7832 - val_loss: 62508320.0000 - val_root_mean_squared_error: 7906.2202\n",
            "Epoch 184/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 62504776.0000 - root_mean_squared_error: 7905.9961 - val_loss: 58887776.0000 - val_root_mean_squared_error: 7673.8369\n",
            "Epoch 185/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 62950428.0000 - root_mean_squared_error: 7934.1304 - val_loss: 57151880.0000 - val_root_mean_squared_error: 7559.8862\n",
            "Epoch 186/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 62329696.0000 - root_mean_squared_error: 7894.9160 - val_loss: 66450316.0000 - val_root_mean_squared_error: 8151.7065\n",
            "Epoch 187/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 64162668.0000 - root_mean_squared_error: 8010.1602 - val_loss: 60639696.0000 - val_root_mean_squared_error: 7787.1494\n",
            "Epoch 188/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 63562976.0000 - root_mean_squared_error: 7972.6392 - val_loss: 59688804.0000 - val_root_mean_squared_error: 7725.8530\n",
            "Epoch 189/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 66777100.0000 - root_mean_squared_error: 8171.7256 - val_loss: 66239940.0000 - val_root_mean_squared_error: 8138.7925\n",
            "Epoch 190/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 65716556.0000 - root_mean_squared_error: 8106.5747 - val_loss: 58430348.0000 - val_root_mean_squared_error: 7643.9746\n",
            "Epoch 191/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 63396984.0000 - root_mean_squared_error: 7962.2222 - val_loss: 57367848.0000 - val_root_mean_squared_error: 7574.1567\n",
            "Epoch 192/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 63424836.0000 - root_mean_squared_error: 7963.9712 - val_loss: 57821624.0000 - val_root_mean_squared_error: 7604.0532\n",
            "Epoch 193/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 63416060.0000 - root_mean_squared_error: 7963.4199 - val_loss: 55918912.0000 - val_root_mean_squared_error: 7477.8950\n",
            "Epoch 194/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 62183252.0000 - root_mean_squared_error: 7885.6357 - val_loss: 58090692.0000 - val_root_mean_squared_error: 7621.7251\n",
            "Epoch 195/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 61803964.0000 - root_mean_squared_error: 7861.5498 - val_loss: 58427472.0000 - val_root_mean_squared_error: 7643.7866\n",
            "Epoch 196/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 62499428.0000 - root_mean_squared_error: 7905.6582 - val_loss: 57552376.0000 - val_root_mean_squared_error: 7586.3281\n",
            "Epoch 197/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 61352296.0000 - root_mean_squared_error: 7832.7705 - val_loss: 60971640.0000 - val_root_mean_squared_error: 7808.4341\n",
            "Epoch 198/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 62391752.0000 - root_mean_squared_error: 7898.8452 - val_loss: 59151184.0000 - val_root_mean_squared_error: 7690.9805\n",
            "Epoch 199/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 61364440.0000 - root_mean_squared_error: 7833.5459 - val_loss: 63194432.0000 - val_root_mean_squared_error: 7949.4927\n",
            "Epoch 200/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 62939156.0000 - root_mean_squared_error: 7933.4204 - val_loss: 66006128.0000 - val_root_mean_squared_error: 8124.4155\n",
            "Epoch 201/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 64345208.0000 - root_mean_squared_error: 8021.5464 - val_loss: 61357520.0000 - val_root_mean_squared_error: 7833.1040\n",
            "Epoch 202/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 67388984.0000 - root_mean_squared_error: 8209.0791 - val_loss: 57163312.0000 - val_root_mean_squared_error: 7560.6421\n",
            "Epoch 203/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 60760248.0000 - root_mean_squared_error: 7794.8862 - val_loss: 54292156.0000 - val_root_mean_squared_error: 7368.3213\n",
            "Epoch 204/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 60180848.0000 - root_mean_squared_error: 7757.6318 - val_loss: 55478108.0000 - val_root_mean_squared_error: 7448.3628\n",
            "Epoch 205/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 60297412.0000 - root_mean_squared_error: 7765.1406 - val_loss: 61097220.0000 - val_root_mean_squared_error: 7816.4712\n",
            "Epoch 206/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 62248132.0000 - root_mean_squared_error: 7889.7485 - val_loss: 60250752.0000 - val_root_mean_squared_error: 7762.1357\n",
            "Epoch 207/300\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 61172140.0000 - root_mean_squared_error: 7821.2622 - val_loss: 60515244.0000 - val_root_mean_squared_error: 7779.1543\n",
            "Epoch 208/300\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 64899296.0000 - root_mean_squared_error: 8056.0098 - val_loss: 54498024.0000 - val_root_mean_squared_error: 7382.2778\n",
            "Epoch 209/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 59919660.0000 - root_mean_squared_error: 7740.7788 - val_loss: 81644888.0000 - val_root_mean_squared_error: 9035.7559\n",
            "Epoch 210/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 65295968.0000 - root_mean_squared_error: 8080.5923 - val_loss: 59524484.0000 - val_root_mean_squared_error: 7715.2114\n",
            "Epoch 211/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 58515076.0000 - root_mean_squared_error: 7649.5146 - val_loss: 54994864.0000 - val_root_mean_squared_error: 7415.8521\n",
            "Epoch 212/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 61167972.0000 - root_mean_squared_error: 7820.9956 - val_loss: 57275196.0000 - val_root_mean_squared_error: 7568.0376\n",
            "Epoch 213/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 60352692.0000 - root_mean_squared_error: 7768.6997 - val_loss: 59524752.0000 - val_root_mean_squared_error: 7715.2285\n",
            "Epoch 214/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 60163820.0000 - root_mean_squared_error: 7756.5342 - val_loss: 60434620.0000 - val_root_mean_squared_error: 7773.9707\n",
            "Epoch 215/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 58854448.0000 - root_mean_squared_error: 7671.6650 - val_loss: 55427464.0000 - val_root_mean_squared_error: 7444.9624\n",
            "Epoch 216/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 58165500.0000 - root_mean_squared_error: 7626.6309 - val_loss: 57997276.0000 - val_root_mean_squared_error: 7615.5942\n",
            "Epoch 217/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 60898896.0000 - root_mean_squared_error: 7803.7744 - val_loss: 58964532.0000 - val_root_mean_squared_error: 7678.8364\n",
            "Epoch 218/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 59162528.0000 - root_mean_squared_error: 7691.7183 - val_loss: 62818216.0000 - val_root_mean_squared_error: 7925.7944\n",
            "Epoch 219/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 61793712.0000 - root_mean_squared_error: 7860.8975 - val_loss: 55927004.0000 - val_root_mean_squared_error: 7478.4360\n",
            "Epoch 220/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 61288728.0000 - root_mean_squared_error: 7828.7119 - val_loss: 54974796.0000 - val_root_mean_squared_error: 7414.4990\n",
            "Epoch 221/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 58508992.0000 - root_mean_squared_error: 7649.1172 - val_loss: 56797332.0000 - val_root_mean_squared_error: 7536.4004\n",
            "Epoch 222/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 62053792.0000 - root_mean_squared_error: 7877.4229 - val_loss: 56976420.0000 - val_root_mean_squared_error: 7548.2725\n",
            "Epoch 223/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 59010300.0000 - root_mean_squared_error: 7681.8164 - val_loss: 60154748.0000 - val_root_mean_squared_error: 7755.9492\n",
            "Epoch 224/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 57536316.0000 - root_mean_squared_error: 7585.2695 - val_loss: 55731676.0000 - val_root_mean_squared_error: 7465.3652\n",
            "Epoch 225/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 58339924.0000 - root_mean_squared_error: 7638.0576 - val_loss: 56447244.0000 - val_root_mean_squared_error: 7513.1382\n",
            "Epoch 226/300\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 59092248.0000 - root_mean_squared_error: 7687.1484 - val_loss: 56928272.0000 - val_root_mean_squared_error: 7545.0825\n",
            "Epoch 227/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 55381268.0000 - root_mean_squared_error: 7441.8594 - val_loss: 54382324.0000 - val_root_mean_squared_error: 7374.4370\n",
            "Epoch 228/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 58759228.0000 - root_mean_squared_error: 7665.4570 - val_loss: 66076128.0000 - val_root_mean_squared_error: 8128.7222\n",
            "Epoch 229/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 60031300.0000 - root_mean_squared_error: 7747.9868 - val_loss: 56845080.0000 - val_root_mean_squared_error: 7539.5674\n",
            "Epoch 230/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 59271276.0000 - root_mean_squared_error: 7698.7842 - val_loss: 53793932.0000 - val_root_mean_squared_error: 7334.4346\n",
            "Epoch 231/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 58724564.0000 - root_mean_squared_error: 7663.1953 - val_loss: 55853376.0000 - val_root_mean_squared_error: 7473.5117\n",
            "Epoch 232/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 58362572.0000 - root_mean_squared_error: 7639.5400 - val_loss: 65553336.0000 - val_root_mean_squared_error: 8096.5015\n",
            "Epoch 233/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 60005204.0000 - root_mean_squared_error: 7746.3027 - val_loss: 56795316.0000 - val_root_mean_squared_error: 7536.2666\n",
            "Epoch 234/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 57218948.0000 - root_mean_squared_error: 7564.3208 - val_loss: 52676392.0000 - val_root_mean_squared_error: 7257.8506\n",
            "Epoch 235/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 55383836.0000 - root_mean_squared_error: 7442.0317 - val_loss: 52446872.0000 - val_root_mean_squared_error: 7242.0215\n",
            "Epoch 236/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 60632196.0000 - root_mean_squared_error: 7786.6680 - val_loss: 57141768.0000 - val_root_mean_squared_error: 7559.2173\n",
            "Epoch 237/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 59061156.0000 - root_mean_squared_error: 7685.1255 - val_loss: 53451988.0000 - val_root_mean_squared_error: 7311.0864\n",
            "Epoch 238/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 55327652.0000 - root_mean_squared_error: 7438.2559 - val_loss: 62681536.0000 - val_root_mean_squared_error: 7917.1670\n",
            "Epoch 239/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 59825388.0000 - root_mean_squared_error: 7734.6875 - val_loss: 54900132.0000 - val_root_mean_squared_error: 7409.4624\n",
            "Epoch 240/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 53198112.0000 - root_mean_squared_error: 7293.7036 - val_loss: 56680492.0000 - val_root_mean_squared_error: 7528.6445\n",
            "Epoch 241/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 57829696.0000 - root_mean_squared_error: 7604.5840 - val_loss: 54189492.0000 - val_root_mean_squared_error: 7361.3511\n",
            "Epoch 242/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 58501704.0000 - root_mean_squared_error: 7648.6406 - val_loss: 53558096.0000 - val_root_mean_squared_error: 7318.3398\n",
            "Epoch 243/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 59303844.0000 - root_mean_squared_error: 7700.8989 - val_loss: 66017340.0000 - val_root_mean_squared_error: 8125.1055\n",
            "Epoch 244/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 69595320.0000 - root_mean_squared_error: 8342.3809 - val_loss: 54825760.0000 - val_root_mean_squared_error: 7404.4419\n",
            "Epoch 245/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 61854644.0000 - root_mean_squared_error: 7864.7725 - val_loss: 56345796.0000 - val_root_mean_squared_error: 7506.3838\n",
            "Epoch 246/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 57462120.0000 - root_mean_squared_error: 7580.3774 - val_loss: 64400532.0000 - val_root_mean_squared_error: 8024.9941\n",
            "Epoch 247/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 58293956.0000 - root_mean_squared_error: 7635.0479 - val_loss: 53230968.0000 - val_root_mean_squared_error: 7295.9556\n",
            "Epoch 248/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 57255428.0000 - root_mean_squared_error: 7566.7314 - val_loss: 58148132.0000 - val_root_mean_squared_error: 7625.4922\n",
            "Epoch 249/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 55128316.0000 - root_mean_squared_error: 7424.8447 - val_loss: 51980864.0000 - val_root_mean_squared_error: 7209.7754\n",
            "Epoch 250/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 53798340.0000 - root_mean_squared_error: 7334.7354 - val_loss: 49909552.0000 - val_root_mean_squared_error: 7064.6694\n",
            "Epoch 251/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 57513456.0000 - root_mean_squared_error: 7583.7627 - val_loss: 53236284.0000 - val_root_mean_squared_error: 7296.3198\n",
            "Epoch 252/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 53344976.0000 - root_mean_squared_error: 7303.7646 - val_loss: 63851928.0000 - val_root_mean_squared_error: 7990.7402\n",
            "Epoch 253/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 55331224.0000 - root_mean_squared_error: 7438.4961 - val_loss: 55325172.0000 - val_root_mean_squared_error: 7438.0894\n",
            "Epoch 254/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 56321564.0000 - root_mean_squared_error: 7504.7695 - val_loss: 58639620.0000 - val_root_mean_squared_error: 7657.6509\n",
            "Epoch 255/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 55655916.0000 - root_mean_squared_error: 7460.2891 - val_loss: 56772756.0000 - val_root_mean_squared_error: 7534.7700\n",
            "Epoch 256/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 58050836.0000 - root_mean_squared_error: 7619.1099 - val_loss: 51048896.0000 - val_root_mean_squared_error: 7144.8511\n",
            "Epoch 257/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 53180536.0000 - root_mean_squared_error: 7292.4985 - val_loss: 54129312.0000 - val_root_mean_squared_error: 7357.2627\n",
            "Epoch 258/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 57460596.0000 - root_mean_squared_error: 7580.2769 - val_loss: 60945476.0000 - val_root_mean_squared_error: 7806.7583\n",
            "Epoch 259/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 54304012.0000 - root_mean_squared_error: 7369.1255 - val_loss: 53303120.0000 - val_root_mean_squared_error: 7300.8984\n",
            "Epoch 260/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 53499784.0000 - root_mean_squared_error: 7314.3545 - val_loss: 52101144.0000 - val_root_mean_squared_error: 7218.1123\n",
            "Epoch 261/300\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 56646196.0000 - root_mean_squared_error: 7526.3667 - val_loss: 49999548.0000 - val_root_mean_squared_error: 7071.0356\n",
            "Epoch 262/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 56499812.0000 - root_mean_squared_error: 7516.6357 - val_loss: 54410268.0000 - val_root_mean_squared_error: 7376.3315\n",
            "Epoch 263/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 52442032.0000 - root_mean_squared_error: 7241.6870 - val_loss: 57749824.0000 - val_root_mean_squared_error: 7599.3306\n",
            "Epoch 264/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 54095256.0000 - root_mean_squared_error: 7354.9478 - val_loss: 53647328.0000 - val_root_mean_squared_error: 7324.4336\n",
            "Epoch 265/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 55164812.0000 - root_mean_squared_error: 7427.3018 - val_loss: 52710264.0000 - val_root_mean_squared_error: 7260.1836\n",
            "Epoch 266/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 58165156.0000 - root_mean_squared_error: 7626.6084 - val_loss: 60165080.0000 - val_root_mean_squared_error: 7756.6152\n",
            "Epoch 267/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 54611536.0000 - root_mean_squared_error: 7389.9619 - val_loss: 52483208.0000 - val_root_mean_squared_error: 7244.5293\n",
            "Epoch 268/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 52461584.0000 - root_mean_squared_error: 7243.0371 - val_loss: 50305952.0000 - val_root_mean_squared_error: 7092.6689\n",
            "Epoch 269/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 51855216.0000 - root_mean_squared_error: 7201.0566 - val_loss: 50933860.0000 - val_root_mean_squared_error: 7136.7964\n",
            "Epoch 270/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 54065540.0000 - root_mean_squared_error: 7352.9272 - val_loss: 53740776.0000 - val_root_mean_squared_error: 7330.8101\n",
            "Epoch 271/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 56805968.0000 - root_mean_squared_error: 7536.9736 - val_loss: 59849484.0000 - val_root_mean_squared_error: 7736.2446\n",
            "Epoch 272/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 56300100.0000 - root_mean_squared_error: 7503.3394 - val_loss: 53196400.0000 - val_root_mean_squared_error: 7293.5864\n",
            "Epoch 273/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 51630952.0000 - root_mean_squared_error: 7185.4683 - val_loss: 49950528.0000 - val_root_mean_squared_error: 7067.5688\n",
            "Epoch 274/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 51223036.0000 - root_mean_squared_error: 7157.0269 - val_loss: 51607696.0000 - val_root_mean_squared_error: 7183.8496\n",
            "Epoch 275/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 55947620.0000 - root_mean_squared_error: 7479.8140 - val_loss: 52672732.0000 - val_root_mean_squared_error: 7257.5981\n",
            "Epoch 276/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 52391136.0000 - root_mean_squared_error: 7238.1724 - val_loss: 51997836.0000 - val_root_mean_squared_error: 7210.9526\n",
            "Epoch 277/300\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 53576172.0000 - root_mean_squared_error: 7319.5747 - val_loss: 65635576.0000 - val_root_mean_squared_error: 8101.5786\n",
            "Epoch 278/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 56268064.0000 - root_mean_squared_error: 7501.2041 - val_loss: 53057768.0000 - val_root_mean_squared_error: 7284.0762\n",
            "Epoch 279/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 52918728.0000 - root_mean_squared_error: 7274.5259 - val_loss: 51609684.0000 - val_root_mean_squared_error: 7183.9878\n",
            "Epoch 280/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 54040772.0000 - root_mean_squared_error: 7351.2427 - val_loss: 52502084.0000 - val_root_mean_squared_error: 7245.8320\n",
            "Epoch 281/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 54176356.0000 - root_mean_squared_error: 7360.4590 - val_loss: 53194680.0000 - val_root_mean_squared_error: 7293.4683\n",
            "Epoch 282/300\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 52088864.0000 - root_mean_squared_error: 7217.2617 - val_loss: 50767504.0000 - val_root_mean_squared_error: 7125.1318\n",
            "Epoch 283/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 50836848.0000 - root_mean_squared_error: 7129.9966 - val_loss: 48289020.0000 - val_root_mean_squared_error: 6949.0303\n",
            "Epoch 284/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 51785916.0000 - root_mean_squared_error: 7196.2432 - val_loss: 50426988.0000 - val_root_mean_squared_error: 7101.1963\n",
            "Epoch 285/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 53127988.0000 - root_mean_squared_error: 7288.8950 - val_loss: 55310144.0000 - val_root_mean_squared_error: 7437.0791\n",
            "Epoch 286/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 56086164.0000 - root_mean_squared_error: 7489.0698 - val_loss: 51814608.0000 - val_root_mean_squared_error: 7198.2363\n",
            "Epoch 287/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 53115008.0000 - root_mean_squared_error: 7288.0044 - val_loss: 56791364.0000 - val_root_mean_squared_error: 7536.0044\n",
            "Epoch 288/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 50768216.0000 - root_mean_squared_error: 7125.1816 - val_loss: 50920704.0000 - val_root_mean_squared_error: 7135.8745\n",
            "Epoch 289/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 54702160.0000 - root_mean_squared_error: 7396.0908 - val_loss: 59837664.0000 - val_root_mean_squared_error: 7735.4810\n",
            "Epoch 290/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 53004664.0000 - root_mean_squared_error: 7280.4302 - val_loss: 50939900.0000 - val_root_mean_squared_error: 7137.2192\n",
            "Epoch 291/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 52795148.0000 - root_mean_squared_error: 7266.0269 - val_loss: 59872872.0000 - val_root_mean_squared_error: 7737.7563\n",
            "Epoch 292/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 56701528.0000 - root_mean_squared_error: 7530.0415 - val_loss: 53508496.0000 - val_root_mean_squared_error: 7314.9502\n",
            "Epoch 293/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 51458340.0000 - root_mean_squared_error: 7173.4468 - val_loss: 54148408.0000 - val_root_mean_squared_error: 7358.5601\n",
            "Epoch 294/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 50360440.0000 - root_mean_squared_error: 7096.5088 - val_loss: 50456028.0000 - val_root_mean_squared_error: 7103.2407\n",
            "Epoch 295/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 52945540.0000 - root_mean_squared_error: 7276.3687 - val_loss: 48710948.0000 - val_root_mean_squared_error: 6979.3228\n",
            "Epoch 296/300\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 53363584.0000 - root_mean_squared_error: 7305.0381 - val_loss: 53319184.0000 - val_root_mean_squared_error: 7301.9985\n",
            "Epoch 297/300\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 53805032.0000 - root_mean_squared_error: 7335.1914 - val_loss: 51334584.0000 - val_root_mean_squared_error: 7164.8159\n",
            "Epoch 298/300\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 51758564.0000 - root_mean_squared_error: 7194.3423 - val_loss: 47663176.0000 - val_root_mean_squared_error: 6903.8521\n",
            "Epoch 299/300\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 50254848.0000 - root_mean_squared_error: 7089.0654 - val_loss: 47387884.0000 - val_root_mean_squared_error: 6883.8857\n",
            "Epoch 300/300\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 53693696.0000 - root_mean_squared_error: 7327.5981 - val_loss: 48990260.0000 - val_root_mean_squared_error: 6999.3042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_train_rmse = history.history[\"root_mean_squared_error\"]\n",
        "hist_test_rmse = history.history[\"val_root_mean_squared_error\"]\n",
        "\n",
        "print(hist_test_rmse)\n",
        "\n",
        "# Create a line chart with two lines using Plotly Express\n",
        "fig = px.line()\n",
        "fig.add_scatter(x=(0,len(hist_train_rmse)), y=hist_train_rmse, mode='lines', name='Train')\n",
        "fig.add_scatter(x=(0,len(hist_test_rmse)), y=hist_test_rmse, mode='lines', name='Test')\n",
        "\n",
        "# Set chart title and axis labels\n",
        "fig.update_layout(\n",
        "    title='Line Chart with Two Lines',\n",
        "    xaxis_title='X Axis Label',\n",
        "    yaxis_title='Y Axis Label'\n",
        ")\n",
        "\n",
        "# Show the chart\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "RhbEPgSPsXCy",
        "outputId": "defd3248-bf9f-40cc-a751-ac27a0c5c14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "id": "RhbEPgSPsXCy",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11445.8203125, 10572.05078125, 10485.408203125, 10500.7705078125, 10435.2421875, 10524.412109375, 10376.26171875, 10334.83203125, 10335.70703125, 10488.2197265625, 10258.498046875, 10259.9462890625, 10172.224609375, 10122.748046875, 10067.9599609375, 10207.80859375, 9911.330078125, 10317.255859375, 9797.5234375, 9689.806640625, 9749.7236328125, 10660.3564453125, 9540.7060546875, 10396.0419921875, 10074.9638671875, 9472.703125, 9607.1064453125, 9351.7587890625, 9325.599609375, 9589.46484375, 9589.8154296875, 9176.8818359375, 9104.8916015625, 9082.0283203125, 9076.654296875, 9288.3740234375, 9035.00390625, 8948.8330078125, 9002.4794921875, 9141.908203125, 8883.861328125, 8972.2822265625, 9012.7890625, 8782.0576171875, 8826.16796875, 8958.0068359375, 8725.935546875, 9313.2431640625, 8693.0078125, 8716.7724609375, 8820.830078125, 9282.34765625, 8628.9765625, 8577.576171875, 8583.0107421875, 8519.533203125, 8473.9033203125, 8493.2548828125, 8456.986328125, 8645.5068359375, 8595.8037109375, 8664.9423828125, 8471.544921875, 8448.3251953125, 8703.79296875, 8610.1884765625, 8516.6162109375, 8284.0966796875, 8268.7236328125, 8374.9033203125, 8774.890625, 8349.830078125, 8241.8388671875, 8335.1318359375, 8284.642578125, 8667.853515625, 8641.6875, 8276.552734375, 8212.9765625, 8206.865234375, 8389.916015625, 8229.130859375, 8185.56005859375, 8146.01220703125, 8787.451171875, 8097.115234375, 8206.6201171875, 8366.7919921875, 8405.05859375, 8118.42578125, 8365.59765625, 8330.52734375, 8061.82177734375, 8485.2353515625, 8112.091796875, 8111.45361328125, 8192.314453125, 8107.763671875, 8253.96875, 8171.330078125, 8002.03369140625, 8231.435546875, 8717.2685546875, 8044.49365234375, 7997.98583984375, 7990.6650390625, 9194.6103515625, 8053.25, 8096.490234375, 7954.03076171875, 8689.880859375, 8021.7119140625, 7940.02587890625, 7925.212890625, 8006.0771484375, 8094.25732421875, 8243.396484375, 7898.90869140625, 8424.6962890625, 8002.47216796875, 8587.0546875, 8873.345703125, 7982.3974609375, 7999.76318359375, 9017.4384765625, 8066.10693359375, 8249.3974609375, 8120.5908203125, 7891.21630859375, 7917.3046875, 7876.05810546875, 7862.84033203125, 7950.32421875, 7989.7158203125, 7800.43896484375, 8350.017578125, 8076.267578125, 8076.54931640625, 8845.484375, 7863.5615234375, 7845.94677734375, 7913.5185546875, 7979.642578125, 7912.3154296875, 7783.17529296875, 7997.60498046875, 7861.27197265625, 7945.244140625, 7823.9111328125, 8150.2373046875, 7705.384765625, 9253.365234375, 8311.265625, 7730.4677734375, 8431.55078125, 7685.900390625, 7897.76318359375, 7761.76904296875, 7653.0830078125, 8720.73046875, 7674.4033203125, 7689.13427734375, 7688.56103515625, 7784.94287109375, 8075.41845703125, 7769.068359375, 8585.541015625, 7662.48583984375, 7673.2548828125, 8169.86572265625, 8410.572265625, 8038.15087890625, 7855.6025390625, 7680.27490234375, 7614.779296875, 7729.728515625, 8234.923828125, 7540.291015625, 7901.5400390625, 7587.17138671875, 7666.65234375, 7661.52392578125, 7906.22021484375, 7673.8369140625, 7559.88623046875, 8151.70654296875, 7787.1494140625, 7725.85302734375, 8138.79248046875, 7643.974609375, 7574.15673828125, 7604.05322265625, 7477.89501953125, 7621.72509765625, 7643.78662109375, 7586.328125, 7808.43408203125, 7690.98046875, 7949.49267578125, 8124.41552734375, 7833.10400390625, 7560.64208984375, 7368.3212890625, 7448.36279296875, 7816.47119140625, 7762.1357421875, 7779.154296875, 7382.27783203125, 9035.755859375, 7715.21142578125, 7415.85205078125, 7568.03759765625, 7715.228515625, 7773.970703125, 7444.96240234375, 7615.59423828125, 7678.83642578125, 7925.79443359375, 7478.43603515625, 7414.4990234375, 7536.400390625, 7548.2724609375, 7755.94921875, 7465.365234375, 7513.13818359375, 7545.08251953125, 7374.43701171875, 8128.72216796875, 7539.5673828125, 7334.4345703125, 7473.51171875, 8096.50146484375, 7536.2666015625, 7257.8505859375, 7242.021484375, 7559.21728515625, 7311.08642578125, 7917.1669921875, 7409.46240234375, 7528.64453125, 7361.35107421875, 7318.33984375, 8125.10546875, 7404.44189453125, 7506.3837890625, 8024.994140625, 7295.95556640625, 7625.4921875, 7209.775390625, 7064.66943359375, 7296.31982421875, 7990.740234375, 7438.08935546875, 7657.65087890625, 7534.77001953125, 7144.85107421875, 7357.2626953125, 7806.75830078125, 7300.8984375, 7218.1123046875, 7071.03564453125, 7376.33154296875, 7599.33056640625, 7324.43359375, 7260.18359375, 7756.615234375, 7244.529296875, 7092.6689453125, 7136.79638671875, 7330.81005859375, 7736.24462890625, 7293.58642578125, 7067.56884765625, 7183.849609375, 7257.59814453125, 7210.95263671875, 8101.57861328125, 7284.076171875, 7183.98779296875, 7245.83203125, 7293.46826171875, 7125.1318359375, 6949.0302734375, 7101.1962890625, 7437.0791015625, 7198.236328125, 7536.00439453125, 7135.87451171875, 7735.48095703125, 7137.21923828125, 7737.75634765625, 7314.9501953125, 7358.56005859375, 7103.24072265625, 6979.32275390625, 7301.99853515625, 7164.81591796875, 6903.85205078125, 6883.8857421875, 6999.30419921875]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"87ae06e5-2202-4aa3-b9dd-b30e93ba01cd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"87ae06e5-2202-4aa3-b9dd-b30e93ba01cd\")) {                    Plotly.newPlot(                        \"87ae06e5-2202-4aa3-b9dd-b30e93ba01cd\",                        [{\"hovertemplate\":\"<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Train\",\"x\":[0,300],\"y\":[21839.474609375,11302.28125,11158.08203125,11226.22265625,11094.94921875,11089.60546875,11065.35546875,11087.263671875,11023.3603515625,11057.5732421875,11031.5615234375,10981.8740234375,10913.5322265625,10833.98046875,10780.6044921875,10815.7177734375,10681.5546875,10907.0810546875,10636.3779296875,10511.8544921875,10403.73828125,10397.15625,10571.9169921875,10543.5146484375,10418.7041015625,10310.5634765625,10130.2138671875,10133.921875,10078.8515625,10042.5185546875,10194.6962890625,9901.466796875,9854.7998046875,9823.240234375,9944.2353515625,9795.541015625,9795.0166015625,9767.234375,9633.5546875,9815.8046875,9712.1533203125,9477.220703125,9838.994140625,9553.765625,9444.9765625,9443.501953125,9340.521484375,9325.3955078125,9306.0283203125,9390.5966796875,9405.94140625,9251.705078125,9281.6708984375,9159.2568359375,9172.345703125,9182.890625,9081.533203125,9046.421875,9039.09765625,9194.7861328125,9047.4921875,9282.060546875,9131.931640625,8953.8291015625,8885.974609375,8864.3466796875,9044.52734375,9086.3994140625,8838.083984375,8850.419921875,8846.2041015625,8961.14453125,8788.9384765625,8815.947265625,9150.01953125,8838.63671875,8719.0849609375,8875.9384765625,8692.2451171875,8722.5615234375,8611.15234375,8683.958984375,8718.005859375,8690.13671875,8684.9091796875,8653.3974609375,8592.001953125,8732.9287109375,8545.5537109375,8594.791015625,8753.8212890625,8733.966796875,8574.7041015625,8662.140625,8514.08203125,8575.732421875,8504.48828125,8617.8203125,8523.4111328125,8566.9306640625,8552.53125,8662.9091796875,8550.29296875,8521.4560546875,8515.9931640625,8473.7060546875,8510.166015625,8558.70703125,8415.1005859375,8486.1796875,8719.0390625,8605.2392578125,8379.912109375,8451.033203125,8373.693359375,8420.3125,8346.5703125,8523.91015625,8656.7763671875,8371.62890625,8380.6083984375,8421.08203125,8584.1083984375,8274.65234375,8381.8701171875,8426.5400390625,8349.275390625,8537.884765625,8497.2900390625,8302.2080078125,8416.8583984375,8296.736328125,8277.75390625,8352.8271484375,8417.7001953125,8215.0107421875,8233.8017578125,8284.017578125,8322.3447265625,8454.91015625,8337.7197265625,8197.845703125,8440.177734375,8279.01953125,8348.8828125,8245.9599609375,8274.22265625,8178.29296875,8155.1083984375,8230.97265625,8156.93017578125,8383.4130859375,8336.388671875,8255.4287109375,8177.017578125,8134.03173828125,8263.5009765625,8169.32421875,8136.6513671875,8264.0205078125,8226.0458984375,8062.08251953125,8086.2431640625,8081.62060546875,8049.68798828125,8090.46923828125,8109.14306640625,8196.0625,8057.53466796875,8077.3134765625,8299.5,8081.86474609375,8006.08349609375,8246.8359375,8213.8388671875,7895.68701171875,7990.1005859375,8215.05859375,7974.341796875,8033.69140625,8445.50390625,7927.17041015625,8040.783203125,7905.99609375,7934.13037109375,7894.916015625,8010.16015625,7972.63916015625,8171.7255859375,8106.57470703125,7962.22216796875,7963.97119140625,7963.419921875,7885.6357421875,7861.5498046875,7905.658203125,7832.7705078125,7898.84521484375,7833.5458984375,7933.42041015625,8021.54638671875,8209.0791015625,7794.88623046875,7757.6318359375,7765.140625,7889.74853515625,7821.26220703125,8056.009765625,7740.77880859375,8080.59228515625,7649.5146484375,7820.99560546875,7768.69970703125,7756.5341796875,7671.6650390625,7626.630859375,7803.7744140625,7691.71826171875,7860.8974609375,7828.7119140625,7649.1171875,7877.4228515625,7681.81640625,7585.26953125,7638.0576171875,7687.1484375,7441.859375,7665.45703125,7747.98681640625,7698.7841796875,7663.1953125,7639.5400390625,7746.302734375,7564.32080078125,7442.03173828125,7786.66796875,7685.12548828125,7438.255859375,7734.6875,7293.70361328125,7604.583984375,7648.640625,7700.89892578125,8342.380859375,7864.7724609375,7580.37744140625,7635.0478515625,7566.7314453125,7424.8447265625,7334.7353515625,7583.7626953125,7303.7646484375,7438.49609375,7504.76953125,7460.2890625,7619.10986328125,7292.49853515625,7580.27685546875,7369.12548828125,7314.3544921875,7526.36669921875,7516.6357421875,7241.68701171875,7354.94775390625,7427.3017578125,7626.6083984375,7389.9619140625,7243.037109375,7201.056640625,7352.92724609375,7536.9736328125,7503.33935546875,7185.46826171875,7157.02685546875,7479.81396484375,7238.17236328125,7319.57470703125,7501.2041015625,7274.52587890625,7351.24267578125,7360.458984375,7217.26171875,7129.99658203125,7196.2431640625,7288.89501953125,7489.06982421875,7288.00439453125,7125.181640625,7396.0908203125,7280.43017578125,7266.02685546875,7530.04150390625,7173.44677734375,7096.5087890625,7276.36865234375,7305.0380859375,7335.19140625,7194.34228515625,7089.0654296875,7327.59814453125],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test\",\"x\":[0,300],\"y\":[11445.8203125,10572.05078125,10485.408203125,10500.7705078125,10435.2421875,10524.412109375,10376.26171875,10334.83203125,10335.70703125,10488.2197265625,10258.498046875,10259.9462890625,10172.224609375,10122.748046875,10067.9599609375,10207.80859375,9911.330078125,10317.255859375,9797.5234375,9689.806640625,9749.7236328125,10660.3564453125,9540.7060546875,10396.0419921875,10074.9638671875,9472.703125,9607.1064453125,9351.7587890625,9325.599609375,9589.46484375,9589.8154296875,9176.8818359375,9104.8916015625,9082.0283203125,9076.654296875,9288.3740234375,9035.00390625,8948.8330078125,9002.4794921875,9141.908203125,8883.861328125,8972.2822265625,9012.7890625,8782.0576171875,8826.16796875,8958.0068359375,8725.935546875,9313.2431640625,8693.0078125,8716.7724609375,8820.830078125,9282.34765625,8628.9765625,8577.576171875,8583.0107421875,8519.533203125,8473.9033203125,8493.2548828125,8456.986328125,8645.5068359375,8595.8037109375,8664.9423828125,8471.544921875,8448.3251953125,8703.79296875,8610.1884765625,8516.6162109375,8284.0966796875,8268.7236328125,8374.9033203125,8774.890625,8349.830078125,8241.8388671875,8335.1318359375,8284.642578125,8667.853515625,8641.6875,8276.552734375,8212.9765625,8206.865234375,8389.916015625,8229.130859375,8185.56005859375,8146.01220703125,8787.451171875,8097.115234375,8206.6201171875,8366.7919921875,8405.05859375,8118.42578125,8365.59765625,8330.52734375,8061.82177734375,8485.2353515625,8112.091796875,8111.45361328125,8192.314453125,8107.763671875,8253.96875,8171.330078125,8002.03369140625,8231.435546875,8717.2685546875,8044.49365234375,7997.98583984375,7990.6650390625,9194.6103515625,8053.25,8096.490234375,7954.03076171875,8689.880859375,8021.7119140625,7940.02587890625,7925.212890625,8006.0771484375,8094.25732421875,8243.396484375,7898.90869140625,8424.6962890625,8002.47216796875,8587.0546875,8873.345703125,7982.3974609375,7999.76318359375,9017.4384765625,8066.10693359375,8249.3974609375,8120.5908203125,7891.21630859375,7917.3046875,7876.05810546875,7862.84033203125,7950.32421875,7989.7158203125,7800.43896484375,8350.017578125,8076.267578125,8076.54931640625,8845.484375,7863.5615234375,7845.94677734375,7913.5185546875,7979.642578125,7912.3154296875,7783.17529296875,7997.60498046875,7861.27197265625,7945.244140625,7823.9111328125,8150.2373046875,7705.384765625,9253.365234375,8311.265625,7730.4677734375,8431.55078125,7685.900390625,7897.76318359375,7761.76904296875,7653.0830078125,8720.73046875,7674.4033203125,7689.13427734375,7688.56103515625,7784.94287109375,8075.41845703125,7769.068359375,8585.541015625,7662.48583984375,7673.2548828125,8169.86572265625,8410.572265625,8038.15087890625,7855.6025390625,7680.27490234375,7614.779296875,7729.728515625,8234.923828125,7540.291015625,7901.5400390625,7587.17138671875,7666.65234375,7661.52392578125,7906.22021484375,7673.8369140625,7559.88623046875,8151.70654296875,7787.1494140625,7725.85302734375,8138.79248046875,7643.974609375,7574.15673828125,7604.05322265625,7477.89501953125,7621.72509765625,7643.78662109375,7586.328125,7808.43408203125,7690.98046875,7949.49267578125,8124.41552734375,7833.10400390625,7560.64208984375,7368.3212890625,7448.36279296875,7816.47119140625,7762.1357421875,7779.154296875,7382.27783203125,9035.755859375,7715.21142578125,7415.85205078125,7568.03759765625,7715.228515625,7773.970703125,7444.96240234375,7615.59423828125,7678.83642578125,7925.79443359375,7478.43603515625,7414.4990234375,7536.400390625,7548.2724609375,7755.94921875,7465.365234375,7513.13818359375,7545.08251953125,7374.43701171875,8128.72216796875,7539.5673828125,7334.4345703125,7473.51171875,8096.50146484375,7536.2666015625,7257.8505859375,7242.021484375,7559.21728515625,7311.08642578125,7917.1669921875,7409.46240234375,7528.64453125,7361.35107421875,7318.33984375,8125.10546875,7404.44189453125,7506.3837890625,8024.994140625,7295.95556640625,7625.4921875,7209.775390625,7064.66943359375,7296.31982421875,7990.740234375,7438.08935546875,7657.65087890625,7534.77001953125,7144.85107421875,7357.2626953125,7806.75830078125,7300.8984375,7218.1123046875,7071.03564453125,7376.33154296875,7599.33056640625,7324.43359375,7260.18359375,7756.615234375,7244.529296875,7092.6689453125,7136.79638671875,7330.81005859375,7736.24462890625,7293.58642578125,7067.56884765625,7183.849609375,7257.59814453125,7210.95263671875,8101.57861328125,7284.076171875,7183.98779296875,7245.83203125,7293.46826171875,7125.1318359375,6949.0302734375,7101.1962890625,7437.0791015625,7198.236328125,7536.00439453125,7135.87451171875,7735.48095703125,7137.21923828125,7737.75634765625,7314.9501953125,7358.56005859375,7103.24072265625,6979.32275390625,7301.99853515625,7164.81591796875,6903.85205078125,6883.8857421875,6999.30419921875],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('87ae06e5-2202-4aa3-b9dd-b30e93ba01cd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_train = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, preds_train))\n",
        "print(\"Trai RMSE: %f\" % (rmse_train))\n",
        "\n",
        "preds_test = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, preds_test))\n",
        "print(\"Test RMSE: %f\" % (rmse_test))"
      ],
      "metadata": {
        "id": "qg2TMtxJUzVm",
        "outputId": "9f21249b-7aaa-49ce-9ef8-201200ce90ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qg2TMtxJUzVm",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 0s 2ms/step\n",
            "Trai RMSE: 6914.520266\n",
            "23/23 [==============================] - 0s 2ms/step\n",
            "Test RMSE: 6999.304796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5.4.\"></a>\n",
        "## 5.4. Recurrent Neural Network\n",
        "[Content](#content)"
      ],
      "metadata": {
        "id": "35YvxR1B1tcY"
      },
      "id": "35YvxR1B1tcY"
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_transformed_date_lagged.isna().sum())\n",
        "#print(X_train.shape[0], X_train.shape[1])\n",
        "#print(type(X_train))"
      ],
      "metadata": {
        "id": "lroAAmcsll9_",
        "outputId": "deb0b430-5a0d-49fc-9801-2411151e14d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lroAAmcsll9_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year                                 0\n",
            "Month                                0\n",
            "Day                                  0\n",
            "Weekday                              0\n",
            "GrafMoltkeStrEast                    0\n",
            "GrafMoltkeStrWest                    0\n",
            "HastedterBrStr                       0\n",
            "LangemarckStrEast                    0\n",
            "LangemarckStrWest                    0\n",
            "Osterdeich                           0\n",
            "RadwegKleineWeser                    0\n",
            "SchwachhauserRing                    0\n",
            "WachmannStrAusSouth                  0\n",
            "WachmannStrEinNorth                  0\n",
            "WilhelmKaisenBrEast                  0\n",
            "WilhelmKaisenBrWest                  0\n",
            "Total                                0\n",
            "tavg                                 0\n",
            "tmin                                 0\n",
            "tmax                                 0\n",
            "prcp                                 0\n",
            "snow                                 0\n",
            "wdir                                 0\n",
            "wspd                                 0\n",
            "wpgt                                 0\n",
            "pres                                 0\n",
            "tsun                                 0\n",
            "Holiday_1. Weihnachtsfeiertag        0\n",
            "Holiday_2. Weihnachtsfeiertag        0\n",
            "Holiday_Christi Himmelfahrt          0\n",
            "Holiday_Karfreitag                   0\n",
            "Holiday_Neujahr                      0\n",
            "Holiday_Ostermontag                  0\n",
            "Holiday_Pfingstmontag                0\n",
            "Holiday_Reformationstag              0\n",
            "Holiday_Tag der Arbeit               0\n",
            "Holiday_Tag der Deutschen Einheit    0\n",
            "Vacation_Herbstferien                0\n",
            "Vacation_Osterferien                 0\n",
            "Vacation_Pfingstferien               0\n",
            "Vacation_Sommerferien                0\n",
            "Vacation_Weihnachtsferien            0\n",
            "Vacation_Winterferien                0\n",
            "prev_Total_1                         1\n",
            "prev_Total_2                         2\n",
            "prev_Total_3                         3\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into a pandas dataframe\n",
        "data = df_transformed_date\n",
        "\n",
        "# Define the features and target\n",
        "# Higly correlated features have been removed (tavg, tmax, wpgt)\n",
        "features = ['Year', 'Month', 'Day', 'Weekday',\n",
        "       'tmax', 'prcp', 'snow', 'wspd', 'pres', 'tsun',\n",
        "       'Holiday_1. Weihnachtsfeiertag', 'Holiday_2. Weihnachtsfeiertag',\n",
        "       'Holiday_Christi Himmelfahrt', 'Holiday_Karfreitag', 'Holiday_Neujahr',\n",
        "       'Holiday_Ostermontag', 'Holiday_Pfingstmontag',\n",
        "       'Holiday_Reformationstag', 'Holiday_Tag der Arbeit',\n",
        "       'Holiday_Tag der Deutschen Einheit', 'Vacation_Herbstferien',\n",
        "       'Vacation_Osterferien', 'Vacation_Pfingstferien',\n",
        "       'Vacation_Sommerferien', 'Vacation_Weihnachtsferien',\n",
        "       'Vacation_Winterferien']\n",
        "\n",
        "target = 'Total'\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[features], data[target], \n",
        "                                                    test_size=0.2, shuffle=True, random_state=0)"
      ],
      "metadata": {
        "id": "J7cPlQdTzEmQ"
      },
      "id": "J7cPlQdTzEmQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined and contain the appropriate data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_samples = X_train.shape[0]\n",
        "# Build the LSTM model\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=256, input_shape=(1, X_train.shape[1]), activation='relu'))\n",
        "# Add a dense output layer with a single unit (for regression) and no activation function\n",
        "model.add(Dense(units=1))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Build the LSTM model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(256, activation='relu'),\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(128, activation='relu'),\n",
        "    # Add another LSTM layer with 128 units and ReLU activation\n",
        "    tf.keras.layers.LSTM(64, activation='relu'),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "X_train_3d = np.reshape(X_train.to_numpy(), (num_samples, 1, X_train.shape[1]))  # Fix variable name\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_3d, y_train, epochs=100, batch_size=64, verbose=1)"
      ],
      "metadata": {
        "id": "sOTf5esj1181",
        "outputId": "81b0f9a1-eb48-4888-a3e9-f53c33c2d6e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "id": "sOTf5esj1181",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-fb3438d48593>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_38' (type Sequential).\n    \n    Input 0 of layer \"lstm_50\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 256)\n    \n    Call arguments received by layer 'sequential_38' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1, 26), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "#X_test_3d = np.reshape(X_test.to_numpy(), (X_test.shape[0], 1, X_test.shape[1]))  # Reshape X_test\n",
        "\n",
        "num_samples = X_test.shape[0]\n",
        "X_test_3d = np.reshape(X_test.to_numpy(), (num_samples, 1, X_test.shape[1]))  # Fix variable name\n",
        "preds = model.predict(X_test_3d)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, np.reshape(preds, (y_test.shape[0]))))\n",
        "print(\"RMSE: %f\" % (rmse))\n"
      ],
      "metadata": {
        "id": "VKXsUKtg3Hf7",
        "outputId": "9e164cf5-c57d-4099-f96c-fc87a762796c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VKXsUKtg3Hf7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 6ms/step\n",
            "2018-03-11    26957.0\n",
            "2014-07-27    37410.0\n",
            "2016-09-30    39593.0\n",
            "2022-06-05    50288.0\n",
            "2017-09-29    41285.0\n",
            "               ...   \n",
            "2013-08-06    37690.0\n",
            "2014-11-02    29683.0\n",
            "2020-06-27    33080.0\n",
            "2016-08-31    53149.0\n",
            "2022-01-16    12165.0\n",
            "Name: Total, Length: 731, dtype: float64\n",
            "[30535.756 37923.53  32049.592 36079.492 31525.645 28276.818 31182.781\n",
            " 28032.14  26946.822 35099.41  40275.06  31049.348 38569.285 31857.996\n",
            " 30947.023 28566.012 28895.145 29982.74  36054.23  28999.047 29830.938\n",
            " 30775.758 27452.115 31243.29  27236.404 27673.469 29084.553 30560.8\n",
            " 30556.438 34519.117 30605.236 31264.998 33066.836 20967.12  37602.754\n",
            " 32578.305 39709.023 29811.994 28410.668 33195.67  27754.33  31554.383\n",
            " 27051.059 28399.223 35825.227 27933.12  39415.55  35235.44  35060.434\n",
            " 32877.6   31883.713 31583.65  28782.07  34868.4   32103.193 28370.572\n",
            " 26299.674 29966.117 36611.188 40976.992 27086.205 35797.164 28439.223\n",
            " 33622.242 28705.676 38175.42  34417.445 28957.5   36308.617 28908.55\n",
            " 37213.16  36347.03  34534.062 34639.863 35874.066 27784.098 35697.617\n",
            " 34003.117 28966.828 29811.201 39181.43  37208.74  29791.184 34617.906\n",
            " 42703.395 30691.934 30614.492 40071.594 31881.691 27934.062 28284.287\n",
            " 28051.7   36985.902 29192.484 27608.682 28789.975 26355.484 27787.441\n",
            " 29981.924 31186.365 28301.477 28304.15  38885.28  36011.42  31960.99\n",
            " 38749.53  38430.297 29760.828 30432.652 30257.871 32469.188 34066.39\n",
            " 30997.773 31536.41  28273.12  32349.531 30816.842 33717.098 33554.9\n",
            " 34276.82  39291.336 33380.445 32863.555 30041.027 32035.176 36708.824\n",
            " 30301.84  34444.28  30674.49  29149.008 31354.275 30204.746 31686.18\n",
            " 29207.268 33989.16  31325.043 39509.79  36273.504 31471.459 40020.6\n",
            " 41277.42  32089.291 24329.695 27392.574 36653.62  34557.67  30227.469\n",
            " 33615.58  34608.184 29098.312 32880.23  28926.908 32157.129 37616.05\n",
            " 27961.137 26307.066 30602.525 30377.96  27462.43  32323.93  31711.664\n",
            " 33492.402 28600.62  27415.158 36909.266 29957.19  32680.48  27420.258\n",
            " 34235.63  38565.977 29908.133 37271.406 28105.71  30903.229 33011.914\n",
            " 36409.562 28768.932 29186.928 39983.547 33785.54  40970.984 36229.52\n",
            " 28698.73  26572.406 31259.195 38083.176 37181.785 36186.29  32611.484\n",
            " 28891.117 41074.977 29592.809 30956.902 29925.838 30389.666 35291.543\n",
            " 27262.867 34318.945 31685.656 33198.883 40358.77  30349.998 28376.86\n",
            " 31006.66  27133.348 29969.465 41086.305 35752.65  33420.82  40327.094\n",
            " 29608.707 32939.836 29481.06  33391.74  31294.055 29367.46  29798.877\n",
            " 37192.773 27496.613 31836.113 29794.701 36261.11  27693.982 36049.74\n",
            " 25118.715 26600.906 34175.516 33649.445 31414.486 30539.434 38395.35\n",
            " 30772.27  41311.33  35912.914 32895.617 30533.494 33835.945 36771.33\n",
            " 34480.727 38675.96  30103.457 33579.766 40636.58  29061.283 27798.26\n",
            " 31739.969 33766.81  33735.445 28814.553 31208.902 32801.484 31415.56\n",
            " 27165.734 28664.709 32880.25  31479.459 34949.44  36264.184 35625.934\n",
            " 29230.758 32458.545 38007.55  29021.336 28242.297 37848.254 37525.438\n",
            " 42074.062 26553.861 39471.312 27804.781 29231.63  27608.887 40036.418\n",
            " 28594.725 32269.191 28240.336 32681.455 33789.19  41092.42  28425.816\n",
            " 28671.113 31419.41  37302.883 36711.89  30868.258 32372.223 30138.152\n",
            " 32457.68  38424.273 34162.3   30955.832 42433.414 25662.822 37814.1\n",
            " 28679.096 32276.273 33771.04  30551.535 28284.578 34561.97  33974.203\n",
            " 27989.67  28785.055 28310.746 41729.945 30032.605 27059.402 35783.43\n",
            " 27916.266 33571.117 29198.871 26820.531 36082.766 36386.96  33544.926\n",
            " 32334.777 30095.615 29765.154 40148.85  29122.496 37977.645 37172.023\n",
            " 35709.605 28241.94  29983.469 39158.055 28481.176 34435.723 31850.875\n",
            " 30427.188 27808.861 35191.312 30108.621 36841.12  33792.17  27250.586\n",
            " 30393.146 41835.01  37661.984 32244.77  34861.438 29055.027 35179.688\n",
            " 28529.32  37502.93  35146.977 29809.055 35348.03  35349.242 35044.953\n",
            " 28649.373 25464.87  26799.586 33202.547 38547.367 29964.395 29271.268\n",
            " 32412.566 34028.418 30448.314 36658.008 37616.61  38865.184 26837.984\n",
            " 30493.35  31135.135 34944.273 29059.062 32612.664 33182.508 36021.21\n",
            " 37659.92  29174.68  27425.734 24425.39  40619.695 29851.543 27222.896\n",
            " 32389.945 32818.61  40478.37  28538.848 32621.975 38760.734 29865.791\n",
            " 29118.438 22734.77  35608.195 39240.777 28204.57  37494.45  27795.809\n",
            " 31124.29  28125.379 30668.83  36780.88  35092.24  27257.584 32762.92\n",
            " 29191.695 30332.67  34698.664 28657.197 32730.62  29361.957 30036.146\n",
            " 36334.027 33118.71  33675.35  34061.305 38280.633 36038.43  32569.033\n",
            " 30402.904 26906.602 30097.39  30153.75  30081.236 36243.273 27097.748\n",
            " 26627.457 41145.016 29065.584 32892.89  27543.842 33744.742 27837.824\n",
            " 29577.424 34806.492 28676.033 29073.951 31024.906 35550.844 26740.033\n",
            " 28744.7   28681.209 31693.246 34573.293 28904.94  29304.68  24170.795\n",
            " 32939.53  30251.47  30783.781 35420.594 38562.535 28807.996 31215.178\n",
            " 34828.586 33485.7   32388.658 25743.254 36113.957 32207.105 37512.91\n",
            " 41754.27  38940.645 30649.145 28809.062 32093.82  29181.783 35446.85\n",
            " 29480.178 31390.502 29172.719 29525.453 33838.9   28600.994 26913.957\n",
            " 30962.293 35262.926 27974.543 29188.564 29932.682 28751.998 36425.914\n",
            " 27765.738 34579.836 31114.379 35488.043 32468.658 37091.543 31804.445\n",
            " 28156.662 28739.523 27238.691 29269.959 29122.938 30934.553 30105.598\n",
            " 27763.31  32968.617 39271.58  34228.047 32043.846 31021.697 36324.773\n",
            " 29090.5   28005.98  35347.39  27314.217 33510.863 34383.508 31989.314\n",
            " 33463.023 26554.512 35642.41  29382.18  37303.53  34534.277 32841.11\n",
            " 27859.672 29799.521 36312.027 39016.92  27766.727 29873.291 29425.498\n",
            " 28755.35  37039.78  28871.238 37739.527 27454.805 32537.203 40147.04\n",
            " 26762.992 29567.355 29248.854 40344.89  28812.508 26026.979 29730.186\n",
            " 27668.277 38192.625 33323.67  32599.21  35461.97  28219.246 37233.184\n",
            " 35047.914 26165.969 32694.93  38129.945 30735.66  32898.11  36779.96\n",
            " 27590.143 37194.258 37617.527 31590.418 35008.133 28993.033 28986.658\n",
            " 29339.412 28805.234 33672.43  40084.5   32237.555 30849.951 33604.5\n",
            " 27592.473 27767.77  29264.3   30782.688 34078.98  40917.883 40331.53\n",
            " 38562.22  27253.578 42213.414 30222.191 29297.605 28220.545 36777.656\n",
            " 37803.168 30457.24  29461.035 35844.703 26979.201 35235.31  28317.184\n",
            " 28099.363 35160.797 17938.512 31606.816 31306.428 27698.33  33872.336\n",
            " 36222.793 31134.57  27105.273 29003.256 29067.514 28795.828 28361.59\n",
            " 29271.955 31125.57  30169.227 36174.95  27300.453 32128.818 42471.688\n",
            " 29884.555 33774.57  40088.14  31469.32  28652.695 37584.008 40613.94\n",
            " 39088.273 28776.893 30917.832 28132.102 33867.203 29434.54  33241.953\n",
            " 27689.957 34596.754 31480.986 33311.766 31321.633 32374.02  28735.398\n",
            " 30912.723 30306.855 30024.146 34695.168 33773.234 27155.594 28942.36\n",
            " 28549.752 32962.67  30988.277 31669.574 32731.906 26505.414 36714.867\n",
            " 32027.564 28014.104 27388.172 29059.31  38950.465 28223.016 36537.156\n",
            " 34646.85  33619.633 27253.11  33640.105 27835.066 28865.283 31741.336\n",
            " 29607.709 31793.18  29821.254 30169.857 29155.113 33091.344 28840.87\n",
            " 30701.451 38699.695 34778.492 30873.91  31753.938 39074.254 29108.562\n",
            " 29054.666 31255.793 27622.195 23942.727 33822.457 26732.242 31384.193\n",
            " 30383.117 33887.848 38108.47  31001.605 30316.656 36109.17  37142.344\n",
            " 37251.527 29568.79  28523.484 30068.816 27156.57  31139.52  32650.121\n",
            " 29119.219 28425.162 29143.188 40756.152 19575.227 32356.07  38374.184\n",
            " 29971.729 34045.992 32953.43  32909.984 28691.13  32954.438 35330.203\n",
            " 25878.568 34547.816 30182.648 35726.12  32246.543 38518.086 28400.176\n",
            " 30923.803 29469.703 33898.254 21382.246 29780.531 35541.96  30789.947\n",
            " 32486.113 33500.625 36360.832 26822.582 37836.04  34492.055 30334.977\n",
            " 36625.    36443.164 27525.09  31452.646 29998.045 35628.61  31696.156\n",
            " 36801.215 40152.914 27091.5  ]\n",
            "RMSE: 10052.370818\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}