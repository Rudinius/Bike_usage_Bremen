{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "CBLnLwZIZpWJ",
      "metadata": {
        "id": "CBLnLwZIZpWJ"
      },
      "source": [
        "# Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lZXvJFJqZuRE",
      "metadata": {
        "id": "lZXvJFJqZuRE"
      },
      "source": [
        "In the Model learning step, the prepared dataset from [3_Imputing](https://raw.githubusercontent.com/Rudinius/Bike_usage_Bremen/main/3_Imputing.ipynb) is loaded. Then different machine learning algorithms are trained and compared to each other.\n",
        "\n",
        "We will test\n",
        "* XGBoost\n",
        "* Multilayer perceptron (MLP)\n",
        "* Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c910711",
      "metadata": {
        "id": "0c910711"
      },
      "source": [
        "<a name=\"content\"></a>\n",
        "# Content\n",
        "\n",
        "* [1. Import libraries and mount drive](#1.)\n",
        "* [2. Import datasets](#2.)\n",
        "* [3. Select a target station](#3.)\n",
        "* [4. Establish baseline benchmark](#4.)\n",
        "* [5. Training machine learning algorithms](#5)\n",
        "    * [5.2. XGBoost](#5.2.)\n",
        "    * [5.3. Multilayer perceptron](#5.3.)\n",
        "    * [5.4. Recurrent Neural Network](#5.4.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f76996",
      "metadata": {
        "id": "85f76996"
      },
      "source": [
        "<a name=\"1.\"></a>\n",
        "# 1.&nbsp;Import libraries\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only used for suppressing warning due to google colab environment\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "xSJzvaLrNPlR"
      },
      "id": "xSJzvaLrNPlR",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3731ea33",
      "metadata": {
        "id": "3731ea33"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, TimeSeriesSplit#, #cross_val_score,\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization, LSTM, Bidirectional, Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import RootMeanSquaredError ###### same as sklearn mse?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "LcKvjPd27cDu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "LcKvjPd27cDu",
        "outputId": "8bbd78f9-1362-4bb7-d7c7-c18af0eb227b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "janitor is already installed\n",
            "shap is already installed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a47b3c592773>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#importlib.__import__(package)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyjanitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyjanitor'"
          ]
        }
      ],
      "source": [
        "# Install package pyjanitor since it is not part of the standard packages\n",
        "# of Google Colab\n",
        "\n",
        "import importlib\n",
        "\n",
        "# Check if package is installed\n",
        "package_name = [\"janitor\", \"shap\"]\n",
        "\n",
        "for package in package_name:\n",
        "    spec = importlib.util.find_spec(package)\n",
        "    if spec is None:\n",
        "        # Package is not installed, install it via pip\n",
        "        !pip install {package}\n",
        "    else:\n",
        "        print(f\"{package} is already installed\")\n",
        "\n",
        "    #importlib.__import__(package)\n",
        "import pyjanitor\n",
        "import shap\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import janitor"
      ],
      "metadata": {
        "id": "lW2oRRTg4zJV",
        "outputId": "87d80ccd-50cd-427a-a29b-d8c2dcd84134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "id": "lW2oRRTg4zJV",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9c17466c364b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjanitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/janitor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mConfigParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msend_from_directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ConfigParser'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.set_random_seed(1)"
      ],
      "metadata": {
        "id": "FBMlPVNJzgfz"
      },
      "id": "FBMlPVNJzgfz",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2516jhMiVxrJ",
      "metadata": {
        "id": "2516jhMiVxrJ"
      },
      "source": [
        "<a name=\"2.\"></a>\n",
        "#2.&nbsp;Import dataset\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IF9lS_3ok1tO",
      "metadata": {
        "id": "IF9lS_3ok1tO"
      },
      "source": [
        "Import the processed dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Xu3OXfHqVxfa",
      "metadata": {
        "id": "Xu3OXfHqVxfa"
      },
      "outputs": [],
      "source": [
        "# Set base url\n",
        "url = \"https://raw.githubusercontent.com/Rudinius/Bike_usage_Bremen/main/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2etHV6ODVsUV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "2etHV6ODVsUV",
        "outputId": "3b898871-2b05-4194-897a-c2163433f50d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            graf_moltke_straße_ostseite  graf_moltke_straße_westseite  \\\n",
              "date                                                                    \n",
              "2013-01-01                        261.0                         290.0   \n",
              "2013-01-02                        750.0                         876.0   \n",
              "2013-01-03                        931.0                        1015.0   \n",
              "2013-01-04                        500.0                         587.0   \n",
              "2013-01-05                       1013.0                        1011.0   \n",
              "\n",
              "            hastedter_bruckenstraße  langemarckstraße_ostseite  \\\n",
              "date                                                             \n",
              "2013-01-01                    381.0                      312.0   \n",
              "2013-01-02                   1109.0                     1258.0   \n",
              "2013-01-03                   1603.0                     1556.0   \n",
              "2013-01-04                   1284.0                      703.0   \n",
              "2013-01-05                      0.0                     1856.0   \n",
              "\n",
              "            langemarckstraße_westseite  osterdeich  radweg_kleine_weser  \\\n",
              "date                                                                      \n",
              "2013-01-01                       308.0       870.0                410.0   \n",
              "2013-01-02                      1120.0      2169.0               1762.0   \n",
              "2013-01-03                      1480.0      2295.0               2287.0   \n",
              "2013-01-04                       626.0      1640.0               1548.0   \n",
              "2013-01-05                      1621.0      4128.0               4256.0   \n",
              "\n",
              "            schwachhauser_ring  wachmannstraße_auswarts_sud  \\\n",
              "date                                                          \n",
              "2013-01-01                 391                        514.0   \n",
              "2013-01-02                 829                       1786.0   \n",
              "2013-01-03                1196                       2412.0   \n",
              "2013-01-04                1418                        964.0   \n",
              "2013-01-05                3075                       2065.0   \n",
              "\n",
              "            wachmannstraße_einwarts_nord  ...  holiday_2_weihnachtsfeiertag  \\\n",
              "date                                      ...                                 \n",
              "2013-01-01                         267.0  ...                           0.0   \n",
              "2013-01-02                        1456.0  ...                           0.0   \n",
              "2013-01-03                        2035.0  ...                           0.0   \n",
              "2013-01-04                         702.0  ...                           0.0   \n",
              "2013-01-05                        1377.0  ...                           0.0   \n",
              "\n",
              "            holiday_christi_himmelfahrt  holiday_karfreitag  holiday_neujahr  \\\n",
              "date                                                                           \n",
              "2013-01-01                          0.0                 0.0              1.0   \n",
              "2013-01-02                          0.0                 0.0              0.0   \n",
              "2013-01-03                          0.0                 0.0              0.0   \n",
              "2013-01-04                          0.0                 0.0              0.0   \n",
              "2013-01-05                          0.0                 0.0              0.0   \n",
              "\n",
              "            holiday_ostermontag  holiday_pfingstmontag  \\\n",
              "date                                                     \n",
              "2013-01-01                  0.0                    0.0   \n",
              "2013-01-02                  0.0                    0.0   \n",
              "2013-01-03                  0.0                    0.0   \n",
              "2013-01-04                  0.0                    0.0   \n",
              "2013-01-05                  0.0                    0.0   \n",
              "\n",
              "            holiday_reformationstag  holiday_tag_der_arbeit  \\\n",
              "date                                                          \n",
              "2013-01-01                      0.0                     0.0   \n",
              "2013-01-02                      0.0                     0.0   \n",
              "2013-01-03                      0.0                     0.0   \n",
              "2013-01-04                      0.0                     0.0   \n",
              "2013-01-05                      0.0                     0.0   \n",
              "\n",
              "            holiday_tag_der_deutschen_einheit  transformed_vacation  \n",
              "date                                                                 \n",
              "2013-01-01                                0.0                     1  \n",
              "2013-01-02                                0.0                     1  \n",
              "2013-01-03                                0.0                     1  \n",
              "2013-01-04                                0.0                     1  \n",
              "2013-01-05                                0.0                     1  \n",
              "\n",
              "[5 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5907deb9-dad2-470f-b630-c6d271be5512\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>graf_moltke_straße_ostseite</th>\n",
              "      <th>graf_moltke_straße_westseite</th>\n",
              "      <th>hastedter_bruckenstraße</th>\n",
              "      <th>langemarckstraße_ostseite</th>\n",
              "      <th>langemarckstraße_westseite</th>\n",
              "      <th>osterdeich</th>\n",
              "      <th>radweg_kleine_weser</th>\n",
              "      <th>schwachhauser_ring</th>\n",
              "      <th>wachmannstraße_auswarts_sud</th>\n",
              "      <th>wachmannstraße_einwarts_nord</th>\n",
              "      <th>...</th>\n",
              "      <th>holiday_2_weihnachtsfeiertag</th>\n",
              "      <th>holiday_christi_himmelfahrt</th>\n",
              "      <th>holiday_karfreitag</th>\n",
              "      <th>holiday_neujahr</th>\n",
              "      <th>holiday_ostermontag</th>\n",
              "      <th>holiday_pfingstmontag</th>\n",
              "      <th>holiday_reformationstag</th>\n",
              "      <th>holiday_tag_der_arbeit</th>\n",
              "      <th>holiday_tag_der_deutschen_einheit</th>\n",
              "      <th>transformed_vacation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>261.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>870.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>391</td>\n",
              "      <td>514.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>750.0</td>\n",
              "      <td>876.0</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>1120.0</td>\n",
              "      <td>2169.0</td>\n",
              "      <td>1762.0</td>\n",
              "      <td>829</td>\n",
              "      <td>1786.0</td>\n",
              "      <td>1456.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>931.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>1603.0</td>\n",
              "      <td>1556.0</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>2287.0</td>\n",
              "      <td>1196</td>\n",
              "      <td>2412.0</td>\n",
              "      <td>2035.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>500.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>703.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>1640.0</td>\n",
              "      <td>1548.0</td>\n",
              "      <td>1418</td>\n",
              "      <td>964.0</td>\n",
              "      <td>702.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>1013.0</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1856.0</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>4128.0</td>\n",
              "      <td>4256.0</td>\n",
              "      <td>3075</td>\n",
              "      <td>2065.0</td>\n",
              "      <td>1377.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5907deb9-dad2-470f-b630-c6d271be5512')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5907deb9-dad2-470f-b630-c6d271be5512 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5907deb9-dad2-470f-b630-c6d271be5512');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03bd265a-c76a-4135-bdd7-e46da8299033\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03bd265a-c76a-4135-bdd7-e46da8299033')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03bd265a-c76a-4135-bdd7-e46da8299033 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Import dataset\n",
        "\n",
        "# We will also parse the date column as datetime64 and set it to the index column\n",
        "df = pd.read_csv(url + \"03_training_data/\" + \"2023-08-24_processed_df.csv\",\n",
        "                         parse_dates=[0], index_col=[0])\n",
        "\n",
        "# Check the correct loading of dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv96sN3croOJ"
      },
      "source": [
        "<a name=\"3.\"></a>\n",
        "# 3.&nbsp;Select a target station\n",
        "[Content](#content)\n"
      ],
      "id": "jv96sN3croOJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many stations that we could train our model on. Also we could add up all stations to a column `total` and try to predict the overall number in the city per day. However this approach would average many values which would lead on side to less noisy data as single outliers would be less impactful. On the other side it would also average over indivdual patterns.\n",
        "\n",
        "For this reason, we choose a single station to train our model on. For real-life purposes better results could be expected with one model per station.\n",
        "\n",
        "For the further process, we will work with the station: `wilhelm_kaisen_brucke_ost`\n"
      ],
      "metadata": {
        "id": "OG06qWVLrl_R"
      },
      "id": "OG06qWVLrl_R"
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"imputed_wilhelm_kaisen_brucke_ost\""
      ],
      "metadata": {
        "id": "cdukN1mWtqr5"
      },
      "id": "cdukN1mWtqr5",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "gBM3I6LFOHL9",
      "metadata": {
        "id": "gBM3I6LFOHL9"
      },
      "source": [
        "<a name=\"4.\"></a>\n",
        "# 4.&nbsp;Establish baseline benchmark\n",
        "[Content](#content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VgkVXhdAx6zB",
      "metadata": {
        "id": "VgkVXhdAx6zB"
      },
      "source": [
        "For our current task of creating model a to predict the amount of cyclers for a given day, we do not have any baseline metric score to measure our model against.\n",
        "For this reason, we will create a naive baseline model. For this, we will simply predict the amount of a day based on the value of previous day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6mu5aaMpO42j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mu5aaMpO42j",
        "outputId": "49c6fdbd-d5a8-43a4-d598-4daf5e61a37c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1791.993974\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model's performance using RMSE\n",
        "\n",
        "# Select the `wilhelm_kaisen_brucke_ost` column as our target and preds arrays\n",
        "y = y_hat = df.loc[:,target]\n",
        "\n",
        "rmse = 0\n",
        "length = y.shape[0]\n",
        "\n",
        "# Loop from 0 to second last entry, as we can only use seconds last entry to\n",
        "# predict the last entry of series\n",
        "for i in range(length-1):\n",
        "    # The mean_sqared_error function expects an array as input, therfore we\n",
        "    # concatenate the range from current value to current value + 1 (excluding)\n",
        "    rmse += np.sqrt(mean_squared_error(y[i+1:i+2], y_hat[i:i+1]))\n",
        "\n",
        "# Divide rmse value by number of pairs\n",
        "rmse = rmse / (length-1)\n",
        "print(\"RMSE: %f\" % (rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6O5OFAwW9Pm",
      "metadata": {
        "id": "f6O5OFAwW9Pm"
      },
      "source": [
        "If we were naivly predicting the current value with the last value, we get an error over the entire dataset of approximately $1,792$.\n",
        "\n",
        "This is our naive benchmark to compare our model against."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YHm0GDHUmczY",
      "metadata": {
        "id": "YHm0GDHUmczY"
      },
      "source": [
        "Another method would be to predict the value of a given day by the average of all the other equal days in the dataset (e.g., to predict 18.08.2017, we take the average of all other 18.08. days in the dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "kOSNaRxAdoCA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOSNaRxAdoCA",
        "outputId": "9c09d1c3-99ec-44fd-a28c-85d8faaf0b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2033.3351259991568\n"
          ]
        }
      ],
      "source": [
        "# Initialize squared error\n",
        "se = 0\n",
        "\n",
        "# Get the total number of examples\n",
        "m = df.shape[0]\n",
        "\n",
        "for i in df.index:\n",
        "    day = i.day\n",
        "    month = i.month\n",
        "    year = i.year\n",
        "\n",
        "    # create a mask for given day but exclude the day we want to predict\n",
        "    mask = (df.index.day == day) & (df.index.month == month) & (df.index.year != year)\n",
        "\n",
        "    # Get value for current day and mean values of all the other same days in the dataset\n",
        "    y = df.loc[i, target]\n",
        "    y_hat = df.loc[mask, target].mean()\n",
        "\n",
        "    # Calculate the squared error\n",
        "    se += (y - y_hat)**2\n",
        "\n",
        "# Calculate mean squared error\n",
        "mse = se / m\n",
        "\n",
        "# Calcualte root mean squared error\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SQ-iEzyHoc8M",
      "metadata": {
        "id": "SQ-iEzyHoc8M"
      },
      "source": [
        "With this second approach, of average all our previous values for the given day and using this as our forecast, we get an error over the entire dataset of approximately $2,033$.\n",
        "\n",
        "The error of this second naive approach is close to the first approach.\n",
        "Both approaches could be seen as human-level as this would be a typical approach of a human, to predict the value of any given day. A domain expert, who also looks at more data and e.g., compares also the temperatures, could come up with better estimates. However humans are typically not very good in accurately predicting complex time-series data. The expected Bayes error (least possible error) should therefore be much lower."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5HqwjOgkxauH",
      "metadata": {
        "id": "5HqwjOgkxauH"
      },
      "source": [
        "<a name=\"5\"></a>\n",
        "# 5.&nbsp;Training machine learning algorithms\n",
        "[Content](#content)\n",
        "\n",
        "We are going to train 1 shallow machine learning algorithm and 2 deep machine learning algorithms to be able to compare performances. Those are:\n",
        "\n",
        "* XGBoost\n",
        "* Multilayer Perceptron (MLP -- standard NN)\n",
        "* Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b154c25",
      "metadata": {
        "id": "9b154c25"
      },
      "source": [
        "<a name=\"5.1.\"></a>\n",
        "## 5.1. Adding sequential data to our model\n",
        "\n",
        "[Content](#content)\n",
        "\n",
        "In contrast to RNNs where the algorithm takes automically the datapoints of previous timesteps into account, XGBoost and MLPs do not have direct access to the sequential data of previous time steps.\n",
        "Those algorithms have only indirect knowledge via the learned model parameters. RNNs however directly include the previous timestep for learning the parameters of the current timestep.\n",
        "\n",
        "We will add the data points of the previous time steps as features to the feature vector.\n",
        "\n",
        "In this case, we will only add the last 3 values, as the observed improvement of accuracy (RMSE score) is drastically decressing with each further time step added after 3 steps.\n",
        "\n",
        "Improvements:\n",
        "* 1 day 6291 2,8%\n",
        "* 2 day 6157 2,1%\n",
        "* 3 day 6120 0,6%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842f23eb",
      "metadata": {
        "id": "842f23eb"
      },
      "source": [
        "The following code creates a dataframe with a variable amount of time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a03f3499",
      "metadata": {
        "id": "a03f3499",
        "outputId": "a38219d1-6988-4183-f8f7-a0ad9f4b2378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Create empty new dataframe\\ndf_lagged_days = pd.DataFrame({})\\n\\n# Select the number of lagged days\\ngo_back_x_days = 3\\n\\nfor i in range(go_back_x_days):\\n    # Shift the values in \"Total\" by i and assign to new column prev_Total_i+1\\n    df_lagged_days[f\\'prev_total_{i+1}\\'] = df_transformed_date[\\'total\\'].shift(i+1)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Create empty new dataframe\n",
        "df_lagged_days = pd.DataFrame({})\n",
        "\n",
        "# Select the number of lagged days\n",
        "go_back_x_days = 3\n",
        "\n",
        "for i in range(go_back_x_days):\n",
        "    # Shift the values in \"Total\" by i and assign to new column prev_Total_i+1\n",
        "    df_lagged_days[f'prev_total_{i+1}'] = df_transformed_date['total'].shift(i+1)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mO2Xt87cykEf",
      "metadata": {
        "id": "mO2Xt87cykEf"
      },
      "source": [
        "<a name=\"5.2.\"></a>\n",
        "## 5.2. XGBoost\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZgSdeq3fOxaQ",
      "metadata": {
        "id": "ZgSdeq3fOxaQ"
      },
      "source": [
        "For XGBoost, we will add the dataframe `df_lagged_days` to our dataset. Because we do not have all the information about the previous days for the first `go_back_x_days`, we drop the rows with `na` values. The parameter on how far to go back in time, has therefore an impact on the length of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "31690fdb-e0fd-460b-daa4-b618c0227618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "p8e0WfWKj6Gn"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Concat new dataframe with old dataframe\\n# Using bfill strategy on dataset since the first few days will have NaN values\\n# Using pyjanitor to clean up names\\ndf_transformed_date_lagged = (pd.concat([df_transformed_date, df_lagged_days], axis=1)\\n                              .dropna(axis=0)\\n                              .clean_names(strip_underscores=\"both\"))\\n\\n# Check output\\ndf_transformed_date_lagged\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Concat new dataframe with old dataframe\n",
        "# Using bfill strategy on dataset since the first few days will have NaN values\n",
        "# Using pyjanitor to clean up names\n",
        "df_transformed_date_lagged = (pd.concat([df_transformed_date, df_lagged_days], axis=1)\n",
        "                              .dropna(axis=0)\n",
        "                              .clean_names(strip_underscores=\"both\"))\n",
        "\n",
        "# Check output\n",
        "df_transformed_date_lagged\n",
        "\"\"\""
      ],
      "id": "p8e0WfWKj6Gn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"5.2.1\"></a>\n",
        "### 5.2.1 Split data into train and dev set and standardize training data\n",
        "[Content](#content)\n",
        "\n",
        "Now, we will split the data into a training set and into a dev set. Also here we select the final futures, which we want to use to train our model.\n",
        "\n",
        "Highly correlated features `tavg`, `tmin`, `wpgt` will be removed and features with no correlation to our target value will be also removed (`wdir`).\n",
        "\n",
        "When splitting into train and dev set, we will not shuffle the data. This ensures that the validation results are more realistic since they are being evaluated on the data collected after the model was trained. Otherwise we would introduce a \"leakage error\" into our data."
      ],
      "metadata": {
        "id": "XH_6MbWERL_5"
      },
      "id": "XH_6MbWERL_5"
    },
    {
      "cell_type": "code",
      "source": [
        "features_date = [\n",
        "    'year',\n",
        "    'month',\n",
        "    'day',\n",
        "    'weekday',\n",
        "]\n",
        "\n",
        "features_sin_cos_transformation = [\n",
        "    'week_sin', 'week_cos',\n",
        "    'month_sin', 'month_cos',\n",
        "    'year_sin', 'year_cos',\n",
        "]\n",
        "\n",
        "features_weather = [\n",
        "    'tmax',\n",
        "    'prcp',\n",
        "    'imputed_snow',\n",
        "    'wspd',\n",
        "    'pres',\n",
        "    'tsun',\n",
        "    ]\n",
        "\n",
        "features_holidays_vacation = [\n",
        "    'holiday_1_weihnachtsfeiertag', 'holiday_2_weihnachtsfeiertag',\n",
        "    'holiday_christi_himmelfahrt', 'holiday_karfreitag', 'holiday_neujahr',\n",
        "    'holiday_ostermontag', 'holiday_pfingstmontag',\n",
        "    'holiday_reformationstag', 'holiday_tag_der_arbeit',\n",
        "    'holiday_tag_der_deutschen_einheit', 'transformed_vacation'\n",
        "    ]\n",
        "\n",
        "# Target is 'imputed_wilhelm_kaisen_brucke_ost'\n",
        "target = target\n",
        "\n",
        "# Higly correlated features have been removed (tavg, tmin, imputed_wpgt)\n",
        "# Features with no correlation have been removed (imputed_wdir, wdir_sin, wdir_cos)\n",
        "# Only all single couting stations are being removed"
      ],
      "metadata": {
        "id": "vZyJeABHuthG"
      },
      "id": "vZyJeABHuthG",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = features_sin_cos_transformation + features_weather + features_holidays_vacation\n",
        "features"
      ],
      "metadata": {
        "id": "BiakefxsxJ7e",
        "outputId": "851c8c30-d206-4abf-c75a-95718aec1060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BiakefxsxJ7e",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['week_sin',\n",
              " 'week_cos',\n",
              " 'month_sin',\n",
              " 'month_cos',\n",
              " 'year_sin',\n",
              " 'year_cos',\n",
              " 'tmax',\n",
              " 'prcp',\n",
              " 'imputed_snow',\n",
              " 'wspd',\n",
              " 'pres',\n",
              " 'tsun',\n",
              " 'holiday_1_weihnachtsfeiertag',\n",
              " 'holiday_2_weihnachtsfeiertag',\n",
              " 'holiday_christi_himmelfahrt',\n",
              " 'holiday_karfreitag',\n",
              " 'holiday_neujahr',\n",
              " 'holiday_ostermontag',\n",
              " 'holiday_pfingstmontag',\n",
              " 'holiday_reformationstag',\n",
              " 'holiday_tag_der_arbeit',\n",
              " 'holiday_tag_der_deutschen_einheit',\n",
              " 'transformed_vacation']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "nxeQ39ojh2Y-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxeQ39ojh2Y-",
        "outputId": "15b0ea8d-2e71-4d5e-972a-837014731dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (2921, 23) y_train:  (2921,)\n",
            "X_train first day:  2013-01-01 00:00:00 X_train last day:  2020-12-30 00:00:00\n",
            "y_train first day:  2013-01-01 00:00:00 y_train last day:  2020-12-30 00:00:00\n",
            "X_dev:  (365, 23) y_dev:  (365,)\n",
            "X_dev first day:  2020-12-31 00:00:00 X_dev last day:  2021-12-30 00:00:00\n",
            "y_dev first day:  2020-12-31 00:00:00 y_dev last day:  2021-12-30 00:00:00\n",
            "X_test:  (366, 23) y_test:  (366,)\n",
            "X_test first day:  2021-12-31 00:00:00 X_test last day:  2022-12-31 00:00:00\n",
            "y_test first day:  2021-12-31 00:00:00 y_test last day:  2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and dev sets\n",
        "# We set shuffle to False\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(df[features], df[target],\n",
        "                                                    test_size=0.2, shuffle=False, random_state=0)\n",
        "\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp,\n",
        "                                                    test_size=0.5, shuffle=False, random_state=0)\n",
        "\n",
        "\n",
        "print(\"X_train: \", X_train[features].shape, \"y_train: \", y_train.shape)\n",
        "print(\"X_train first day: \", X_train.index[0], \"X_train last day: \", X_train.index[-1])\n",
        "print(\"y_train first day: \", y_train.index[0], \"y_train last day: \", y_train.index[-1])\n",
        "print(\"X_dev: \", X_dev[features].shape, \"y_dev: \", y_dev.shape)\n",
        "print(\"X_dev first day: \", X_dev.index[0], \"X_dev last day: \", X_dev.index[-1])\n",
        "print(\"y_dev first day: \", y_dev.index[0], \"y_dev last day: \", y_dev.index[-1])\n",
        "print(\"X_test: \", X_test[features].shape, \"y_test: \", y_test.shape)\n",
        "print(\"X_test first day: \", X_test.index[0], \"X_test last day: \", X_test.index[-1])\n",
        "print(\"y_test first day: \", y_test.index[0], \"y_test last day: \", y_test.index[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1GVZoPCdit-",
      "metadata": {
        "id": "a1GVZoPCdit-"
      },
      "source": [
        "Finally, we will standardize our dataset. Standarization will generally improve learning speed of the models and can help to improve the accuarcy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ZwsuKeAWsUr8"
      },
      "outputs": [],
      "source": [
        "# Standardize and fit to the training set only\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the same standardization to the dev set\n",
        "X_dev_scaled = scaler.transform(X_dev)\n",
        "\n",
        "# Apply the same standardization to the test set\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "id": "ZwsuKeAWsUr8"
    },
    {
      "cell_type": "markdown",
      "id": "amR72D-bg9Ea",
      "metadata": {
        "id": "amR72D-bg9Ea"
      },
      "source": [
        "<a name=\"5.2.2\"></a>\n",
        "### 5.2.2 Using GridSeachCV to select the optimal parameters\n",
        "[Content](#content)\n",
        "\n",
        "We will use `GridSearchCV` to select optimal parameters among the preselected ranges for the training data. Furthermore we will create our own scoring metric, to evaluate the performance of the parameters found with `GridSearchCV`.\n",
        "\n",
        "`GridSearchCV` is using `KFold` for regression problems as default. However `KFold` would split the training data in such a way, that later data will be evaluated against earlier data, introducing `leackage error`.\n",
        "Therefore we do not use the default, but create splits with `TimeSeriesSplit` and pass this to `GridSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom function for evaluating GridSearchCV\n",
        "def custom_rmse(y, y_hat):\n",
        "    return np.sqrt(mean_squared_error(y, y_hat))\n",
        "\n",
        "# Create the scoring object using the custom scoring function\n",
        "custom_scorer_rmse = make_scorer(custom_rmse)"
      ],
      "metadata": {
        "id": "TB-c62B8Je2b"
      },
      "id": "TB-c62B8Je2b",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "973fb2b1-b7b9-4be8-afab-51dede7bc4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "dU0g5nDdCaX4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nparams = {\\n    'n_estimators': [1000],\\n    'learning_rate': [0.05],\\n    'max_depth': [5, 10, 20],           # max. depth of tree\\n    'min_child_weight': [3, 6, 12],     # min. weight for splitting into new node\\n    'colsample_bytree': [0.7, 0.8],     # subsample ratio of columns\\n    'reg_alpha': [2.0, 4.0, 8.0],       # L1 regularization\\n    'reg_lambda': [4.0, 8.0, 16.0],    # L2 regularization\\n}\\n\\n# Getting time series splits using TimeSeriesSplit\\nn = 4\\ntscv = TimeSeriesSplit(n_splits=n)\\nsplits = []\\n\\nfor i, (train_index, test_index) in enumerate(tscv.split(X_train)):\\n    splits.append((train_index, test_index))\\n\\n# Define the estimator\\nxg_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)\\n\\n# Define GridSearch and fit GridSearch on the training data with the custom scorer and custom splits\\ngrid_search = GridSearchCV(xg_reg, param_grid=params, cv=splits, scoring=custom_scorer_rmse, n_jobs=-1, verbose=2)\\ngrid_search.fit(X_train_scaled, y_train)\\n\\n# Print the best parameters and score as well as the best model to that score\\nprint(grid_search.best_params_)\\nprint(grid_search.best_score_)\\n\\nbest_model = grid_search.best_estimator_\\nprint(best_model)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\"\"\"\n",
        "params = {\n",
        "    'n_estimators': [1000],\n",
        "    'learning_rate': [0.05],\n",
        "    'max_depth': [5, 10, 20],           # max. depth of tree\n",
        "    'min_child_weight': [3, 6, 12],     # min. weight for splitting into new node\n",
        "    'colsample_bytree': [0.7, 0.8],     # subsample ratio of columns\n",
        "    'reg_alpha': [2.0, 4.0, 8.0],       # L1 regularization\n",
        "    'reg_lambda': [4.0, 8.0, 16.0],    # L2 regularization\n",
        "}\n",
        "\n",
        "# Getting time series splits using TimeSeriesSplit\n",
        "n = 4\n",
        "tscv = TimeSeriesSplit(n_splits=n)\n",
        "splits = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(tscv.split(X_train)):\n",
        "    splits.append((train_index, test_index))\n",
        "\n",
        "# Define the estimator\n",
        "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=0)\n",
        "\n",
        "# Define GridSearch and fit GridSearch on the training data with the custom scorer and custom splits\n",
        "grid_search = GridSearchCV(xg_reg, param_grid=params, cv=splits, scoring=custom_scorer_rmse, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and score as well as the best model to that score\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)\n",
        "\"\"\""
      ],
      "id": "dU0g5nDdCaX4"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "u9DKLFqkmIRm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9DKLFqkmIRm",
        "outputId": "760d9786-7d14-40bd-bda9-9b234792afb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 785.685960\n",
            "Dev RMSE: 1581.168878\n",
            "Test RMSE: 1418.602322\n"
          ]
        }
      ],
      "source": [
        "# Build the XGBoost regressor model with selected hyper parameters\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror',  reg_alpha = 10.0, reg_lambda = 1.0, learning_rate = 0.1)\n",
        "\n",
        "\"\"\", colsample_bytree = 0.5, learning_rate = 0.05,\n",
        "                          max_depth = 8, n_estimators = 1000, reg_alpha = 10.0, reg_lambda = 40.0,\n",
        "                          subsample = 0.8, min_child_weight=5\"\"\"\n",
        "\n",
        "xg_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model's performance using RMSE\n",
        "\n",
        "# Training set\n",
        "# Predict on the train set\n",
        "y_train_hat = xg_reg.predict(X_train_scaled)\n",
        "rmse_train = custom_rmse(y_train, y_train_hat)\n",
        "print(\"Train RMSE: %f\" % (rmse_train))\n",
        "\n",
        "# Dev set\n",
        "# Predict on the dev set\n",
        "y_dev_hat = xg_reg.predict(X_dev_scaled)\n",
        "rmse_dev = custom_rmse(y_dev, y_dev_hat)\n",
        "print(\"Dev RMSE: %f\" % (rmse_dev))\n",
        "\n",
        "# Test set\n",
        "# Predict on the test set\n",
        "y_test_hat = xg_reg.predict(X_test_scaled)\n",
        "rmse_test = custom_rmse(y_test, y_test_hat)\n",
        "print(\"Test RMSE: %f\" % (rmse_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sin and cos\n",
        "Train RMSE: 1019.252085\n",
        "Dev RMSE: 1709.549721\n",
        "\n",
        "date\n",
        "Train RMSE: 1184.215359\n",
        "Dev RMSE: 1761.530727"
      ],
      "metadata": {
        "id": "RH9n4j1XTNFh"
      },
      "id": "RH9n4j1XTNFh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get an understanding of our model and also to check for plausibility (e.g., did the model pick up correct patterns) we plot the feature importance with the `shap` library."
      ],
      "metadata": {
        "id": "3DncApmZuA7q"
      },
      "id": "3DncApmZuA7q"
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain model predictions using shap library:\n",
        "explainer = shap.TreeExplainer(xg_reg)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "# Plot summary_plot as barplot:\n",
        "shap.summary_plot(shap_values, X_train_scaled, feature_names=features, plot_type='bar', plot_size=[15,5])"
      ],
      "metadata": {
        "id": "5Z6rHfVAuAUr",
        "outputId": "708d14e5-f0f0-4b59-8bae-3c5c9dcd847c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "id": "5Z6rHfVAuAUr",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot tells us, that the most important features for the model output are `week_sin`, `tmax`, `month_sin`, and `transformed_vacation`. This seems reasonable since we have seen a weekly periodicity and `tmax` having the highest correlation."
      ],
      "metadata": {
        "id": "ugcPJDRyx7QG"
      },
      "id": "ugcPJDRyx7QG"
    },
    {
      "cell_type": "markdown",
      "id": "fOFZ5oXgTT7V",
      "metadata": {
        "id": "fOFZ5oXgTT7V"
      },
      "source": [
        "<a name=\"5.3.\"></a>\n",
        "## 5.3. Multilayer Perceptron\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CFbCaX6sKhZF",
      "metadata": {
        "id": "CFbCaX6sKhZF"
      },
      "outputs": [],
      "source": [
        "dropout = 0.2 # 0.2 best\n",
        "\n",
        "# Define the architecture of the MLP with L2 regularization\n",
        "model_mlp = Sequential()\n",
        "\n",
        "model_mlp.add(Input(shape=(len(features),)))\n",
        "model_mlp.add(Dense(units=128, activation='relu'))\n",
        "model_mlp.add(Dropout(dropout))\n",
        "model_mlp.add(Dense(units=64, activation='relu'))\n",
        "model_mlp.add(Dropout(dropout))\n",
        "model_mlp.add(Dense(units=1, activation='linear'))  # Output layer with 1 neuron for regression\n",
        "\n",
        "# Compile the model with mean squared error (MSE) loss, and root mean square error (RMSE) as metric\n",
        "# Use Adam optimizer with learning rate\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_mlp.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "print(model_mlp.summary())\n",
        "\n",
        "# Train the model and save the learning history, use x_dev and y_dev for validation\n",
        "history = model_mlp.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_dev_scaled, y_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "all features with cos and sin\n",
        "Epoch 100/100\n",
        "92/92 [==============================] - 0s 3ms/step - loss: 2264314.0000 - root_mean_squared_error: 1504.7638 - val_loss: 2452808.2500 - val_root_mean_squared_error: 1566.1444"
      ],
      "metadata": {
        "id": "60pDB98PVm1I"
      },
      "id": "60pDB98PVm1I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RhbEPgSPsXCy",
      "metadata": {
        "id": "RhbEPgSPsXCy"
      },
      "outputs": [],
      "source": [
        "# Create the array for the x axis, starting from 1\n",
        "epochs = np.arange(1, len(history.history[\"root_mean_squared_error\"])+1)\n",
        "train_rmse = history.history[\"root_mean_squared_error\"]\n",
        "dev_rmse = history.history[\"val_root_mean_squared_error\"]\n",
        "\n",
        "# Create a line chart with two lines using Plotly Express\n",
        "fig = px.line(title='train RMSE vs. dev RMSE')\n",
        "fig.add_scatter(x=epochs, y=train_rmse, mode='lines+markers', name='Train RMSE', line=dict(color='red'))\n",
        "fig.add_scatter(x=epochs, y=dev_rmse, mode='lines+markers', name='Dev RMSE', line=dict(color='blue'))\n",
        "\n",
        "\n",
        "# Set chart title and axis labels\n",
        "fig.update_layout(\n",
        "    xaxis_title='Epochs',\n",
        "    yaxis_title='RMSE'\n",
        ")\n",
        "\n",
        "# Show the chart\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain model predictions using shap library:\n",
        "explainer = shap.DeepExplainer(model_mlp, X_train_scaled)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "# Plot summary_plot as barplot:\n",
        "shap.summary_plot(shap_values, X_train_scaled, feature_names=features, plot_type='bar', plot_size=[15,5])"
      ],
      "metadata": {
        "id": "bamMyHTGoTl1"
      },
      "id": "bamMyHTGoTl1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qg2TMtxJUzVm",
      "metadata": {
        "id": "qg2TMtxJUzVm"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model's performance using RMSE on train\n",
        "y_train_hat = model_mlp.predict(X_train_scaled)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_hat))\n",
        "print(\"Train RMSE: %f\" % (rmse_train))\n",
        "\n",
        "# Evaluate the model's performance using RMSE on dev\n",
        "y_dev_hat = model_mlp.predict(X_dev_scaled)\n",
        "rmse_dev = np.sqrt(mean_squared_error(y_dev, y_dev_hat))\n",
        "print(\"Dev RMSE: %f\" % (rmse_dev))\n",
        "\n",
        "# Evaluate the model's performance using RMSE on test\n",
        "y_test_hat = model_mlp.predict(X_test_scaled)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_hat))\n",
        "print(\"Test RMSE: %f\" % (rmse_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35YvxR1B1tcY",
      "metadata": {
        "id": "35YvxR1B1tcY"
      },
      "source": [
        "<a name=\"5.4.\"></a>\n",
        "## 5.4. Recurrent Neural Network\n",
        "[Content](#content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we train an RNN to compare to the previous two models. A RNN can take in multiple timesteps, to make a prediction (Many-to-One). Specifically, we will feed in 4 timesteps at a time (current day and the 3 previous days) and output the prediction of the current day.\n",
        "\n",
        "Out input shape is therefore (none, 4, 21), where none represents a variable amount of training days (in our case the length of X_train)."
      ],
      "metadata": {
        "id": "sfs0s3ZGC9Wp"
      },
      "id": "sfs0s3ZGC9Wp"
    },
    {
      "cell_type": "code",
      "source": [
        "y_dev[:10]\n",
        "#X_train[:10]"
      ],
      "metadata": {
        "id": "prk6dSfED3WF",
        "outputId": "cd4f07fa-fc3e-42ce-bbea-d85fb4596bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "prk6dSfED3WF",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date\n",
              "2020-12-31     2676.0\n",
              "2021-01-01     2175.0\n",
              "2021-01-02     2168.0\n",
              "2021-01-03     6828.0\n",
              "2021-01-04     6305.0\n",
              "2021-01-05     3872.0\n",
              "2021-01-06    10398.0\n",
              "2021-01-07     7953.0\n",
              "2021-01-08     2765.0\n",
              "2021-01-09     9202.0\n",
              "Name: imputed_wilhelm_kaisen_brucke_ost, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import timeseries_dataset_from_array\n",
        "\n",
        "seq_length = 4\n",
        "\n",
        "#input_data = X_train_scaled\n",
        "#targets = y_train[3:]\n",
        "#targets = y_train\n",
        "\"\"\"\n",
        "a_X_train = X_train_scaled[:-seq_length]\n",
        "a_y_train = y_train[seq_length-1:]\n",
        "\n",
        "a_X_dev = X_dev_scaled[:-seq_length]\n",
        "a_y_dev = y_dev[seq_length-1:]\n",
        "\n",
        "a_X_test = X_test_scaled[:-seq_length]\n",
        "a_y_test = y_test[seq_length-1:]\"\"\"\n",
        "\n",
        "dataset_X_train = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data=X_train_scaled, targets=None, sequence_length=seq_length, batch_size=32, shuffle=False)\n",
        "\n",
        "dataset_y_train = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data=y_train, targets=None, sequence_length=seq_length, batch_size=32, shuffle=False)\n",
        "\n",
        "dataset_train = tf.data.Dataset.zip((dataset_X_train, dataset_y_train))\n",
        "\n",
        "dataset_X_dev = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data=X_dev_scaled, targets=None, sequence_length=seq_length, batch_size=32, shuffle=False)\n",
        "\n",
        "dataset_y_dev = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data=y_dev, targets=None, sequence_length=seq_length, batch_size=32, shuffle=False)\n",
        "\n",
        "dataset_dev = tf.data.Dataset.zip((dataset_X_dev, dataset_y_dev))\n",
        "#print(dataset.take(10))\n",
        "\n",
        "for x,y in dataset_dev.take(1):\n",
        "    print(x, y)\n",
        "\"\"\"\n",
        "\n",
        "#for x, y in dataset.take(10):\n",
        "#    print(x, y)\n",
        "\n",
        "y_trainnnn = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data=targets, targets=None, sequence_length=4, batch_size=None, shuffle=False)\n",
        "\n",
        "\n",
        "for y in y_trainnnn.take(10):\n",
        "    print(y)\n",
        "\n",
        "x_trainnnn.to_numpy()\"\"\"\n"
      ],
      "metadata": {
        "id": "vzzhZEanaiIt",
        "outputId": "5e89663e-9375-4844-f175-da11b928c672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "vzzhZEanaiIt",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 6.12636142e-01 -1.27460169e+00 -1.90818567e-03 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [-6.14336899e-01 -1.27460169e+00  2.80247781e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [-1.37934208e+00 -3.14946833e-01  5.50852250e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [-1.10631489e+00  8.81723202e-01  7.98826641e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]]\n",
            "\n",
            " [[-6.14336899e-01 -1.27460169e+00  2.80247781e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [-1.37934208e+00 -3.14946833e-01  5.50852250e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [-1.10631489e+00  8.81723202e-01  7.98826641e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [-8.50378709e-04  1.41429147e+00  1.01401885e+00 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]]\n",
            "\n",
            " [[-1.37934208e+00 -3.14946833e-01  5.50852250e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [-1.10631489e+00  8.81723202e-01  7.98826641e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [-8.50378709e-04  1.41429147e+00  1.01401885e+00 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [ 1.10461413e+00  8.81723202e-01  1.18761890e+00 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-6.14336899e-01 -1.27460169e+00 -5.54668621e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02 -5.77745579e-01]\n",
            "  [-1.37934208e+00 -3.14946833e-01 -2.84064153e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02 -5.77745579e-01]\n",
            "  [-1.10631489e+00  8.81723202e-01 -1.90818567e-03 ... -5.24052445e-02\n",
            "   -5.24052445e-02 -5.77745579e-01]\n",
            "  [-8.50378709e-04  1.41429147e+00  2.80247781e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]]\n",
            "\n",
            " [[-1.37934208e+00 -3.14946833e-01 -2.84064153e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02 -5.77745579e-01]\n",
            "  [-1.10631489e+00  8.81723202e-01 -1.90818567e-03 ... -5.24052445e-02\n",
            "   -5.24052445e-02 -5.77745579e-01]\n",
            "  [-8.50378709e-04  1.41429147e+00  2.80247781e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [ 1.10461413e+00  8.81723202e-01  5.50852250e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]]\n",
            "\n",
            " [[-1.10631489e+00  8.81723202e-01 -1.90818567e-03 ... -5.24052445e-02\n",
            "   -5.24052445e-02 -5.77745579e-01]\n",
            "  [-8.50378709e-04  1.41429147e+00  2.80247781e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [ 1.10461413e+00  8.81723202e-01  5.50852250e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02  1.73086569e+00]\n",
            "  [ 1.37764132e+00 -3.14946833e-01  7.98826641e-01 ... -5.24052445e-02\n",
            "   -5.24052445e-02 -5.77745579e-01]]], shape=(32, 4, 23), dtype=float64) tf.Tensor(\n",
            "[[ 2676.  2175.  2168.  6828.]\n",
            " [ 2175.  2168.  6828.  6305.]\n",
            " [ 2168.  6828.  6305.  3872.]\n",
            " [ 6828.  6305.  3872. 10398.]\n",
            " [ 6305.  3872. 10398.  7953.]\n",
            " [ 3872. 10398.  7953.  2765.]\n",
            " [10398.  7953.  2765.  9202.]\n",
            " [ 7953.  2765.  9202.  9158.]\n",
            " [ 2765.  9202.  9158.  8688.]\n",
            " [ 9202.  9158.  8688.  6215.]\n",
            " [ 9158.  8688.  6215.  5269.]\n",
            " [ 8688.  6215.  5269.  5688.]\n",
            " [ 6215.  5269.  5688.  5573.]\n",
            " [ 5269.  5688.  5573.  3031.]\n",
            " [ 5688.  5573.  3031.  2221.]\n",
            " [ 5573.  3031.  2221.  5422.]\n",
            " [ 3031.  2221.  5422.  4669.]\n",
            " [ 2221.  5422.  4669.  6263.]\n",
            " [ 5422.  4669.  6263.  5994.]\n",
            " [ 4669.  6263.  5994.  5985.]\n",
            " [ 6263.  5994.  5985.  3360.]\n",
            " [ 5994.  5985.  3360.  2695.]\n",
            " [ 5985.  3360.  2695.  5988.]\n",
            " [ 3360.  2695.  5988.  5944.]\n",
            " [ 2695.  5988.  5944.  5569.]\n",
            " [ 5988.  5944.  5569.  5983.]\n",
            " [ 5944.  5569.  5983.  3377.]\n",
            " [ 5569.  5983.  3377.   986.]\n",
            " [ 5983.  3377.   986.   963.]\n",
            " [ 3377.   986.   963.  2554.]\n",
            " [  986.   963.  2554.  2457.]\n",
            " [  963.  2554.  2457.  7184.]], shape=(32, 4), dtype=float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n#for x, y in dataset.take(10):\\n#    print(x, y)\\n\\ny_trainnnn = tf.keras.utils.timeseries_dataset_from_array(\\n    data=targets, targets=None, sequence_length=4, batch_size=None, shuffle=False)\\n\\n\\nfor y in y_trainnnn.take(10):\\n    print(y)\\n\\nx_trainnnn.to_numpy()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Define the number of timesteps\n",
        "seq_length = 4\n",
        "\n",
        "# Create sequences of length 4\n",
        "X_train_scaled_3d, X_dev_scaled_3d = [], []\n",
        "y_train_3d, y_dev_3d = [], []\n",
        "\n",
        "for i in range(len(X_train_scaled) - seq_length + 1):\n",
        "    X_train_scaled_3d.append(X_train_scaled[i : i + seq_length])\n",
        "    y_train_3d.append(y_train[i : i + seq_length])\n",
        "\n",
        "X_train_scaled_3d = np.array(X_train_scaled_3d)\n",
        "y_train_3d = np.array(y_train_3d)\n",
        "\n",
        "\n",
        "for i in range(len(X_dev_scaled) - seq_length + 1):\n",
        "    X_dev_scaled_3d.append(X_dev_scaled[i : i + seq_length])\n",
        "    y_dev_3d.append(y_dev[i : i + seq_length])\n",
        "\n",
        "X_dev_scaled_3d = np.array(X_dev_scaled_3d)\n",
        "y_dev_3d = np.array(y_dev_3d)\n",
        "\n",
        "# Check result\n",
        "print(X_train_scaled_3d.shape)\n",
        "print(y_train_3d.shape)\n",
        "\n",
        "print(X_dev_scaled_3d.shape)\n",
        "print(y_dev_3d.shape)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG3uW6OfVD4n",
        "outputId": "e64f9e38-8d4a-44b5-8dff-1dba2dabd63b"
      },
      "id": "jG3uW6OfVD4n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2918, 4, 13)\n",
            "(2918, 4)\n",
            "(362, 4, 13)\n",
            "(362, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "sOTf5esj1181",
      "metadata": {
        "id": "sOTf5esj1181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb24839-b77a-465e-f374-8683091c6065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 4, 23)]           0         \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 4, 128)           45056     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirecti  (None, 4, 64)            41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4, 1)              65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86,337\n",
            "Trainable params: 86,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "92/92 [==============================] - 10s 28ms/step - loss: 34806936.0000 - root_mean_squared_error: 5899.7402 - val_loss: 15649460.0000 - val_root_mean_squared_error: 3955.9399\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 10011604.0000 - root_mean_squared_error: 3164.1121 - val_loss: 9281685.0000 - val_root_mean_squared_error: 3046.5857\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 6323661.0000 - root_mean_squared_error: 2514.6890 - val_loss: 6444990.0000 - val_root_mean_squared_error: 2538.6982\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 4496389.5000 - root_mean_squared_error: 2120.4692 - val_loss: 4939782.0000 - val_root_mean_squared_error: 2222.5620\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 4051583.5000 - root_mean_squared_error: 2012.8546 - val_loss: 4576508.0000 - val_root_mean_squared_error: 2139.2773\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3822385.0000 - root_mean_squared_error: 1955.0922 - val_loss: 4843656.5000 - val_root_mean_squared_error: 2200.8308\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 3746551.0000 - root_mean_squared_error: 1935.6010 - val_loss: 4519504.5000 - val_root_mean_squared_error: 2125.9126\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 3605963.0000 - root_mean_squared_error: 1898.9374 - val_loss: 4557141.5000 - val_root_mean_squared_error: 2134.7463\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3566277.5000 - root_mean_squared_error: 1888.4591 - val_loss: 4198821.0000 - val_root_mean_squared_error: 2049.1025\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3637017.7500 - root_mean_squared_error: 1907.0966 - val_loss: 4017758.0000 - val_root_mean_squared_error: 2004.4346\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3634941.0000 - root_mean_squared_error: 1906.5522 - val_loss: 4044391.5000 - val_root_mean_squared_error: 2011.0673\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 3546491.7500 - root_mean_squared_error: 1883.2131 - val_loss: 4170460.2500 - val_root_mean_squared_error: 2042.1704\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 3541043.2500 - root_mean_squared_error: 1881.7660 - val_loss: 3804198.5000 - val_root_mean_squared_error: 1950.4354\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3447414.5000 - root_mean_squared_error: 1856.7214 - val_loss: 3964282.7500 - val_root_mean_squared_error: 1991.0507\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3577949.7500 - root_mean_squared_error: 1891.5469 - val_loss: 3803998.5000 - val_root_mean_squared_error: 1950.3842\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 5s 52ms/step - loss: 3527355.7500 - root_mean_squared_error: 1878.1256 - val_loss: 3918867.0000 - val_root_mean_squared_error: 1979.6129\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 5s 53ms/step - loss: 3448338.0000 - root_mean_squared_error: 1856.9701 - val_loss: 3793214.5000 - val_root_mean_squared_error: 1947.6177\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3467273.7500 - root_mean_squared_error: 1862.0618 - val_loss: 3895552.2500 - val_root_mean_squared_error: 1973.7153\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 3441779.0000 - root_mean_squared_error: 1855.2032 - val_loss: 3841012.2500 - val_root_mean_squared_error: 1959.8501\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 3392827.7500 - root_mean_squared_error: 1841.9630 - val_loss: 3676753.0000 - val_root_mean_squared_error: 1917.4861\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 3442972.2500 - root_mean_squared_error: 1855.5248 - val_loss: 3643065.7500 - val_root_mean_squared_error: 1908.6816\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3373761.2500 - root_mean_squared_error: 1836.7802 - val_loss: 3739140.2500 - val_root_mean_squared_error: 1933.6857\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3237887.2500 - root_mean_squared_error: 1799.4131 - val_loss: 3704961.7500 - val_root_mean_squared_error: 1924.8278\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3272118.2500 - root_mean_squared_error: 1808.8998 - val_loss: 3615249.7500 - val_root_mean_squared_error: 1901.3810\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3269985.0000 - root_mean_squared_error: 1808.3099 - val_loss: 3626264.5000 - val_root_mean_squared_error: 1904.2753\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 3s 31ms/step - loss: 3236072.7500 - root_mean_squared_error: 1798.9088 - val_loss: 3708206.2500 - val_root_mean_squared_error: 1925.6703\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 3325184.2500 - root_mean_squared_error: 1823.5088 - val_loss: 3563203.2500 - val_root_mean_squared_error: 1887.6448\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 3198298.7500 - root_mean_squared_error: 1788.3787 - val_loss: 3913856.0000 - val_root_mean_squared_error: 1978.3467\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 3241201.0000 - root_mean_squared_error: 1800.3336 - val_loss: 3526054.5000 - val_root_mean_squared_error: 1877.7792\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3354162.5000 - root_mean_squared_error: 1831.4373 - val_loss: 3587937.5000 - val_root_mean_squared_error: 1894.1852\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3178474.2500 - root_mean_squared_error: 1782.8276 - val_loss: 3584019.5000 - val_root_mean_squared_error: 1893.1506\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3288172.0000 - root_mean_squared_error: 1813.3318 - val_loss: 3530730.7500 - val_root_mean_squared_error: 1879.0239\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 3215857.2500 - root_mean_squared_error: 1793.2811 - val_loss: 3569858.0000 - val_root_mean_squared_error: 1889.4067\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 3256646.0000 - root_mean_squared_error: 1804.6179 - val_loss: 3552041.2500 - val_root_mean_squared_error: 1884.6859\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3205747.7500 - root_mean_squared_error: 1790.4602 - val_loss: 3537678.2500 - val_root_mean_squared_error: 1880.8717\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3207568.7500 - root_mean_squared_error: 1790.9686 - val_loss: 3538103.2500 - val_root_mean_squared_error: 1880.9846\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3243277.5000 - root_mean_squared_error: 1800.9102 - val_loss: 3551872.2500 - val_root_mean_squared_error: 1884.6411\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 3192253.7500 - root_mean_squared_error: 1786.6880 - val_loss: 3545239.7500 - val_root_mean_squared_error: 1882.8806\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 3s 27ms/step - loss: 3179463.5000 - root_mean_squared_error: 1783.1050 - val_loss: 3574093.0000 - val_root_mean_squared_error: 1890.5272\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3129060.0000 - root_mean_squared_error: 1768.9148 - val_loss: 3462871.7500 - val_root_mean_squared_error: 1860.8793\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3119564.0000 - root_mean_squared_error: 1766.2289 - val_loss: 3452818.0000 - val_root_mean_squared_error: 1858.1760\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 3102907.7500 - root_mean_squared_error: 1761.5072 - val_loss: 3515820.5000 - val_root_mean_squared_error: 1875.0521\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3184332.0000 - root_mean_squared_error: 1784.4697 - val_loss: 3461383.7500 - val_root_mean_squared_error: 1860.4795\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 3089900.0000 - root_mean_squared_error: 1757.8112 - val_loss: 3434137.5000 - val_root_mean_squared_error: 1853.1427\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 3085879.7500 - root_mean_squared_error: 1756.6672 - val_loss: 3390399.0000 - val_root_mean_squared_error: 1841.3036\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 3056615.0000 - root_mean_squared_error: 1748.3177 - val_loss: 3451811.0000 - val_root_mean_squared_error: 1857.9050\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 3083041.7500 - root_mean_squared_error: 1755.8593 - val_loss: 3457271.2500 - val_root_mean_squared_error: 1859.3739\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 3060272.0000 - root_mean_squared_error: 1749.3633 - val_loss: 3436014.2500 - val_root_mean_squared_error: 1853.6490\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 3107816.7500 - root_mean_squared_error: 1762.9003 - val_loss: 3424671.5000 - val_root_mean_squared_error: 1850.5868\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 3084949.7500 - root_mean_squared_error: 1756.4025 - val_loss: 3471290.2500 - val_root_mean_squared_error: 1863.1398\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 3128491.2500 - root_mean_squared_error: 1768.7542 - val_loss: 3412483.2500 - val_root_mean_squared_error: 1847.2908\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2926130.2500 - root_mean_squared_error: 1710.5935 - val_loss: 3404543.2500 - val_root_mean_squared_error: 1845.1404\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 3110878.7500 - root_mean_squared_error: 1763.7683 - val_loss: 3393323.5000 - val_root_mean_squared_error: 1842.0975\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 2995156.5000 - root_mean_squared_error: 1730.6521 - val_loss: 3385756.2500 - val_root_mean_squared_error: 1840.0425\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 4s 45ms/step - loss: 3093583.2500 - root_mean_squared_error: 1758.8585 - val_loss: 3425839.7500 - val_root_mean_squared_error: 1850.9025\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 4s 45ms/step - loss: 2918569.2500 - root_mean_squared_error: 1708.3821 - val_loss: 3438088.2500 - val_root_mean_squared_error: 1854.2083\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 3052522.0000 - root_mean_squared_error: 1747.1469 - val_loss: 3427422.7500 - val_root_mean_squared_error: 1851.3300\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 3069202.7500 - root_mean_squared_error: 1751.9141 - val_loss: 3379035.2500 - val_root_mean_squared_error: 1838.2153\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 3011418.0000 - root_mean_squared_error: 1735.3438 - val_loss: 3399810.7500 - val_root_mean_squared_error: 1843.8575\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 3068707.0000 - root_mean_squared_error: 1751.7726 - val_loss: 3352502.7500 - val_root_mean_squared_error: 1830.9841\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2952080.5000 - root_mean_squared_error: 1718.1620 - val_loss: 3392406.2500 - val_root_mean_squared_error: 1841.8486\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 3s 35ms/step - loss: 3008035.0000 - root_mean_squared_error: 1734.3688 - val_loss: 3403096.5000 - val_root_mean_squared_error: 1844.7482\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 2950287.2500 - root_mean_squared_error: 1717.6400 - val_loss: 3381360.7500 - val_root_mean_squared_error: 1838.8477\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2943223.5000 - root_mean_squared_error: 1715.5826 - val_loss: 3373940.7500 - val_root_mean_squared_error: 1836.8290\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 2931336.5000 - root_mean_squared_error: 1712.1146 - val_loss: 3415035.5000 - val_root_mean_squared_error: 1847.9814\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2918153.0000 - root_mean_squared_error: 1708.2603 - val_loss: 3385524.7500 - val_root_mean_squared_error: 1839.9795\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 4s 38ms/step - loss: 2909632.5000 - root_mean_squared_error: 1705.7645 - val_loss: 3356263.5000 - val_root_mean_squared_error: 1832.0107\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 2956341.0000 - root_mean_squared_error: 1719.4014 - val_loss: 3309290.5000 - val_root_mean_squared_error: 1819.1455\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2978875.7500 - root_mean_squared_error: 1725.9420 - val_loss: 3387582.2500 - val_root_mean_squared_error: 1840.5385\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2916220.2500 - root_mean_squared_error: 1707.6945 - val_loss: 3406765.5000 - val_root_mean_squared_error: 1845.7426\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 2896453.7500 - root_mean_squared_error: 1701.8971 - val_loss: 3314151.5000 - val_root_mean_squared_error: 1820.4812\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 2932427.2500 - root_mean_squared_error: 1712.4330 - val_loss: 3287944.5000 - val_root_mean_squared_error: 1813.2690\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2903051.5000 - root_mean_squared_error: 1703.8342 - val_loss: 3380881.0000 - val_root_mean_squared_error: 1838.7172\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2910899.7500 - root_mean_squared_error: 1706.1359 - val_loss: 3401732.5000 - val_root_mean_squared_error: 1844.3787\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2977030.2500 - root_mean_squared_error: 1725.4072 - val_loss: 3341209.5000 - val_root_mean_squared_error: 1827.8975\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2959695.5000 - root_mean_squared_error: 1720.3766 - val_loss: 3394500.5000 - val_root_mean_squared_error: 1842.4170\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 3s 27ms/step - loss: 2968740.5000 - root_mean_squared_error: 1723.0033 - val_loss: 3336461.7500 - val_root_mean_squared_error: 1826.5984\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2952774.2500 - root_mean_squared_error: 1718.3638 - val_loss: 3369612.5000 - val_root_mean_squared_error: 1835.6504\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 2901150.5000 - root_mean_squared_error: 1703.2764 - val_loss: 3307933.0000 - val_root_mean_squared_error: 1818.7723\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2871367.5000 - root_mean_squared_error: 1694.5111 - val_loss: 3308766.5000 - val_root_mean_squared_error: 1819.0015\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 2855436.7500 - root_mean_squared_error: 1689.8037 - val_loss: 3371660.5000 - val_root_mean_squared_error: 1836.2083\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 2870098.7500 - root_mean_squared_error: 1694.1366 - val_loss: 3288176.5000 - val_root_mean_squared_error: 1813.3330\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2920705.2500 - root_mean_squared_error: 1709.0071 - val_loss: 3296966.0000 - val_root_mean_squared_error: 1815.7549\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 2838961.5000 - root_mean_squared_error: 1684.9218 - val_loss: 3344148.2500 - val_root_mean_squared_error: 1828.7013\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2787613.7500 - root_mean_squared_error: 1669.6149 - val_loss: 3266872.2500 - val_root_mean_squared_error: 1807.4491\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2794756.7500 - root_mean_squared_error: 1671.7526 - val_loss: 3310301.7500 - val_root_mean_squared_error: 1819.4235\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 3s 38ms/step - loss: 2858155.5000 - root_mean_squared_error: 1690.6080 - val_loss: 3318886.2500 - val_root_mean_squared_error: 1821.7810\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2842101.7500 - root_mean_squared_error: 1685.8534 - val_loss: 3309253.7500 - val_root_mean_squared_error: 1819.1355\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2833498.7500 - root_mean_squared_error: 1683.2999 - val_loss: 3331055.0000 - val_root_mean_squared_error: 1825.1178\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2876894.7500 - root_mean_squared_error: 1696.1412 - val_loss: 3334706.2500 - val_root_mean_squared_error: 1826.1178\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 2s 27ms/step - loss: 2794349.2500 - root_mean_squared_error: 1671.6307 - val_loss: 3311927.7500 - val_root_mean_squared_error: 1819.8702\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 2752266.7500 - root_mean_squared_error: 1658.9957 - val_loss: 3253001.2500 - val_root_mean_squared_error: 1803.6079\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2809545.0000 - root_mean_squared_error: 1676.1698 - val_loss: 3309128.7500 - val_root_mean_squared_error: 1819.1013\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2820024.0000 - root_mean_squared_error: 1679.2927 - val_loss: 3316599.7500 - val_root_mean_squared_error: 1821.1534\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 2833165.2500 - root_mean_squared_error: 1683.2009 - val_loss: 3267095.2500 - val_root_mean_squared_error: 1807.5107\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 2822435.5000 - root_mean_squared_error: 1680.0106 - val_loss: 3292667.0000 - val_root_mean_squared_error: 1814.5708\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 3s 34ms/step - loss: 2839043.2500 - root_mean_squared_error: 1684.9460 - val_loss: 3214360.5000 - val_root_mean_squared_error: 1792.8638\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 2772847.5000 - root_mean_squared_error: 1665.1869 - val_loss: 3271976.2500 - val_root_mean_squared_error: 1808.8605\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 2750841.5000 - root_mean_squared_error: 1658.5660 - val_loss: 3323936.2500 - val_root_mean_squared_error: 1823.1665\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 2794848.5000 - root_mean_squared_error: 1671.7799 - val_loss: 3273158.7500 - val_root_mean_squared_error: 1809.1874\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Simple bidrectional LSTM model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# model wiht functional API\n",
        "inputs = Input(shape=(seq_length, len(features)))\n",
        "x = Bidirectional(LSTM(64, activation='relu', dropout=0.25, return_sequences=True))(inputs)\n",
        "#x = Bidirectional(LSTM(32, activation='relu', dropout=0.25, return_sequences=True))(x)\n",
        "x = Bidirectional(LSTM(32, activation='relu', dropout=0.25, return_sequences=True))(x)\n",
        "outputs = Dense(1, activation='linear')(x)\n",
        "\n",
        "model_seq = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_seq.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "print(model_seq.summary())\n",
        "\"\"\"\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in dataset:\n",
        "        # Assuming batch is a tuple of input data and labels\n",
        "        loss = model_seq.train_on_batch(batch[0], batch[1])\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss}\")\"\"\"\n",
        "\n",
        "history = model_seq.fit(dataset_train, epochs=100, batch_size=32, validation_data=(dataset_dev))\n",
        "#history = model_seq.fit(X_train_scaled_3d, y_train_3d, epochs=100, batch_size=32, validation_data=(X_dev_scaled_3d, y_dev_3d))\n",
        "#history = model_seq.fit(dataset_train, epochs=100, batch_size=32, validation_data=(X_dev_scaled_3d, y_dev_3d))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the array for the x axis, starting from 1\n",
        "epochs = np.arange(1, len(history.history[\"root_mean_squared_error\"])+1)\n",
        "train_rmse = history.history[\"root_mean_squared_error\"]\n",
        "dev_rmse = history.history[\"val_root_mean_squared_error\"]\n",
        "\n",
        "# Create a line chart with two lines using Plotly Express\n",
        "fig = px.line(title='train RMSE vs. dev RMSE')\n",
        "fig.add_scatter(x=epochs, y=train_rmse, mode='lines+markers', name='Train RMSE', line=dict(color='red'))\n",
        "fig.add_scatter(x=epochs, y=dev_rmse, mode='lines+markers', name='Dev RMSE', line=dict(color='blue'))\n",
        "\n",
        "\n",
        "# Set chart title and axis labels\n",
        "fig.update_layout(\n",
        "    xaxis_title='Epochs',\n",
        "    yaxis_title='RMSE'\n",
        ")\n",
        "\n",
        "# Show the chart\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7i6bKNcPps07",
        "outputId": "df7d4f5d-2477-43a5-c7c9-6d97e0e1c257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        }
      },
      "id": "7i6bKNcPps07",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"a9382565-9c2b-48b0-bd10-346bfb78f0eb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a9382565-9c2b-48b0-bd10-346bfb78f0eb\")) {                    Plotly.newPlot(                        \"a9382565-9c2b-48b0-bd10-346bfb78f0eb\",                        [{\"hovertemplate\":\"\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"mode\":\"lines+markers\",\"name\":\"Train RMSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[5844.79736328125,2811.19287109375,2139.4658203125,2005.2056884765625,1971.40576171875,1933.7227783203125,1921.346435546875,1897.8109130859375,1889.396240234375,1873.2935791015625,1862.311767578125,1867.1474609375,1835.841796875,1824.3731689453125,1838.57666015625,1816.7703857421875,1819.5989990234375,1798.9195556640625,1794.6011962890625,1778.123779296875,1793.43017578125,1795.4339599609375,1775.146728515625,1783.93359375,1773.703857421875,1765.8145751953125,1767.8494873046875,1751.096923828125,1736.259765625,1746.5279541015625,1731.9635009765625,1735.5994873046875,1729.939697265625,1717.61328125,1727.5689697265625,1726.1142578125,1707.7099609375,1704.53369140625,1721.1837158203125,1707.50927734375,1700.3382568359375,1689.1781005859375,1699.6636962890625,1696.35302734375,1683.5811767578125,1701.5330810546875,1706.7144775390625,1688.5450439453125,1691.2899169921875,1689.24169921875,1680.4317626953125,1673.7208251953125,1684.343994140625,1675.3099365234375,1669.219482421875,1679.2633056640625,1675.7591552734375,1669.41064453125,1679.7440185546875,1669.932861328125,1662.59130859375,1660.156005859375,1657.9981689453125,1658.2222900390625,1664.1353759765625,1667.984375,1666.926513671875,1653.279296875,1658.9449462890625,1655.8721923828125,1665.5821533203125,1653.8084716796875,1643.3294677734375,1649.1746826171875,1661.3863525390625,1648.37353515625,1652.5726318359375,1641.1309814453125,1632.325439453125,1632.7001953125,1631.6224365234375,1640.638671875,1617.3507080078125,1631.31689453125,1616.38330078125,1621.5146484375,1626.770751953125,1623.71923828125,1624.1822509765625,1625.8155517578125,1599.7403564453125,1613.8953857421875,1612.2872314453125,1614.9844970703125,1600.4066162109375,1611.338623046875,1594.5439453125,1590.426513671875,1581.3043212890625,1592.87548828125],\"type\":\"scatter\"},{\"line\":{\"color\":\"blue\"},\"mode\":\"lines+markers\",\"name\":\"Dev RMSE\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[3454.544921875,2612.613525390625,2288.38720703125,2258.964599609375,2245.35498046875,2159.83251953125,2139.91796875,2146.829833984375,2132.541748046875,2150.048828125,2128.000732421875,2054.94140625,2061.717041015625,2057.067626953125,2045.1226806640625,1901.3955078125,2055.313232421875,1942.6201171875,1969.79052734375,1966.2220458984375,1916.8980712890625,1980.9395751953125,1970.7703857421875,1994.222412109375,1948.4365234375,1884.2474365234375,1964.135009765625,1920.8323974609375,1910.8380126953125,1907.2122802734375,1854.0452880859375,1883.7021484375,1950.8223876953125,1862.0430908203125,1852.6728515625,1857.3665771484375,1879.6868896484375,1822.453369140625,1914.237060546875,1825.32470703125,1850.1265869140625,1840.9986572265625,1818.3330078125,1890.5281982421875,1855.685302734375,1819.1787109375,1847.68603515625,1818.0426025390625,1825.4788818359375,1863.083984375,1819.0958251953125,1876.3675537109375,1842.4232177734375,1832.788330078125,1807.4488525390625,1844.6082763671875,1839.7012939453125,1836.1678466796875,1856.9224853515625,1847.7967529296875,1841.8201904296875,1826.0513916015625,1851.4254150390625,1894.2803955078125,1891.8199462890625,1831.058837890625,1790.5450439453125,1833.8995361328125,1844.6392822265625,1853.2938232421875,1794.359619140625,1815.272216796875,1863.9453125,1786.1060791015625,1795.976318359375,1844.755859375,1789.1796875,1797.2344970703125,1772.40380859375,1890.8997802734375,1798.0792236328125,1784.1290283203125,1823.151123046875,1781.21533203125,1808.3839111328125,1781.872802734375,1829.4398193359375,1808.5955810546875,1752.2633056640625,1778.1468505859375,1867.0723876953125,1780.94140625,1806.708984375,1816.25146484375,1778.953857421875,1794.172119140625,1780.97021484375,1798.9761962890625,1829.4212646484375,1757.5758056640625],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"RMSE\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"train RMSE vs. dev RMSE\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a9382565-9c2b-48b0-bd10-346bfb78f0eb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain model predictions using shap library:\n",
        "explainer = shap.DeepExplainer(model_seq, X_train_scaled_3d)\n",
        "shap_values = explainer.shap_values(X_train_scaled_3d)\n",
        "\n",
        "# Plot summary_plot as barplot:\n",
        "shap.summary_plot(shap_values, X_train_scaled, feature_names=features, plot_type='bar', plot_size=[15,5])"
      ],
      "metadata": {
        "id": "de-Brsyzo-9-",
        "outputId": "a0b00bf8-f9aa-4866-d1d5-b8b43306b32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "id": "de-Brsyzo-9-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/shap/explainers/_deep/deep_tf.py:107: UserWarning:\n",
            "\n",
            "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-55215e9fd474>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Explain model predictions using shap library:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled_3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plot summary_plot as barplot:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_deep/__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_deep/deep_tf.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mmodel_output_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mranked_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mmodel_output_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_symbolics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# compute the attributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_BatchDataset' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utils\n",
        "def get_error_sequential(model, X, y, seq_length):\n",
        "    # Evaluate the model's performance using RMSE on dataset X, y\n",
        "    y_hat = model.predict(X)\n",
        "\n",
        "    # Reshaping array for calculating RMSE\n",
        "    y_flattened = y.reshape(len(y), seq_length)\n",
        "    y_hat_flattened = y_hat.reshape(len(y_hat), seq_length)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_flattened, y_hat_flattened))\n",
        "    return rmse\n",
        "\n",
        "print(\"Train RMSE: %f\" % (get_error_sequential(model_seq, X_train_scaled_3d, y_train_3d, 4)))\n",
        "print(\"Dev RMSE: %f\" % (get_error_sequential(model_seq, X_dev_scaled_3d, y_dev_3d, 4)))"
      ],
      "metadata": {
        "id": "yTUneZ4s-7jP",
        "outputId": "2fe76791-094b-4702-86d4-d9fadb4268b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yTUneZ4s-7jP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 1s 9ms/step\n",
            "Train RMSE: 1516.949516\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Dev RMSE: 1757.575771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-QSP6ba9x2S"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Complex model takes very long and val score is not much better. It overfitted\n",
        "Epoch 50/50\n",
        "92/92 [==============================] - 25s 273ms/step - loss: 1557592.7500 - root_mean_squared_error: 1248.0355 - val_loss: 2976063.0000 - val_root_mean_squared_error: 1725.1270\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#num_samples = len(X_train_scaled_3d)\n",
        "num_sequence = 4\n",
        "# Build the LSTM model\n",
        "\n",
        "CONV_WIDTH = 3\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.ConvLSTM2D(filters=512, kernel_size=(1,2), activation='relu', dropout=0.2, input_shape=(2, 1, 2, 23)),\n",
        "            tf.keras.layers.Dense(\n",
        "                num_sequence, kernel_initializer=tf.initializers.zeros()\n",
        "            ),\n",
        "            tf.keras.layers.Reshape([num_sequence, 1]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "X = X_train_scaled_3d.reshape((X_train_scaled_3d.shape[0], 2, 1, 2, 23))\n",
        "Xdev = X_dev_scaled_3d.reshape((X_dev_scaled_3d.shape[0], 2, 1, 2, 23))\n",
        "\n",
        "history = model.fit(X, y_train_3d, epochs=50, batch_size=32, validation_data=(Xdev, y_dev_3d))"
      ],
      "id": "t-QSP6ba9x2S"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3FCqONIDCU2"
      },
      "source": [
        "<a name=\"6.\"></a>\n",
        "## 6. Summary and conclusion\n",
        "[Content](#content)"
      ],
      "id": "v3FCqONIDCU2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have trained three different models with increasing complexity. For the problem at hand it can be said that the more complex MLP model or LSTM model did not perform better, than the simpler XGBoost model. In fact, the LSTM model performt worse than the two previous ones.\n",
        "\n",
        "While the XGBoost model already did well with standard parameters, it was more difficult to find a good architecture with the more complex model MLP and LSTM which was especially true for the last model.\n",
        "\n",
        "A possible reason, why the LSTM model performed worse could be, that the problem at hand has not a strong sequential nature. The dataset is clearly time series data, but the different data points or not very dependent on the previous data points. An easy ilustration to this is, that the people taking a bycicle today, do not care about the weather of yesterday or how many people took the bicyle one day ago. Much more relevant is the current day of the week and the weather of today. Therefore the sequential LSTM model mostly added complexity without adding much of value."
      ],
      "metadata": {
        "id": "urK_A--4Duuj"
      },
      "id": "urK_A--4Duuj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b1665a-51e2-4abd-89d0-301a25a32e84",
        "id": "Pi51ZxlXqxlA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 4, 13)]           0         \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 4, 128)           39936     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirecti  (None, 4, 64)            41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4, 1)              65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,217\n",
            "Trainable params: 81,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "92/92 [==============================] - 9s 42ms/step - loss: 34699160.0000 - root_mean_squared_error: 5890.5991 - val_loss: 11886261.0000 - val_root_mean_squared_error: 3447.6460\n",
            "Epoch 2/10\n",
            "92/92 [==============================] - 3s 36ms/step - loss: 7404714.0000 - root_mean_squared_error: 2721.1602 - val_loss: 6774370.0000 - val_root_mean_squared_error: 2602.7617\n",
            "Epoch 3/10\n",
            "92/92 [==============================] - 2s 18ms/step - loss: 4837188.5000 - root_mean_squared_error: 2199.3608 - val_loss: 5235229.0000 - val_root_mean_squared_error: 2288.0623\n",
            "Epoch 4/10\n",
            "92/92 [==============================] - 2s 24ms/step - loss: 4083634.5000 - root_mean_squared_error: 2020.8004 - val_loss: 4775735.0000 - val_root_mean_squared_error: 2185.3455\n",
            "Epoch 5/10\n",
            "92/92 [==============================] - 3s 27ms/step - loss: 3849119.5000 - root_mean_squared_error: 1961.9171 - val_loss: 5005984.0000 - val_root_mean_squared_error: 2237.4058\n",
            "Epoch 6/10\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 3771984.0000 - root_mean_squared_error: 1942.1597 - val_loss: 4629778.0000 - val_root_mean_squared_error: 2151.6919\n",
            "Epoch 7/10\n",
            "92/92 [==============================] - 3s 32ms/step - loss: 3710187.5000 - root_mean_squared_error: 1926.1847 - val_loss: 4636717.5000 - val_root_mean_squared_error: 2153.3040\n",
            "Epoch 8/10\n",
            "92/92 [==============================] - 4s 43ms/step - loss: 3649427.5000 - root_mean_squared_error: 1910.3475 - val_loss: 4388221.0000 - val_root_mean_squared_error: 2094.8081\n",
            "Epoch 9/10\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 3592765.5000 - root_mean_squared_error: 1895.4592 - val_loss: 3887623.5000 - val_root_mean_squared_error: 1971.7057\n",
            "Epoch 10/10\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 3509326.5000 - root_mean_squared_error: 1873.3197 - val_loss: 4403028.0000 - val_root_mean_squared_error: 2098.3394\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Simple bidrectional LSTM model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "num_sequence = 4\n",
        "# Build the LSTM model\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=256, input_shape=(1, X_train.shape[1]), activation='relu'))\n",
        "# Add a dense output layer with a single unit (for regression) and no activation function\n",
        "model.add(Dense(units=1))\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    # Shape => [batch, time, features]\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\"\"\"\n",
        "# Build the LSTM model\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(num_sequence, 21)))\n",
        "model.add(LSTM(units=32, activation='relu', dropout=0.1))\n",
        "model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "model = Sequential([\n",
        "    #Input(shape=(num_sequence, 21)),\n",
        "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
        "    LSTM(32, activation='relu', dropout=0.1, return_sequences=True),\n",
        "    # Shape => [batch, time, features]\n",
        "    Dense(units=1, activation='linear')\n",
        "])\"\"\"\n",
        "\n",
        "CONV_WIDTH = 3\n",
        "\n",
        "\n",
        "\"\"\"OUT_STEPS = 4\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        Input(shape=(num_sequence, 23)),\n",
        "        tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
        "        tf.keras.layers.Conv1D(256, activation=\"relu\", kernel_size=(CONV_WIDTH)),\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(32, return_sequences=True)\n",
        "        ),\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(32, return_sequences=False)\n",
        "        ),\n",
        "        tf.keras.layers.Dense(\n",
        "            OUT_STEPS * 1, kernel_initializer=tf.initializers.zeros()\n",
        "        ),\n",
        "        tf.keras.layers.Reshape([OUT_STEPS, 1]),\n",
        "    ]\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "inputs = Input(shape=(num_sequence, len(features))\n",
        "#x = tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :])(inputs)\n",
        "#x = tf.keras.layers.Conv1D(256, activation=\"relu\", kernel_size=(CONV_WIDTH))(x)\n",
        "x = Bidirectional(LSTM(64, activation='relu', dropout=0.25, return_sequences=True))(inputs)\n",
        "x = Bidirectional(LSTM(32, activation='relu', dropout=0.25, return_sequences=True))(x)\n",
        "#x = LSTM(64, activation='relu', dropout=0.2, return_sequences=True)(inputs)\n",
        "#x = LSTM(32, activation='relu', dropout=0.2, return_sequences=True)(x)\n",
        "#x = LSTM(32, activation='relu', dropout=0.0, return_sequences=True)(x)\n",
        "outputs = Dense(1, activation='linear')(x)\n",
        "#outputs = Reshape([num_sequence, 1])(x)\n",
        "\n",
        "\"\"\"\n",
        "inputs = Input(shape=(num_sequence, 21))\n",
        "x = LSTM(64, activation='relu', dropout=0.1, return_sequences=True)(inputs)\n",
        "outputs = Dense(1, activation='linear', name=\"custom_output\")(x)\n",
        "\"\"\"\n",
        "\n",
        "model_seq = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_seq.compile(optimizer=optimizer, loss='mse', metrics=[RootMeanSquaredError()])\n",
        "\n",
        "print(model_seq.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_train_scaled_3d = np.reshape(X_train_scaled, (num_samples, num_sequence, X_train_scaled.shape[1]))  # Fix variable name\n",
        "\n",
        "#num_samples = X_dev_scaled.shape[0]\n",
        "#X_dev_scaled_3d = np.reshape(X_dev_scaled, (num_samples, num_sequence, X_dev_scaled.shape[1]))\n",
        "\n",
        "# Train the model\n",
        "#X_train_scaled_3d = np.expand_dims(X_train_scaled_3d[0], axis=0)\n",
        "#y_train_3d = np.expand_dims(y_train_3d[0], axis=0)\n",
        "#print(X_train_scaled_3d)\n",
        "#print(y_train_3d)\n",
        "#print(testing_y.shape)\n",
        "\n",
        "#X = X_train_scaled_3d.reshape((X_train_scaled_3d.shape[0], 2, 1, 2, 23))\n",
        "#Xdev = X_dev_scaled_3d.reshape((X_dev_scaled_3d.shape[0], 2, 1, 2, 23))\n",
        "\n",
        "\n",
        "#history = model.fit(X_train_scaled_3d, testing_y, epochs=10, batch_size=32, verbose=2, validation_data=(X_dev_scaled_3d, y_dev_3d))\n",
        "#history = model.fit(X, y_train_3d, epochs=50, batch_size=32, validation_data=(Xdev, y_dev_3d))\n",
        "\n",
        "history = model_seq.fit(X_train_scaled_3d, y_train_3d, epochs=10, batch_size=32, validation_data=(X_dev_scaled_3d, y_dev_3d))\n",
        "#history = model.fit(dataset, epochs=10, batch_size=32, verbose=2, validation_data=(X_dev_scaled_3d, y_dev_3d))\n",
        "#history = model.fit(x_trainnnn, y_trainnnn, epochs=10, batch_size=32, verbose=2)\n",
        "\n",
        "#validation_data=(X_dev_scaled, y_dev)\n",
        "\n",
        "#output = model.predict(X_train_scaled_3d)\n",
        "#output = model.predict(X_train_scaled_3d)\n",
        "#intermediate_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(\"custom_output\").output)\n",
        "#intermediate_model.predict(X_train_scaled_3d)\n",
        "\n",
        "\n"
      ],
      "id": "Pi51ZxlXqxlA"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}